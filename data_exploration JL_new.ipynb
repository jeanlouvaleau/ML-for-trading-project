{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663276e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32cd8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2423b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RidgeCV, MultiTaskLassoCV, MultiTaskElasticNetCV, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor,MultiOutputClassifier\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371adc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce457d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f109b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f13923",
   "metadata": {},
   "source": [
    "# I- Training linear models on daily data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261e7b5",
   "metadata": {},
   "source": [
    "We will try to train models on both daily and weekly data. We may see some different dynamics between daily and weekly data: it could be easier to train a model on weekly data because there is less autocorrelation between datapoints. However in the meanwhile, the dataset on daily datapoints may be bigger so it could also be easier to train models on daily data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e53cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('data', 'US', 'us_data.csv')\n",
    "dus = pd.read_csv(datapath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_inf = dus.columns[np.isinf(dus.to_numpy()).any(axis=0)]\n",
    "print(cols_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus.hist(figsize=(23, 23), bins=100)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec41c5",
   "metadata": {},
   "source": [
    "### A) Creating new features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86313b39",
   "metadata": {},
   "source": [
    "Now we need to add the lagged values of yields as features. We have to choose lags and yields to add as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for USyield in ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']:\n",
    "    series = dus[USyield]\n",
    "    fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "    plot_acf(series, lags=90,title = f'ACF {USyield}', ax = axes[0])\n",
    "    plot_pacf(series, lags=90,title = f'PACF {USyield}',ax = axes[1])\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlim(0.5, 90)  # décale le début après 0\n",
    "        ax.set_ylim(-0.2, 0.2) \n",
    "\n",
    "        if USyield in ['DGS5','DGS7','DGS10', 'DGS20', 'DGS30']:\n",
    "            \n",
    "            ax.axvline(x=25, color='red', linestyle='--', linewidth=1)\n",
    "            ax.axvline(x=50, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa2f66",
   "metadata": {},
   "source": [
    "- We can see that on short term yields, there is much more autocorrelation in the data, up to more than 30 days. Returns in the past few days are highly correlated to returns in the next days. \n",
    "- However, on long term yields, there is much less autocorrelation and returns in the past 2 days are only slightly correlated to next day return. Surprisingly we see some persistent autocorrelation between returns at day t and t-25 and t-50. \n",
    "\n",
    "For maturities less than 1y, we'll add the following lags:\n",
    "- t-1,t-2,t-5,t-10,t-15,t-20,t-25,t-30,t-40,t-50\n",
    "\n",
    "For maturities more than 1y, we will add:\n",
    "- t-1,t-2,t-10,t-25,t-50\n",
    "\n",
    "We will probably need to do some PCA to combine features as they will be very correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3581d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [1,2,5,10,15,20,25,30,40,50]:\n",
    "    dus[f'DGS1MO_t-{lag}'] = dus['DGS1MO'].shift(lag-1)\n",
    "    dus[f'DGS3MO_t-{lag}'] = dus['DGS3MO'].shift(lag-1)\n",
    "    dus[f'DGS6MO_t-{lag}'] = dus['DGS6MO'].shift(lag-1)\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "  \n",
    "\n",
    "for lag in [1,2,10,15,25,50]:\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "    dus[f'DGS2_t-{lag}'] = dus['DGS2'].shift(lag-1)\n",
    "    dus[f'DGS3_t-{lag}'] = dus['DGS3'].shift(lag-1)\n",
    "    dus[f'DGS5_t-{lag}'] = dus['DGS5'].shift(lag-1)\n",
    "    dus[f'DGS7_t-{lag}'] = dus['DGS7'].shift(lag-1)\n",
    "    dus[f'DGS10_t-{lag}'] = dus['DGS10'].shift(lag-1)\n",
    "    dus[f'DGS20_t-{lag}'] = dus['DGS20'].shift(lag-1)\n",
    "    dus[f'DGS30_t-{lag}'] = dus['DGS30'].shift(lag-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variables to forecast \n",
    "\n",
    "dus['Y_1MO'] = dus['DGS1MO'].shift(-1)\n",
    "dus['Y_3MO'] = dus['DGS3MO'].shift(-1)\n",
    "dus['Y_6MO'] = dus['DGS6MO'].shift(-1)\n",
    "dus['Y_1year'] = dus['DGS1'].shift(-1)\n",
    "dus['Y_2year'] = dus['DGS2'].shift(-1)\n",
    "dus['Y_3year'] = dus['DGS3'].shift(-1)\n",
    "dus['Y_5year'] = dus['DGS5'].shift(-1)\n",
    "dus['Y_7year'] = dus['DGS7'].shift(-1)\n",
    "dus['Y_10year'] = dus['DGS10'].shift(-1)\n",
    "dus['Y_20year'] = dus['DGS20'].shift(-1)\n",
    "dus['Y_30year'] = dus['DGS30'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now remove the original yield columns\n",
    "dus = dus.drop(columns=['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c8c90",
   "metadata": {},
   "source": [
    "We can now look at the heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,25))\n",
    "sns.heatmap(dus.corr(), cmap='seismic', center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514c74a",
   "metadata": {},
   "source": [
    "Overall the features have a very low correlation with the target, so we'll remove the least correlated ones: \n",
    "\n",
    "- the lagged features that have a correlation coefficient < 0.05 in absolute value with all target variables. \n",
    "- the other features that have a correlation coefficient < 0.03 in absolute value with all target variables. We do a distinction between lagged features and other features because filtering all features with the 0.05 threshold removes somes features that should have a predictive impact: sp500, gold, VIX for instance. \n",
    "\n",
    "Moreover, given the very high correlation between lagged features, we'll apply a PCA in the pipeline on those to limit the number of colinear features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0962fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dus[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n",
    "dus_lagged_features = dus[[col for col in dus.columns if '_t-' in col]]\n",
    "dus_other =dus.drop(columns=[col for col in dus.columns if '_t-' in col])\n",
    "\n",
    "corrs = pd.DataFrame({\n",
    "    target: dus_lagged_features.corrwith(Y[target]) for target in Y.columns\n",
    "}).abs()  \n",
    "\n",
    "# repérer les colonnes où la corrélation absolue < 0.05 pour toutes les targets\n",
    "mask = (corrs < 0.05).all(axis=1)\n",
    "low_corr_features = corrs.index[mask]\n",
    "\n",
    "# supprimer ces colonnes\n",
    "dus_filtered = dus.drop(columns=low_corr_features)\n",
    "\n",
    "\n",
    "\n",
    "corrs = pd.DataFrame({\n",
    "    target: dus_other.corrwith(Y[target]) for target in Y.columns\n",
    "}).abs()  \n",
    "\n",
    "# repérer les colonnes où la corrélation absolue < 0.05 pour toutes les targets\n",
    "mask = (corrs < 0.03).all(axis=1)\n",
    "low_corr_features_2 = corrs.index[mask]\n",
    "\n",
    "# supprimer ces colonnes\n",
    "dus_filtered = dus_filtered.drop(columns=low_corr_features_2)\n",
    "\n",
    "print(f\"{len(low_corr_features) + len(low_corr_features_2)} features were deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low_corr_features)\n",
    "print(low_corr_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdeb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(dus_filtered.corr(), cmap='seismic', center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb294fcf",
   "metadata": {},
   "source": [
    "### B) PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1768633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus_filtered = dus_filtered.dropna()\n",
    "X = dus_filtered[['USGOOD', 'USCONS', 'MANEMP', 'DMANEMP', 'NDMANEMP', 'USWTRADE',\n",
    "       'USFIRE', 'PERMIT', 'UMCSENT', 'M2SL', 'M2REAL', 'TOTRESNS', 'CPIAUCSL',\n",
    "       'CPIAPPSL', 'CPITRNSL', 'CUSR0000SAC', 'CPIULFSL', 'CUUR0000SA0L2',\n",
    "       'PCEPI', 'DNDGRG3M086SBEA', 'MTSDS133FMS', 'GFDEGDQ188S',\n",
    "       'IRLTLT01DEM156N', 'IRLTLT01JPM156N', 'IRLTLT01GBM156N',\n",
    "       'IRLTLT01CAM156N', 'IRLTLT01AUM156N', 'IRLTLT01FRM156N', 'NASDAQCOM',\n",
    "       'AAA', 'BAA', 'DEXCAUS', 'DEXUSAL', 'NFCI', 'FEDFUNDS', 'BOGMBASE',\n",
    "       'WSHOSHO', 'T5YIE', 'T10YIE', 'log return gold', 'log return sp500',\n",
    "       'DGS1MO_t-1', 'DGS3MO_t-1', 'DGS6MO_t-1', 'DGS1_t-1', 'DGS1MO_t-2',\n",
    "       'DGS3MO_t-2', 'DGS6MO_t-2', 'DGS1MO_t-5', 'DGS3MO_t-5', 'DGS6MO_t-5',\n",
    "       'DGS3MO_t-10', 'DGS6MO_t-10', 'DGS1_t-10', 'DGS1MO_t-15', 'DGS3MO_t-15',\n",
    "       'DGS6MO_t-15', 'DGS1MO_t-20', 'DGS3MO_t-20', 'DGS6MO_t-20', 'DGS1_t-20',\n",
    "       'DGS3MO_t-30', 'DGS6MO_t-40', 'DGS1MO_t-50', 'DGS2_t-1', 'DGS3_t-1',\n",
    "       'DGS10_t-1', 'DGS20_t-1', 'DGS30_t-1', 'DGS7_t-50', 'DGS10_t-50',\n",
    "       'DGS20_t-50', 'DGS30_t-50']]\n",
    "\n",
    "Y = dus_filtered[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47038b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Number of components kept:\", pca.n_components_)\n",
    "print(\"cumulative explained variance :\", pca.explained_variance_ratio_.cumsum())\n",
    "print(\"Composantes principales (coefficients sur les features originales) :\")\n",
    "print(pca.components_)\n",
    "\n",
    "print(\"Exemple des nouvelles features transformées :\")\n",
    "print(X_pca[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculer la contribution absolue sur PC1 et PC2\n",
    "pc1, pc2 = np.abs(pca.components_[:2])\n",
    "importance = pc1 + pc2\n",
    "\n",
    "# garder les n features les plus importantes\n",
    "n = 30\n",
    "top_idx = np.argsort(importance)[-n:]\n",
    "top_labels = X.columns[top_idx]\n",
    "top_components = pca.components_[:2, top_idx]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "circle = plt.Circle((0,0), 1, color='gray', fill=False)\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(top_components[0,:], top_components[1,:])):\n",
    "    plt.arrow(0, 0, x, y, color='r', alpha=0.6, head_width=0.02)\n",
    "    plt.text(x*1.15, y*1.15, top_labels[i], color='b', ha='center', va='center', fontsize=9)\n",
    "\n",
    "plt.xlim(-1.1, 1.1)\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Correlation circle (top features)\")\n",
    "plt.grid()\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af776ae0",
   "metadata": {},
   "source": [
    "We can see that features are overall very correlated, so we'll train some models with PCA and some without."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4584738",
   "metadata": {},
   "source": [
    "### C) Training a ridge model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f7a26",
   "metadata": {},
   "source": [
    "We do a walk forward cross validation:\n",
    "- we train our model on 4 years of data (= approximately 1000 data points)\n",
    "- we do prediction for the next month (21 days)\n",
    "- wa add a PCA to the pipeline to deal with correlated features. We'll also train a model without PCA to see how it changes the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "window_train = 252 *4\n",
    "window_pred = 21          \n",
    "alphas = np.logspace(-3, 3, 20)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "plt.close('all')  # ferme toutes les figures existantes\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per model with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per model without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per model with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per model without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7249b4",
   "metadata": {},
   "source": [
    "- When looking at the in sample R2 of our models, we see that the R2 is overall low, but that it is better on short term yields, ie from 1 month to 1 year, and significantly lower for long-term yields. \n",
    "- we see significant variations in R2 in 2011 and 2020, probably because of outliers. \n",
    "\n",
    "- The out of sample R2 is close to zero or even negative so there is no predictive power in our model.\n",
    "\n",
    "- adding a PCA in the pipeline do not change anything to the in sample R2. However, the hit rate is slightly less variable when adding the PCA, suggesting a bit less overfitting (although the out of sample results are as bad).\n",
    "- The hit rate seems to be close to 0.5 on average for all models and all samples. So it appears the model does not do anything better than predicting at random - it completely overfits the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5de84f",
   "metadata": {},
   "source": [
    "## Training Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-5, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 252 *4\n",
    "window_pred = 21          \n",
    "alphas = np.logspace(-5, 2, 20)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('lasso', MultiTaskLassoCV(fit_intercept=False,alphas=alphas, cv=tscv))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('lasso', MultiTaskLassoCV(fit_intercept=False,alphas=alphas, cv=tscv))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "alpha,selected_features = [],[]\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "alpha_nopca,selected_features_nopca = [],[]\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    alpha.append(pipe.named_steps['lasso'].alpha_)\n",
    "    selected_features.append(np.sum(np.any(pipe.named_steps['lasso'].coef_!=0,axis=0)))\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "    alpha_nopca.append(pipe_nopca.named_steps['lasso'].alpha_)\n",
    "    selected_features_nopca.append(np.sum(np.any(pipe_nopca.named_steps['lasso'].coef_!=0,axis=0)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0852b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs = pd.DataFrame(selected_features)\n",
    "fs.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs_nopca = pd.DataFrame(selected_features_nopca)\n",
    "fs_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "alphadf = pd.DataFrame(alpha)\n",
    "alphadf.index = [date[0] for date in dates_pred]\n",
    "\n",
    "alphadf_nopca = pd.DataFrame(alpha_nopca)\n",
    "alphadf_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(5,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per maturity with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per maturity without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per maturity with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per maturity without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "fs.plot(ax = ax[3,0], title = 'Evolution of number of selected features with PCA, per sample')\n",
    "ax[3,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "fs_nopca.plot(ax = ax[3,1], title = 'Evolution of number of selected features without PCA, per sample')\n",
    "ax[3,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "alphadf.plot(ax = ax[4,0], title = 'Evolution of alpha selected by cross validation - model with PCA, per sample')\n",
    "ax[4,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "alphadf_nopca.plot(ax = ax[4,1], title = 'Evolution of alpha selected by cross validation - model without PCA, per sample')\n",
    "ax[4,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129a4af",
   "metadata": {},
   "source": [
    "Lasso performance is even worse than that of ridge because there are some periods for which the model selects no features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c5160",
   "metadata": {},
   "source": [
    "## Training Elastic net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 252 *10\n",
    "window_pred = 21          \n",
    "alphas = np.logspace(-3, 2, 20)\n",
    "l1_ratios = [0.25,0.5,0.75]\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=0.5, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=l1_ratios, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "alpha,selected_features,l1 = [],[],[]\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "alpha_nopca,selected_features_nopca,l1_nopca = [],[],[]\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    alpha.append(pipe.named_steps['elasticnet'].alpha_)\n",
    "    selected_features.append(np.sum(np.any(pipe.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1.append(pipe.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "    alpha_nopca.append(pipe_nopca.named_steps['elasticnet'].alpha_)\n",
    "    selected_features_nopca.append(np.sum(np.any(pipe_nopca.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1_nopca.append(pipe_nopca.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489868d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs = pd.DataFrame(selected_features)\n",
    "fs.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs_nopca = pd.DataFrame(selected_features_nopca)\n",
    "fs_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "alphadf = pd.DataFrame(alpha)\n",
    "alphadf.index = [date[0] for date in dates_pred]\n",
    "\n",
    "alphadf_nopca = pd.DataFrame(alpha_nopca)\n",
    "alphadf_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "l1df = pd.DataFrame(l1)\n",
    "l1df.index = [date[0] for date in dates_pred]\n",
    "\n",
    "l1df_nopca = pd.DataFrame(l1_nopca)\n",
    "l1df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(6,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per maturity with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per maturity without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per maturity with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per maturity without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "fs.plot(ax = ax[3,0], title = 'Evolution of number of selected features with PCA, per sample')\n",
    "ax[3,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "fs_nopca.plot(ax = ax[3,1], title = 'Evolution of number of selected features without PCA, per sample')\n",
    "ax[3,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "alphadf.plot(ax = ax[4,0], title = 'Evolution of alpha selected by cross validation - model with PCA, per sample')\n",
    "ax[4,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "alphadf_nopca.plot(ax = ax[4,1], title = 'Evolution of alpha selected by cross validation - model without PCA, per sample')\n",
    "ax[4,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "l1df.plot(ax = ax[5,0], title = 'Evolution of L1 ratio selected by cross validation - model with PCA, per sample')\n",
    "ax[5,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "l1df_nopca.plot(ax = ax[5,1], title = 'Evolution of L1 ratio selected by cross validation - model without PCA, per sample')\n",
    "ax[5,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09193bf",
   "metadata": {},
   "source": [
    "Overall all these linear models work very poorly, which is not surprising given the low correlation between features and past yields. We can now try to work on weekly data, which may be a bit less noisy: hopefully our model will be able to better identify some trends and patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08c70c",
   "metadata": {},
   "source": [
    "# II) Training linear models on weekly data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('data', 'US', 'us_data_weekly.csv')\n",
    "dus = pd.read_csv(datapath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe448618",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus = dus[dus.index>'2003-01-03']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db708b",
   "metadata": {},
   "source": [
    "### A) Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for USyield in ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']:\n",
    "    series = dus[USyield]\n",
    "    fig, axes = plt.subplots(1,2, figsize=(14,6))\n",
    "    plot_acf(series, lags=50,title = f'ACF {USyield}', ax = axes[0])\n",
    "    plot_pacf(series, lags=50,title = f'PACF {USyield}',ax = axes[1])\n",
    "    \n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlim(0.5, 50)  # décale le début après 0\n",
    "        ax.set_ylim(-0.2, 0.2) \n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd433bc6",
   "metadata": {},
   "source": [
    "- We can see that on short term yields, there is much more autocorrelation in the data, up to 40 lags. Returns in the past few weeks (and so on the past year) are highly correlated to returns in the next week. \n",
    "- However, on long term yields, there is much less autocorrelation and returns in the past 2 weeks are only very slightly correlated to next day return. Surprisingly we see some persistent autocorrelation between returns at day t and t-25 and t-50. \n",
    "\n",
    "For maturities less than 1y, we'll add the following lags:\n",
    "- t-1,t-2,t-5,t-10,t-15,t-20,t-25,t-30,t-40\n",
    "\n",
    "For maturities more than 1y, we will add:\n",
    "- t-1,t-2,t-10\n",
    "\n",
    "We will probably need to do some PCA to combine features as they will be very correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeeec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [1,2,5,10,15,20,25,30,40,50]:\n",
    "    dus[f'DGS1MO_t-{lag}'] = dus['DGS1MO'].shift(lag-1)\n",
    "    dus[f'DGS3MO_t-{lag}'] = dus['DGS3MO'].shift(lag-1)\n",
    "    dus[f'DGS6MO_t-{lag}'] = dus['DGS6MO'].shift(lag-1)\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "  \n",
    "\n",
    "for lag in [1,2,10]:\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "    dus[f'DGS2_t-{lag}'] = dus['DGS2'].shift(lag-1)\n",
    "    dus[f'DGS3_t-{lag}'] = dus['DGS3'].shift(lag-1)\n",
    "    dus[f'DGS5_t-{lag}'] = dus['DGS5'].shift(lag-1)\n",
    "    dus[f'DGS7_t-{lag}'] = dus['DGS7'].shift(lag-1)\n",
    "    dus[f'DGS10_t-{lag}'] = dus['DGS10'].shift(lag-1)\n",
    "    dus[f'DGS20_t-{lag}'] = dus['DGS20'].shift(lag-1)\n",
    "    dus[f'DGS30_t-{lag}'] = dus['DGS30'].shift(lag-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variables to forecast \n",
    "\n",
    "dus['Y_1MO'] = dus['DGS1MO'].shift(-1)\n",
    "dus['Y_3MO'] = dus['DGS3MO'].shift(-1)\n",
    "dus['Y_6MO'] = dus['DGS6MO'].shift(-1)\n",
    "dus['Y_1year'] = dus['DGS1'].shift(-1)\n",
    "dus['Y_2year'] = dus['DGS2'].shift(-1)\n",
    "dus['Y_3year'] = dus['DGS3'].shift(-1)\n",
    "dus['Y_5year'] = dus['DGS5'].shift(-1)\n",
    "dus['Y_7year'] = dus['DGS7'].shift(-1)\n",
    "dus['Y_10year'] = dus['DGS10'].shift(-1)\n",
    "dus['Y_20year'] = dus['DGS20'].shift(-1)\n",
    "dus['Y_30year'] = dus['DGS30'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be9808",
   "metadata": {},
   "source": [
    "We'll also add statistical features like the mean, variance, autocorrelation, quantiles of the time series to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ts_features(df, cols, max_lag=30, windows=[20, 60]):\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for col in cols:\n",
    "        y = df[col]\n",
    "\n",
    "  \n",
    "        # --- Statistiques glissantes ---\n",
    "        for w in windows:\n",
    "            features[f'{col}_mean_{w}'] = y.rolling(w).mean()\n",
    "            features[f'{col}_std_{w}'] = y.rolling(w).std()\n",
    "            features[f'{col}_q25_{w}'] = y.rolling(w).quantile(0.25)\n",
    "            features[f'{col}_q75_{w}'] = y.rolling(w).quantile(0.75)\n",
    "            features[f'{col}_q05_{w}'] = y.rolling(w).quantile(0.1)\n",
    "            features[f'{col}_q90_{w}'] = y.rolling(w).quantile(0.9)\n",
    "            features[f'{col}_range_{w}'] = y.rolling(w).max() - y.rolling(w).min() \n",
    "        \n",
    "       \n",
    "        # --- Autocorrélations locales ---\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            features[f'{col}_autocorr_{lag}'] = (\n",
    "                y.rolling(window=max(windows)).apply(lambda x: x.autocorr(lag=lag), raw=False)\n",
    "            )\n",
    "        \n",
    "    return features\n",
    "\n",
    "# Exemple d’usage :\n",
    "cols = ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3',\n",
    "        'DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']\n",
    "\n",
    "dus_features = add_ts_features(dus, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae323cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus_features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus = dus.merge(dus_features, how = 'inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus = dus.dropna()\n",
    "dus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now remove the original yield columns\n",
    "dus = dus.drop(columns=['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6d6c4",
   "metadata": {},
   "source": [
    "Many features aren't that much correlated to the target, so we'll remove all features with correlation lower than 0.1 to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dus[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n",
    "\n",
    "corrs = pd.DataFrame({\n",
    "    target: dus.corrwith(Y[target]) for target in Y.columns\n",
    "}).abs()  \n",
    "\n",
    "# repérer les colonnes où la corrélation absolue < 0.05 pour toutes les targets\n",
    "mask = (corrs < 0.1).all(axis=1)\n",
    "low_corr_features = corrs.index[mask]\n",
    "\n",
    "# supprimer ces colonnes\n",
    "dus_filtered = dus.drop(columns=low_corr_features)\n",
    "\n",
    "print(f\"{len(low_corr_features)} features were deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a959c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c80cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,25))\n",
    "sns.heatmap(dus_filtered.corr(), cmap='seismic', center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dus_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9ecb7",
   "metadata": {},
   "source": [
    "### B) Training a ridge model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259923a",
   "metadata": {},
   "source": [
    "We can now try to train a ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dus_filtered[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n",
    "\n",
    "X = dus_filtered.drop(columns = ['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316231bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52*5 #we train our model on 5 years of data and test it on the next month \n",
    "window_pred = 4          \n",
    "alphas = np.logspace(-1, 3, 20)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "plt.close('all')  # ferme toutes les figures existantes\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per model with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per model without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per model with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per model without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab5e46",
   "metadata": {},
   "source": [
    "Results are slightly better than when working on daily data, but we still only learn noise and completely overfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83421aee",
   "metadata": {},
   "source": [
    "### B) Training an elastic net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52*5\n",
    "window_pred = 4         \n",
    "alphas = np.logspace(-2, 2, 20)\n",
    "l1_ratios = [0.25,0.5,0.75]\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=0.5, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=l1_ratios, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "alpha,selected_features,l1 = [],[],[]\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "alpha_nopca,selected_features_nopca,l1_nopca = [],[],[]\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    alpha.append(pipe.named_steps['elasticnet'].alpha_)\n",
    "    selected_features.append(np.sum(np.any(pipe.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1.append(pipe.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "    alpha_nopca.append(pipe_nopca.named_steps['elasticnet'].alpha_)\n",
    "    selected_features_nopca.append(np.sum(np.any(pipe_nopca.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1_nopca.append(pipe_nopca.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs = pd.DataFrame(selected_features)\n",
    "fs.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs_nopca = pd.DataFrame(selected_features_nopca)\n",
    "fs_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "alphadf = pd.DataFrame(alpha)\n",
    "alphadf.index = [date[0] for date in dates_pred]\n",
    "\n",
    "alphadf_nopca = pd.DataFrame(alpha_nopca)\n",
    "alphadf_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "l1df = pd.DataFrame(l1)\n",
    "l1df.index = [date[0] for date in dates_pred]\n",
    "\n",
    "l1df_nopca = pd.DataFrame(l1_nopca)\n",
    "l1df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(6,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per maturity with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per maturity without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per maturity with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per maturity without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "fs.plot(ax = ax[3,0], title = 'Evolution of number of selected features with PCA, per sample')\n",
    "ax[3,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "fs_nopca.plot(ax = ax[3,1], title = 'Evolution of number of selected features without PCA, per sample')\n",
    "ax[3,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "alphadf.plot(ax = ax[4,0], title = 'Evolution of alpha selected by cross validation - model with PCA, per sample')\n",
    "ax[4,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "alphadf_nopca.plot(ax = ax[4,1], title = 'Evolution of alpha selected by cross validation - model without PCA, per sample')\n",
    "ax[4,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "l1df.plot(ax = ax[5,0], title = 'Evolution of L1 ratio selected by cross validation - model with PCA, per sample')\n",
    "ax[5,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "l1df_nopca.plot(ax = ax[5,1], title = 'Evolution of L1 ratio selected by cross validation - model without PCA, per sample')\n",
    "ax[5,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27653ef",
   "metadata": {},
   "source": [
    "The results are also disappointing. Overall this is not surprising, we've seen that our features have a low correlation with the yield so the predictive power of these models is logically very low. We'll now try to do binary classification, maybe it could work better. Moreover, we'll focus on more complex models to see if they can extract non linear relationships between features and yields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa254c",
   "metadata": {},
   "source": [
    "# III - Binary classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7f1e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('data', 'US', 'us_data_weekly.csv')\n",
    "dus_weekly = pd.read_csv(datapath, index_col=0)\n",
    "dus_weekly = dus_weekly.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aafec19",
   "metadata": {},
   "source": [
    "### A) Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc344f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_ts_features(df, cols, max_lag=20, windows=[10,20,50]):\n",
    "\n",
    "    all_features = {}\n",
    "\n",
    "    for col in cols:\n",
    "        y = df[col]\n",
    "\n",
    "        # --- Rolling statistics ---\n",
    "        for w in windows:\n",
    "            roll = y.rolling(w)\n",
    "            all_features[f'{col}_mean_{w}'] = roll.mean()\n",
    "            all_features[f'{col}_std_{w}'] = roll.std()\n",
    "            all_features[f'{col}_q25_{w}'] = roll.quantile(0.25)\n",
    "            all_features[f'{col}_q75_{w}'] = roll.quantile(0.75)\n",
    "            all_features[f'{col}_q05_{w}'] = roll.quantile(0.05)\n",
    "            all_features[f'{col}_q90_{w}'] = roll.quantile(0.9)\n",
    "            all_features[f'{col}_range_{w}'] = roll.max() - roll.min()\n",
    "\n",
    "            # Z-score et momentum\n",
    "            all_features[f'{col}_zscore_{w}'] = (y - roll.mean()) / roll.std()\n",
    "            all_features[f'{col}_momentum_{w}'] = y - y.shift(w)\n",
    "\n",
    "        # Ratio de moyennes rapides / lentes\n",
    "        all_features[f'{col}_ratio_{10}_{50}'] = (\n",
    "            y.rolling(10).mean() / y.rolling(50).mean()\n",
    "        )\n",
    "\n",
    "        # Volatilité annualisée approx\n",
    "        all_features[f'{col}_vol_20'] = y.rolling(20).std() * np.sqrt(52)\n",
    "\n",
    "        # --- Lags bruts ---\n",
    "        for lag in [1,2,3,4,5,10,15,20,25,30,40,50]:\n",
    "            all_features[f'{col}_lag_{lag}'] = y.shift(lag-1)\n",
    "\n",
    "        # --- Autocorrélations (in-sample) ---\n",
    "        acf_vals = acf(y.dropna(), nlags=max_lag, fft=True)\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            all_features[f'{col}_autocorr_{lag}'] = acf_vals[lag]\n",
    "\n",
    "    # --- Construction finale ---\n",
    "    features = pd.DataFrame(all_features, index=df.index)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58251785",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3',\n",
    "        'DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']\n",
    "\n",
    "dus_features = add_ts_features(dus_weekly, cols)\n",
    "dus_features= dus_features.dropna()\n",
    "dus_weekly = dus_weekly.merge(dus_features, how = 'inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45debff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003-12-26   -0.071593\n",
       "2004-01-02   -0.071593\n",
       "2004-01-09   -0.071593\n",
       "2004-01-16   -0.071593\n",
       "2004-01-23   -0.071593\n",
       "                ...   \n",
       "2024-12-06   -0.071593\n",
       "2024-12-13   -0.071593\n",
       "2024-12-20   -0.071593\n",
       "2024-12-27   -0.071593\n",
       "2025-01-03   -0.071593\n",
       "Name: DGS1MO_autocorr_10, Length: 1098, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dus_features['DGS1MO_autocorr_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "890a9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols: \n",
    "    dus_weekly[f'Y_{col}'] = (dus_weekly[col]>0).astype(int).shift(-1)\n",
    "\n",
    "\n",
    "dus_weekly= dus_weekly.dropna()\n",
    "dus_weekly = dus_weekly.replace([np.inf, -np.inf], np.nan)\n",
    "dus_weekly = dus_weekly.ffill()\n",
    "\n",
    "#we can now remove the original yield columns\n",
    "dus_weekly = dus_weekly.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d9a2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 738 features in the dataset\n"
     ]
    }
   ],
   "source": [
    "Yw = dus_weekly[[f'Y_{col}' for col in cols]]\n",
    "Xw = dus_weekly.drop(columns = [f'Y_{col}' for col in cols])\n",
    "\n",
    "print(f\"there are {Xw.shape[1]} features in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f3a58",
   "metadata": {},
   "source": [
    "We augmented the dataset by adding a very large amount of features created from the yields time series. however, many of these features are not informative so we need to remove them before training our model. \n",
    "\n",
    "We'll filter features by keeping only those with a mutual information score above than a given threshold. We'll create several datasets of features containing features filtered for the thresholds 0.03, 0.035, 0.04, 0.05 and train models on these specific datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a09ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:42<02:07, 42.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we removed 464 features in the weekly dataset for threshold 0.03\n",
      "Number of variables in the dataset with MI threshold 0.03: 274\n",
      "Macro and market variables in the dataset with MI threshold 0.03: ['UNRATE', 'USGOVT', 'SRVPRD', 'MANEMP', 'USTPU', 'M2SL', 'USCONS', 'PERMIT', 'IRLTLT01FRM156N', 'CURRCIR', 'GFDEGDQ188S', 'DNDGRG3M086SBEA', 'IRLTLT01DEM156N', 'CPITRNSL', 'DTCTHFNM', 'FGDEF', 'IRLTLT01JPM156N', 'IRLTLT01AUM156N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [01:34<01:35, 47.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we removed 559 features in the weekly dataset for threshold 0.035\n",
      "Number of variables in the dataset with MI threshold 0.035: 179\n",
      "Macro and market variables in the dataset with MI threshold 0.035: ['USTPU', 'TOTRESNS', 'UEMP5TO14', 'USCONS', 'IRLTLT01CAM156N', 'IRLTLT01DEM156N', 'IRLTLT01AUM156N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [02:16<00:45, 45.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we removed 639 features in the weekly dataset for threshold 0.04\n",
      "Number of variables in the dataset with MI threshold 0.04: 99\n",
      "Macro and market variables in the dataset with MI threshold 0.04: ['SRVPRD', 'MTSDS133FMS', 'USTPU', 'GFDEGDQ188S', 'IRLTLT01DEM156N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:53<00:00, 43.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we removed 698 features in the weekly dataset for threshold 0.05\n",
      "Number of variables in the dataset with MI threshold 0.05: 40\n",
      "Macro and market variables in the dataset with MI threshold 0.05: ['MTSDS133FMS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "initial_number_of_features = Xw.shape[1]\n",
    "\n",
    "threshold_list = [0.03,0.035,0.04,0.05]\n",
    "\n",
    "datasets = {t:pd.DataFrame() for t in threshold_list}\n",
    "\n",
    "for threshold_mi in tqdm(threshold_list): \n",
    "    selected_features_w = set()\n",
    "    for col in Yw.columns:\n",
    "        mi = mutual_info_classif(Xw, Yw[col])\n",
    "        top_features_i = Xw.columns[mi > threshold_mi]  \n",
    "        selected_features_w.update(top_features_i)\n",
    "\n",
    "    datasets[threshold_mi] = Xw[list(selected_features_w)]\n",
    "\n",
    "    print(f'we removed {initial_number_of_features-len(selected_features_w)} features in the weekly dataset for threshold {threshold_mi}')\n",
    "    print(f'Number of variables in the dataset with MI threshold {threshold_mi}:',datasets[threshold_mi].shape[1])\n",
    "    print(f'Macro and market variables in the dataset with MI threshold {threshold_mi}:', [col for col in datasets[threshold_mi].columns if 'DGS' not in col])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4c612",
   "metadata": {},
   "source": [
    "Notice that many of the macro and market variables that we extracted from the FRED website do not share much mutual information with the target since many of these variables are removed with the threshold we used. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819007b",
   "metadata": {},
   "source": [
    "### B) Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c619595",
   "metadata": {},
   "source": [
    "We define the following pipelines for our logistic regression models.\n",
    "We train our model on a rolling window of 15 years of data (with cross validation without leakage of future information) and then predict the 4 next weeks. We then update the rolling window, train another model, predict the 4 next weekds and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c291d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52 * 15\n",
    "window_pred = 4\n",
    "\n",
    "alphas = np.logspace(-5, 2, 30)\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', MultiOutputClassifier(\n",
    "        LogisticRegressionCV(\n",
    "            penalty='l2',\n",
    "            cv=tscv,\n",
    "            Cs=alphas,\n",
    "            fit_intercept=False,\n",
    "            scoring='accuracy',\n",
    "            max_iter=5000)))\n",
    "])\n",
    "\n",
    "pipepca = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.99)), \n",
    "    ('logreg', MultiOutputClassifier(\n",
    "        LogisticRegressionCV(\n",
    "            penalty='l2',\n",
    "            cv=tscv,\n",
    "            Cs=alphas,\n",
    "            fit_intercept=False,\n",
    "            scoring='accuracy',\n",
    "            max_iter=5000)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0e368",
   "metadata": {},
   "source": [
    "We train logistic regression models for the 4 datasets containing features with mutual information larger than 0.03, 0.035, 0.04, 0.05 respectively. Then we save the results in datasets. \n",
    "\n",
    "The dataset with variables with mutual information > 0.03 contains 266 features, which is very high compared to the numer of points in the training datasets (52*15 lines), so we'll also train a model that performs a PCA before applying the logistic regression in order to reduce the number of features and see if it can improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model on dataset with features with mutual information above 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [35:56<00:00, 27.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.03 is:\n",
      "Y_DGS1MO    0.607595\n",
      "Y_DGS3MO    0.661392\n",
      "Y_DGS6MO    0.636076\n",
      "Y_DGS1      0.591772\n",
      "Y_DGS2      0.582278\n",
      "Y_DGS3      0.563291\n",
      "Y_DGS5      0.525316\n",
      "Y_DGS7      0.496835\n",
      "Y_DGS10     0.487342\n",
      "Y_DGS20     0.509494\n",
      "Y_DGS30     0.515823\n",
      "dtype: float64\n",
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.03 and PCA is:\n",
      "Y_DGS1MO    0.620253\n",
      "Y_DGS3MO    0.667722\n",
      "Y_DGS6MO    0.651899\n",
      "Y_DGS1      0.588608\n",
      "Y_DGS2      0.579114\n",
      "Y_DGS3      0.537975\n",
      "Y_DGS5      0.534810\n",
      "Y_DGS7      0.537975\n",
      "Y_DGS10     0.496835\n",
      "Y_DGS20     0.512658\n",
      "Y_DGS30     0.490506\n",
      "dtype: float64\n",
      "training model on dataset with features with mutual information above 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [24:58<00:00, 18.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.035 is:\n",
      "Y_DGS1MO    0.613924\n",
      "Y_DGS3MO    0.702532\n",
      "Y_DGS6MO    0.645570\n",
      "Y_DGS1      0.544304\n",
      "Y_DGS2      0.515823\n",
      "Y_DGS3      0.556962\n",
      "Y_DGS5      0.509494\n",
      "Y_DGS7      0.474684\n",
      "Y_DGS10     0.443038\n",
      "Y_DGS20     0.487342\n",
      "Y_DGS30     0.465190\n",
      "dtype: float64\n",
      "training model on dataset with features with mutual information above 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [17:00<00:00, 12.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.04 is:\n",
      "Y_DGS1MO    0.636076\n",
      "Y_DGS3MO    0.702532\n",
      "Y_DGS6MO    0.686709\n",
      "Y_DGS1      0.598101\n",
      "Y_DGS2      0.525316\n",
      "Y_DGS3      0.518987\n",
      "Y_DGS5      0.525316\n",
      "Y_DGS7      0.477848\n",
      "Y_DGS10     0.493671\n",
      "Y_DGS20     0.471519\n",
      "Y_DGS30     0.474684\n",
      "dtype: float64\n",
      "training model on dataset with features with mutual information above 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [07:56<00:00,  6.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.05 is:\n",
      "Y_DGS1MO    0.645570\n",
      "Y_DGS3MO    0.686709\n",
      "Y_DGS6MO    0.629747\n",
      "Y_DGS1      0.598101\n",
      "Y_DGS2      0.550633\n",
      "Y_DGS3      0.531646\n",
      "Y_DGS5      0.512658\n",
      "Y_DGS7      0.471519\n",
      "Y_DGS10     0.484177\n",
      "Y_DGS20     0.458861\n",
      "Y_DGS30     0.471519\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for threshold in threshold_list:\n",
    "\n",
    "    print(f'training model on dataset with features with mutual information above {threshold}')\n",
    "\n",
    "    Xw = datasets[threshold]\n",
    "\n",
    "    # for the dataset containing features with mutual information above 0.03:\n",
    "    # we'll train our logistic model with and without PCA since there are many features in this dataset\n",
    "    if threshold == 0.03:\n",
    "\n",
    "\n",
    "        accuraciesl2 = {col: [] for col in Yw.columns}\n",
    "        accuraciesl2pca = {col: [] for col in Yw.columns}\n",
    "        alphal2 = {col: [] for col in Yw.columns}\n",
    "        alphal2pca = {col: [] for col in Yw.columns}\n",
    "        feature_importancel2 = {col: [] for col in Yw.columns}\n",
    "        feature_importancel2pca = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_predl2 = []\n",
    "        y_predl2pca = []\n",
    "\n",
    "\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "        \n",
    "            pipe.fit(Xw_train, Yw_train)\n",
    "            pipepca.fit(Xw_train, Yw_train)\n",
    "\n",
    "\n",
    "            Yw_pred = pipe.predict(Xw_test)\n",
    "            Yw_predpca = pipepca.predict(Xw_test)\n",
    "\n",
    "            y_predl2.append(Yw_pred)\n",
    "            y_predl2pca.append(Yw_predpca)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuraciesl2[col].append(acc)\n",
    "\n",
    "                acc = accuracy_score(Yw_test[col], Yw_predpca[:, i])\n",
    "                accuraciesl2pca[col].append(acc)\n",
    "\n",
    "                # parameters chosen\n",
    "                best_C = pipe.named_steps['logreg'].estimators_[i].C_[0]\n",
    "                alphal2[col].append(best_C)\n",
    "\n",
    "                best_C = pipepca.named_steps['logreg'].estimators_[i].C_[0]\n",
    "                alphal2pca[col].append(best_C)\n",
    "\n",
    "                # feature importance\n",
    "                coefs = np.abs(pipe.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "                feature_importancel2[col].append(coefs)\n",
    "\n",
    "                coefs = np.abs(pipepca.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "                feature_importancel2pca[col].append(coefs)\n",
    "\n",
    "        ### saving the results\n",
    "        acc = pd.DataFrame(accuraciesl2,columns = Yw.columns)\n",
    "        params = pd.DataFrame(alphal2, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importancel2, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_predl2).reshape(-1, np.array(y_predl2).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies logistic regression, 15y train test.csv')\n",
    "        params.to_csv('results of models/params logistic regression, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance logistic regression, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast logistic regression, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values logistic regression, 15y train test.csv')\n",
    "\n",
    "        acc = pd.DataFrame(accuraciesl2pca,columns = Yw.columns)\n",
    "        params = pd.DataFrame(alphal2pca, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importancel2pca, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_predl2pca).reshape(-1, np.array(y_predl2pca).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} and PCA is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies logistic regression pca, 15y train test.csv')\n",
    "        params.to_csv('results of models/params logistic regression pca, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance logistic regression pca, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast logistic regression pca, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values logistic regression pca, 15y train test.csv')\n",
    "\n",
    "    #for other datasets, we train models without applying a PCA before. \n",
    "    else: \n",
    "\n",
    "\n",
    "        accuraciesl2 = {col: [] for col in Yw.columns}\n",
    "        alphal2 = {col: [] for col in Yw.columns}\n",
    "        feature_importancel2 = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_predl2 = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            pipe.fit(Xw_train, Yw_train)\n",
    "\n",
    "            Yw_pred = pipe.predict(Xw_test)\n",
    "\n",
    "            y_predl2.append(Yw_pred)\n",
    "\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuraciesl2[col].append(acc)\n",
    "\n",
    "\n",
    "                # alpha optimal choisi\n",
    "                best_C = pipe.named_steps['logreg'].estimators_[i].C_[0]\n",
    "                alphal2[col].append(best_C)\n",
    "\n",
    "                # importance des features = moyenne absolue des coefficients\n",
    "                coefs = np.abs(pipe.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "                feature_importancel2[col].append(coefs)\n",
    "\n",
    "        acc = pd.DataFrame(accuraciesl2,columns = Yw.columns)\n",
    "        params = pd.DataFrame(alphal2, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importancel2, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_predl2).reshape(-1, np.array(y_predl2).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv(f'results of models/accuracies logistic regression, MI {threshold}, 15y train test.csv')\n",
    "        params.to_csv(f'results of models/params logistic regression, MI {threshold}, 15y train test.csv')\n",
    "        feature_imp.to_csv(f'results of models/feature importance logistic regression, MI {threshold}, 15y train test.csv')\n",
    "        ypred.to_csv(f'results of models/forecast logistic regression, MI {threshold}, 15y train test.csv')\n",
    "        ytrue.to_csv(f'results of models/true values logistic regression, MI {threshold}, 15y train test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b29dd",
   "metadata": {},
   "source": [
    "## C) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9a75c",
   "metadata": {},
   "source": [
    "We'll now train XGboost models to see whether it can capture non linearities in the data and improve accuracy of out-of-sample predictions. Once again, we'll train some models on the 4 datasets that we created. \n",
    "\n",
    "For the first dataset (with features with a MI>0.03), we'll also train a model that performs a PCA to reduce the number of features before applying XGboost. \n",
    "\n",
    "The pipelines that we'll use are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2777039",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52 * 15\n",
    "window_pred = 4\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "\n",
    "# parameters to test in cross validation \n",
    "param_grid = {\n",
    " 'xgb__estimator__n_estimators': [100, 200],\n",
    " 'xgb__estimator__learning_rate': [0.01, 0.05],\n",
    " 'xgb__estimator__max_depth': [4,7],\n",
    " 'xgb__estimator__subsample': [0.5, 0.7],\n",
    " 'xgb__estimator__colsample_bytree': [0.4, 0.8],\n",
    " 'xgb__estimator__min_child_weight': [5, 10],\n",
    " 'xgb__estimator__reg_alpha': [0.5, 1.0],\n",
    " 'xgb__estimator__reg_lambda': [5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pipeline without PCA \n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', MultiOutputClassifier(\n",
    "        XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "#pipeline with PCA \n",
    "pipepca = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca',PCA(n_components = 0.99)),\n",
    "    ('xgb', MultiOutputClassifier(\n",
    "        XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "#and we'll use gridsearchCV to cross validate the model:\n",
    "GridSearchCV(pipepca, #or pipe\n",
    "            param_grid,\n",
    "            cv=tscv,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ace69",
   "metadata": {},
   "source": [
    "We now train XGBoost models on the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e61701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_list:\n",
    "\n",
    "    print(f'training model on dataset with features with mutual information above {threshold}')\n",
    "\n",
    "    Xw = datasets[threshold]\n",
    "\n",
    "    # for the dataset containing features with mutual information above 0.03:\n",
    "    # we'll train our xgboost model with and without PCA since there are many features in this dataset\n",
    "    if threshold == 0.03:\n",
    "\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies xgboost, 15y train test.csv')\n",
    "        params.to_csv('results of models/params xgboost, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance xgboost, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast xgboost, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values xgboost, 15y train test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #### Now we do the same training but this time we add the PCA in the pipeline before training the model\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "\n",
    "        \n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipepca,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} and PCA is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies xgboost, pca, 15y train test.csv')\n",
    "        params.to_csv('results of models/params xgboost, pca, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance xgboost, pca, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast xgboost, pca, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values xgboost, pca, 15y train test.csv')\n",
    "    \n",
    "\n",
    "    # for other datasets with larger mutual information threshold, we don't apply PCA and train the model directly \n",
    "    else:\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "        \n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv(f'results of models/accuracies xgboost, MI {threshold}, 15y train test.csv')\n",
    "        params.to_csv(f'results of models/params xgboost, MI {threshold}, 15y train test.csv')\n",
    "        feature_imp.to_csv(f'results of models/feature importance xgboost, MI {threshold}, 15y train test.csv')\n",
    "        ypred.to_csv(f'results of models/forecast xgboost, MI {threshold}, 15y train test.csv')\n",
    "        ytrue.to_csv(f'results of models/true values xgboost, MI {threshold}, 15y train test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02f0b8",
   "metadata": {},
   "source": [
    "## D) Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea97c1",
   "metadata": {},
   "source": [
    "We'll proceed as for the logistic regression and XGBoost models when training random forests. The pipelines (with and without PCA) are defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb4ee62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52 * 15\n",
    "window_pred = 4\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'rf__estimator__n_estimators': [150],\n",
    "    'rf__estimator__max_depth': [4,7],\n",
    "    'rf__estimator__min_samples_leaf': [5,10]\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', MultiOutputClassifier(\n",
    "        RandomForestClassifier(\n",
    "            n_jobs=-1,\n",
    "            random_state = 42\n",
    "            )))\n",
    "])\n",
    "\n",
    "pipepca = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.99)),\n",
    "    ('rf', MultiOutputClassifier(\n",
    "        RandomForestClassifier(\n",
    "            n_jobs=-1,\n",
    "            random_state = 42\n",
    "            )))\n",
    "])\n",
    "\n",
    "\n",
    "#we will cross validate the model the following way: \n",
    "grid = GridSearchCV(pipe,  #or pipepca\n",
    "                        param_grid,\n",
    "                        cv = tscv,\n",
    "                        scoring = 'accuracy',\n",
    "                        n_jobs=-1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_list:\n",
    "\n",
    "    print(f'training model on dataset with features with mutual information above {threshold}')\n",
    "\n",
    "    Xw = datasets[threshold]\n",
    "\n",
    "    # for the dataset containing features with mutual information above 0.03:\n",
    "    # we'll train our random forest model with and without PCA since there are many features in this dataset\n",
    "    if threshold == 0.03:\n",
    "\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "           \n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['rf'].estimators_[i]  \n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies random forest, 15y train test.csv')\n",
    "        params.to_csv('results of models/params random forest, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance random forest, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast random forest, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values random forest, 15y train test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #### Now we do the same training but this time we add the PCA in the pipeline before training the model\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "\n",
    "        \n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipepca,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['rf'].estimators_[i]   \n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} and PCA is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies random forest, pca, 15y train test.csv')\n",
    "        params.to_csv('results of models/params random forest, pca, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance random forest, pca, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast random forest, pca, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values random forest, pca, 15y train test.csv')\n",
    "    \n",
    "\n",
    "    # for other datasets with larger mutual information threshold, we don't apply PCA and train the model directly \n",
    "    else:\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "            \n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['rf'].estimators_[i]  \n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "        \n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv(f'results of models/accuracies random forest, MI {threshold}, 15y train test.csv')\n",
    "        params.to_csv(f'results of models/params random forest, MI {threshold}, 15y train test.csv')\n",
    "        feature_imp.to_csv(f'results of models/feature importance random forest, MI {threshold}, 15y train test.csv')\n",
    "        ypred.to_csv(f'results of models/forecast random forest, MI {threshold}, 15y train test.csv')\n",
    "        ytrue.to_csv(f'results of models/true values random forest, MI {threshold}, 15y train test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64796f97",
   "metadata": {},
   "source": [
    "# IV - Models analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54917234",
   "metadata": {},
   "source": [
    "## A- McNemar tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0edbb1",
   "metadata": {},
   "source": [
    "In what follows, we will perform a McNemar test to ensure that our forecast performance is statistically significant. To do this, we will compare the forecast of each of our models to the \"majority class classifier\", which always predict the most frequent class. For each of the 79 training datasets, we'll build this majority class classifier and then compare its forecast to those of our models through a McNemar test to see whether our models are statistically overperforming this \"naive\" benchmark and are effectively learning something from the features. \n",
    "\n",
    "We build the majority class classifier below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0bdcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52 * 15\n",
    "window_pred = 4\n",
    "\n",
    "majority_class_classifier = {col : [] for col in Yw.columns}\n",
    "\n",
    "for start in range(0, len(Xw) - window_train - window_pred + 1, window_pred):\n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    for col in Yw.columns:\n",
    "        Yw_train = Yw.iloc[start:end_train][col]\n",
    "        if Yw_train.mean()<0.5:\n",
    "            majority_class_classifier[col].extend([0,0,0,0])\n",
    "        else:\n",
    "            majority_class_classifier[col].extend([1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b750cb9",
   "metadata": {},
   "source": [
    "The average out-of-sample accuracy of this majority class classifier over the 79 rolling windows is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "dea81854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y_DGS1MO    0.588608\n",
       "Y_DGS3MO    0.553797\n",
       "Y_DGS6MO    0.503165\n",
       "Y_DGS1      0.556962\n",
       "Y_DGS2      0.525316\n",
       "Y_DGS3      0.509494\n",
       "Y_DGS5      0.506329\n",
       "Y_DGS7      0.503165\n",
       "Y_DGS10     0.506329\n",
       "Y_DGS20     0.522152\n",
       "Y_DGS30     0.512658\n",
       "dtype: float64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_class_classifier = pd.DataFrame(majority_class_classifier, index = Yw.iloc[780:Yw.shape[0]-1].index)\n",
    "a = (majority_class_classifier == Yw.iloc[780:Yw.shape[0]-1]).astype(int).mean()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0adfa",
   "metadata": {},
   "source": [
    "We can now run the McNemar test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "66c750b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "forecast = {\n",
    "            \"lr 0.03\":pd.read_csv(\"results of models/forecast logistic regression, 15y train test.csv\",index_col=0),\n",
    "             \"lr 0.03 pca\":pd.read_csv(\"results of models/forecast logistic regression pca, 15y train test.csv\", index_col=0),\n",
    "             \"lr 0.035\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.035, 15y train test.csv\", index_col=0),\n",
    "             \"lr 0.04\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.04, 15y train test.csv\", index_col=0),\n",
    "             \"lr 0.05\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.05, 15y train test.csv\", index_col=0),\n",
    "            \"rf 0.03\":pd.read_csv(\"results of models/forecast random forest, no pca, 15y train test.csv\", index_col=0),\n",
    "             \"rf 0.03 pca\":pd.read_csv(\"results of models/forecast random forest pca, 15y train test.csv\", index_col=0),\n",
    "             \"rf 0.035\":pd.read_csv(\"results of models/forecast random forest, MI 0.035, 15y train test.csv\", index_col=0),\n",
    "             \"rf 0.04\":pd.read_csv(\"results of models/forecast random forest, MI 0.04, 15y train test.csv\", index_col=0),\n",
    "             \"rf 0.05\":pd.read_csv(\"results of models/forecast random forest, MI 0.05, 15y train test.csv\", index_col=0),\n",
    "             \"xg 0.03\":pd.read_csv(\"results of models/forecast xgboost, 15y train test.csv\", index_col=0),\n",
    "             \"xg 0.035\":pd.read_csv(\"results of models/forecast xgboost, MI 0.035, 15y train test.csv\",index_col=0),\n",
    "             \"xg 0.04\":pd.read_csv(\"results of models/forecast xgboost, MI 0.04, 15y train test.csv\", index_col=0),\n",
    "             \"xg 0.05\":pd.read_csv(\"results of models/forecast xgboost, MI 0.05, 15y train test.csv\", index_col=0),\n",
    "             'LSTM 0.02': (pd.read_csv(\"results of models/forecast_LSTM_cls_12864128_0.02MI_2patience_52LB_evalsscores.csv\",index_col=0)>0.05).astype(int)\n",
    "             }\n",
    "\n",
    "pvalues = pd.DataFrame(index = forecast.keys(), columns = majority_class_classifier.columns)\n",
    "\n",
    "for key in forecast.keys():\n",
    "\n",
    "    for col in majority_class_classifier.columns: \n",
    "\n",
    "        y_pred = forecast[key][col]\n",
    "        y_benchmark = majority_class_classifier[col]\n",
    "        y_true = Yw.iloc[780:Yw.shape[0]-1][col]\n",
    "        # McNemar test\n",
    "        correct_real = y_pred == y_true\n",
    "        correct_benchmark = y_benchmark == y_true\n",
    "        table = confusion_matrix(correct_real, correct_benchmark)\n",
    "        result = mcnemar(table, exact=False, correction=True)\n",
    "        pvalues.loc[key,col] = result.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0b697",
   "metadata": {},
   "source": [
    "Below are the p-value of McNemar test for each of the models trained, for each yield in the yield curve. The $H_0$ hypothesis of this test is : \"The model has no better error rate than the majority class classifier\". \n",
    "\n",
    "Each name of column of this dataframe is in 3 parts:\n",
    "- lr or rf or xg or lstm depending on whether the model is a logistic regression, random forest, xg boost or lstm model, \n",
    "- 0.03 or 0.035 or 0.04 or 0.05 depending on the dataset on which the model was trained. As a reminder, this number represents the threshold of mutual information. For instance, for the dataset labelled as 0.03 we kept only features with a mutual information shared with the targets above 0.03.\n",
    "- pca or \" \" depending on whether we applied a PCA to reduce dimensionality before training the model. \n",
    "\n",
    "For instance, the first cell of the model is associated to the logistic regression model trained on the dataset of features with mutual information above 0.03 and on the 1 month yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "58e3ec36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-value of McNemar test for lr 0.03</th>\n",
       "      <th>p-value of McNemar test for lr 0.03 pca</th>\n",
       "      <th>p-value of McNemar test for lr 0.035</th>\n",
       "      <th>p-value of McNemar test for lr 0.04</th>\n",
       "      <th>p-value of McNemar test for lr 0.05</th>\n",
       "      <th>p-value of McNemar test for rf 0.03</th>\n",
       "      <th>p-value of McNemar test for rf 0.03 pca</th>\n",
       "      <th>p-value of McNemar test for rf 0.035</th>\n",
       "      <th>p-value of McNemar test for rf 0.04</th>\n",
       "      <th>p-value of McNemar test for rf 0.05</th>\n",
       "      <th>p-value of McNemar test for xg 0.03</th>\n",
       "      <th>p-value of McNemar test for xg 0.035</th>\n",
       "      <th>p-value of McNemar test for xg 0.04</th>\n",
       "      <th>p-value of McNemar test for xg 0.05</th>\n",
       "      <th>p-value of McNemar test for LSTM 0.02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>0.860223</td>\n",
       "      <td>0.656005</td>\n",
       "      <td>0.355226</td>\n",
       "      <td>0.187836</td>\n",
       "      <td>0.330915</td>\n",
       "      <td>0.07544</td>\n",
       "      <td>0.417304</td>\n",
       "      <td>0.128885</td>\n",
       "      <td>0.082662</td>\n",
       "      <td>0.042826</td>\n",
       "      <td>0.05678</td>\n",
       "      <td>0.267938</td>\n",
       "      <td>0.374003</td>\n",
       "      <td>0.220671</td>\n",
       "      <td>0.001975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.00922</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.063397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.050962</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.689995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>0.811364</td>\n",
       "      <td>0.803916</td>\n",
       "      <td>0.098181</td>\n",
       "      <td>0.153438</td>\n",
       "      <td>0.457304</td>\n",
       "      <td>0.363278</td>\n",
       "      <td>0.331975</td>\n",
       "      <td>0.41177</td>\n",
       "      <td>0.276082</td>\n",
       "      <td>0.163604</td>\n",
       "      <td>0.838256</td>\n",
       "      <td>0.095293</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.844519</td>\n",
       "      <td>0.048964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2y yield</th>\n",
       "      <td>0.43437</td>\n",
       "      <td>0.192768</td>\n",
       "      <td>0.197479</td>\n",
       "      <td>0.720985</td>\n",
       "      <td>0.564715</td>\n",
       "      <td>0.33815</td>\n",
       "      <td>0.606905</td>\n",
       "      <td>0.298618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538167</td>\n",
       "      <td>0.863832</td>\n",
       "      <td>0.748774</td>\n",
       "      <td>0.877371</td>\n",
       "      <td>0.863832</td>\n",
       "      <td>0.398772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3y yield</th>\n",
       "      <td>0.419921</td>\n",
       "      <td>0.407016</td>\n",
       "      <td>0.593518</td>\n",
       "      <td>0.462209</td>\n",
       "      <td>0.61157</td>\n",
       "      <td>0.515735</td>\n",
       "      <td>0.589639</td>\n",
       "      <td>0.639575</td>\n",
       "      <td>0.302895</td>\n",
       "      <td>0.135697</td>\n",
       "      <td>0.719438</td>\n",
       "      <td>0.163734</td>\n",
       "      <td>0.498962</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>0.778502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5y yield</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260798</td>\n",
       "      <td>0.347262</td>\n",
       "      <td>0.452264</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.307101</td>\n",
       "      <td>0.07314</td>\n",
       "      <td>0.930111</td>\n",
       "      <td>0.855725</td>\n",
       "      <td>0.850764</td>\n",
       "      <td>0.470486</td>\n",
       "      <td>0.748774</td>\n",
       "      <td>0.770493</td>\n",
       "      <td>0.441418</td>\n",
       "      <td>0.865983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7y yield</th>\n",
       "      <td>0.272832</td>\n",
       "      <td>0.525793</td>\n",
       "      <td>0.487453</td>\n",
       "      <td>0.65738</td>\n",
       "      <td>0.943628</td>\n",
       "      <td>0.34254</td>\n",
       "      <td>0.200994</td>\n",
       "      <td>0.846687</td>\n",
       "      <td>0.658531</td>\n",
       "      <td>0.187836</td>\n",
       "      <td>0.626496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10y yield</th>\n",
       "      <td>0.47399</td>\n",
       "      <td>0.751076</td>\n",
       "      <td>0.636309</td>\n",
       "      <td>0.605822</td>\n",
       "      <td>0.607766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66062</td>\n",
       "      <td>0.594032</td>\n",
       "      <td>0.921127</td>\n",
       "      <td>0.470298</td>\n",
       "      <td>0.823063</td>\n",
       "      <td>0.453255</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.605577</td>\n",
       "      <td>0.865983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20y yield</th>\n",
       "      <td>0.690793</td>\n",
       "      <td>0.810181</td>\n",
       "      <td>0.818022</td>\n",
       "      <td>0.583588</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.299758</td>\n",
       "      <td>0.830218</td>\n",
       "      <td>0.152661</td>\n",
       "      <td>0.395092</td>\n",
       "      <td>0.778729</td>\n",
       "      <td>0.422678</td>\n",
       "      <td>0.75183</td>\n",
       "      <td>0.19043</td>\n",
       "      <td>0.371093</td>\n",
       "      <td>0.464592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30y yield</th>\n",
       "      <td>0.824966</td>\n",
       "      <td>0.941549</td>\n",
       "      <td>0.558536</td>\n",
       "      <td>0.697936</td>\n",
       "      <td>0.263786</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>0.606057</td>\n",
       "      <td>0.223391</td>\n",
       "      <td>0.597312</td>\n",
       "      <td>0.672604</td>\n",
       "      <td>0.4795</td>\n",
       "      <td>0.813664</td>\n",
       "      <td>0.382733</td>\n",
       "      <td>0.546494</td>\n",
       "      <td>0.693743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          p-value of McNemar test for lr 0.03  \\\n",
       "1m yield                             0.860223   \n",
       "3m yield                             0.000625   \n",
       "6m yield                             0.000373   \n",
       "1y yield                             0.811364   \n",
       "2y yield                              0.43437   \n",
       "3y yield                             0.419921   \n",
       "5y yield                                  1.0   \n",
       "7y yield                             0.272832   \n",
       "10y yield                             0.47399   \n",
       "20y yield                            0.690793   \n",
       "30y yield                            0.824966   \n",
       "\n",
       "          p-value of McNemar test for lr 0.03 pca  \\\n",
       "1m yield                                 0.656005   \n",
       "3m yield                                 0.001074   \n",
       "6m yield                                 0.000567   \n",
       "1y yield                                 0.803916   \n",
       "2y yield                                 0.192768   \n",
       "3y yield                                 0.407016   \n",
       "5y yield                                 0.260798   \n",
       "7y yield                                 0.525793   \n",
       "10y yield                                0.751076   \n",
       "20y yield                                0.810181   \n",
       "30y yield                                0.941549   \n",
       "\n",
       "          p-value of McNemar test for lr 0.035  \\\n",
       "1m yield                              0.355226   \n",
       "3m yield                              0.000006   \n",
       "6m yield                              0.000003   \n",
       "1y yield                              0.098181   \n",
       "2y yield                              0.197479   \n",
       "3y yield                              0.593518   \n",
       "5y yield                              0.347262   \n",
       "7y yield                              0.487453   \n",
       "10y yield                             0.636309   \n",
       "20y yield                             0.818022   \n",
       "30y yield                             0.558536   \n",
       "\n",
       "          p-value of McNemar test for lr 0.04  \\\n",
       "1m yield                             0.187836   \n",
       "3m yield                             0.000008   \n",
       "6m yield                             0.000182   \n",
       "1y yield                             0.153438   \n",
       "2y yield                             0.720985   \n",
       "3y yield                             0.462209   \n",
       "5y yield                             0.452264   \n",
       "7y yield                              0.65738   \n",
       "10y yield                            0.605822   \n",
       "20y yield                            0.583588   \n",
       "30y yield                            0.697936   \n",
       "\n",
       "          p-value of McNemar test for lr 0.05  \\\n",
       "1m yield                             0.330915   \n",
       "3m yield                             0.012725   \n",
       "6m yield                             0.000802   \n",
       "1y yield                             0.457304   \n",
       "2y yield                             0.564715   \n",
       "3y yield                              0.61157   \n",
       "5y yield                             0.882466   \n",
       "7y yield                             0.943628   \n",
       "10y yield                            0.607766   \n",
       "20y yield                            0.059948   \n",
       "30y yield                            0.263786   \n",
       "\n",
       "          p-value of McNemar test for rf 0.03  \\\n",
       "1m yield                              0.07544   \n",
       "3m yield                             0.000018   \n",
       "6m yield                             0.000003   \n",
       "1y yield                             0.363278   \n",
       "2y yield                              0.33815   \n",
       "3y yield                             0.515735   \n",
       "5y yield                             0.307101   \n",
       "7y yield                              0.34254   \n",
       "10y yield                                 1.0   \n",
       "20y yield                            0.299758   \n",
       "30y yield                            0.329114   \n",
       "\n",
       "          p-value of McNemar test for rf 0.03 pca  \\\n",
       "1m yield                                 0.417304   \n",
       "3m yield                                  0.00922   \n",
       "6m yield                                 0.050962   \n",
       "1y yield                                 0.331975   \n",
       "2y yield                                 0.606905   \n",
       "3y yield                                 0.589639   \n",
       "5y yield                                  0.07314   \n",
       "7y yield                                 0.200994   \n",
       "10y yield                                 0.66062   \n",
       "20y yield                                0.830218   \n",
       "30y yield                                0.606057   \n",
       "\n",
       "          p-value of McNemar test for rf 0.035  \\\n",
       "1m yield                              0.128885   \n",
       "3m yield                              0.000018   \n",
       "6m yield                              0.000005   \n",
       "1y yield                               0.41177   \n",
       "2y yield                              0.298618   \n",
       "3y yield                              0.639575   \n",
       "5y yield                              0.930111   \n",
       "7y yield                              0.846687   \n",
       "10y yield                             0.594032   \n",
       "20y yield                             0.152661   \n",
       "30y yield                             0.223391   \n",
       "\n",
       "          p-value of McNemar test for rf 0.04  \\\n",
       "1m yield                             0.082662   \n",
       "3m yield                             0.000007   \n",
       "6m yield                             0.000002   \n",
       "1y yield                             0.276082   \n",
       "2y yield                                  1.0   \n",
       "3y yield                             0.302895   \n",
       "5y yield                             0.855725   \n",
       "7y yield                             0.658531   \n",
       "10y yield                            0.921127   \n",
       "20y yield                            0.395092   \n",
       "30y yield                            0.597312   \n",
       "\n",
       "          p-value of McNemar test for rf 0.05  \\\n",
       "1m yield                             0.042826   \n",
       "3m yield                             0.000067   \n",
       "6m yield                             0.000002   \n",
       "1y yield                             0.163604   \n",
       "2y yield                             0.538167   \n",
       "3y yield                             0.135697   \n",
       "5y yield                             0.850764   \n",
       "7y yield                             0.187836   \n",
       "10y yield                            0.470298   \n",
       "20y yield                            0.778729   \n",
       "30y yield                            0.672604   \n",
       "\n",
       "          p-value of McNemar test for xg 0.03  \\\n",
       "1m yield                              0.05678   \n",
       "3m yield                             0.000114   \n",
       "6m yield                             0.000009   \n",
       "1y yield                             0.838256   \n",
       "2y yield                             0.863832   \n",
       "3y yield                             0.719438   \n",
       "5y yield                             0.470486   \n",
       "7y yield                             0.626496   \n",
       "10y yield                            0.823063   \n",
       "20y yield                            0.422678   \n",
       "30y yield                              0.4795   \n",
       "\n",
       "          p-value of McNemar test for xg 0.035  \\\n",
       "1m yield                              0.267938   \n",
       "3m yield                              0.000041   \n",
       "6m yield                              0.000001   \n",
       "1y yield                              0.095293   \n",
       "2y yield                              0.748774   \n",
       "3y yield                              0.163734   \n",
       "5y yield                              0.748774   \n",
       "7y yield                                   1.0   \n",
       "10y yield                             0.453255   \n",
       "20y yield                              0.75183   \n",
       "30y yield                             0.813664   \n",
       "\n",
       "          p-value of McNemar test for xg 0.04  \\\n",
       "1m yield                             0.374003   \n",
       "3m yield                             0.000049   \n",
       "6m yield                             0.000001   \n",
       "1y yield                             0.037635   \n",
       "2y yield                             0.877371   \n",
       "3y yield                             0.498962   \n",
       "5y yield                             0.770493   \n",
       "7y yield                             0.877371   \n",
       "10y yield                            0.037635   \n",
       "20y yield                             0.19043   \n",
       "30y yield                            0.382733   \n",
       "\n",
       "          p-value of McNemar test for xg 0.05  \\\n",
       "1m yield                             0.220671   \n",
       "3m yield                             0.000209   \n",
       "6m yield                             0.000018   \n",
       "1y yield                             0.844519   \n",
       "2y yield                             0.863832   \n",
       "3y yield                             0.689157   \n",
       "5y yield                             0.441418   \n",
       "7y yield                                  1.0   \n",
       "10y yield                            0.605577   \n",
       "20y yield                            0.371093   \n",
       "30y yield                            0.546494   \n",
       "\n",
       "          p-value of McNemar test for LSTM 0.02  \n",
       "1m yield                               0.001975  \n",
       "3m yield                               0.063397  \n",
       "6m yield                               0.689995  \n",
       "1y yield                               0.048964  \n",
       "2y yield                               0.398772  \n",
       "3y yield                               0.778502  \n",
       "5y yield                               0.865983  \n",
       "7y yield                               0.955139  \n",
       "10y yield                              0.865983  \n",
       "20y yield                              0.464592  \n",
       "30y yield                              0.693743  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues = pvalues.T\n",
    "pvalues = pvalues.add_prefix(\"p-value of McNemar test for \")\n",
    "pvalues.index = [\"1m yield\",\"3m yield\",\"6m yield\",\"1y yield\",\"2y yield\",\"3y yield\",\"5y yield\",\"7y yield\",\"10y yield\",\"20y yield\",\"30y yield\"]\n",
    "pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d5b80",
   "metadata": {},
   "source": [
    "Remark: we had to remove the XGboost model with PCA because it only predicted some zeros, which resulted in errors when running the test. \n",
    "\n",
    "The models with a performance significatively better than the constant benchmark classifier (pvalue <0.1) are listed below. There is a 1 in the cell if the model forecasting power is statistically significant and a 0 otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "91100c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr 0.03</th>\n",
       "      <th>lr 0.03 pca</th>\n",
       "      <th>lr 0.035</th>\n",
       "      <th>lr 0.04</th>\n",
       "      <th>lr 0.05</th>\n",
       "      <th>rf 0.03</th>\n",
       "      <th>rf 0.03 pca</th>\n",
       "      <th>rf 0.035</th>\n",
       "      <th>rf 0.04</th>\n",
       "      <th>rf 0.05</th>\n",
       "      <th>xg 0.03</th>\n",
       "      <th>xg 0.035</th>\n",
       "      <th>xg 0.04</th>\n",
       "      <th>xg 0.05</th>\n",
       "      <th>LSTM 0.02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30y yield</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of significative models</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                lr 0.03  lr 0.03 pca  lr 0.035  lr 0.04  \\\n",
       "1m yield                              0            0         0        0   \n",
       "3m yield                              1            1         1        1   \n",
       "6m yield                              1            1         1        1   \n",
       "1y yield                              0            0         1        0   \n",
       "2y yield                              0            0         0        0   \n",
       "3y yield                              0            0         0        0   \n",
       "5y yield                              0            0         0        0   \n",
       "7y yield                              0            0         0        0   \n",
       "10y yield                             0            0         0        0   \n",
       "20y yield                             0            0         0        0   \n",
       "30y yield                             0            0         0        0   \n",
       "Number of significative models        2            2         3        2   \n",
       "\n",
       "                                lr 0.05  rf 0.03  rf 0.03 pca  rf 0.035  \\\n",
       "1m yield                              0        1            0         0   \n",
       "3m yield                              1        1            1         1   \n",
       "6m yield                              1        1            1         1   \n",
       "1y yield                              0        0            0         0   \n",
       "2y yield                              0        0            0         0   \n",
       "3y yield                              0        0            0         0   \n",
       "5y yield                              0        0            1         0   \n",
       "7y yield                              0        0            0         0   \n",
       "10y yield                             0        0            0         0   \n",
       "20y yield                             1        0            0         0   \n",
       "30y yield                             0        0            0         0   \n",
       "Number of significative models        3        3            3         2   \n",
       "\n",
       "                                rf 0.04  rf 0.05  xg 0.03  xg 0.035  xg 0.04  \\\n",
       "1m yield                              1        1        1         0        0   \n",
       "3m yield                              1        1        1         1        1   \n",
       "6m yield                              1        1        1         1        1   \n",
       "1y yield                              0        0        0         1        1   \n",
       "2y yield                              0        0        0         0        0   \n",
       "3y yield                              0        0        0         0        0   \n",
       "5y yield                              0        0        0         0        0   \n",
       "7y yield                              0        0        0         0        0   \n",
       "10y yield                             0        0        0         0        1   \n",
       "20y yield                             0        0        0         0        0   \n",
       "30y yield                             0        0        0         0        0   \n",
       "Number of significative models        3        3        3         3        4   \n",
       "\n",
       "                                xg 0.05  LSTM 0.02  \n",
       "1m yield                              0          1  \n",
       "3m yield                              1          1  \n",
       "6m yield                              1          0  \n",
       "1y yield                              0          1  \n",
       "2y yield                              0          0  \n",
       "3y yield                              0          0  \n",
       "5y yield                              0          0  \n",
       "7y yield                              0          0  \n",
       "10y yield                             0          0  \n",
       "20y yield                             0          0  \n",
       "30y yield                             0          0  \n",
       "Number of significative models        2          3  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval = (pvalues < 0.1).astype(int)\n",
    "pval.loc['Number of significative models'] = pval.sum(axis = 0)\n",
    "pval.columns = forecast.keys()\n",
    "pval.add_prefix('Statistical significance of performance of ')\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856764b",
   "metadata": {},
   "source": [
    "We can see that there are large disparities in terms of statistical significance for the different models and different parts of the yield curve:  \n",
    "- We can see that most models have a statistically significant forecasting power on the short end of the yield curve, and particularly for the 3-month and 6-month yields.\n",
    "- no model manages to have a statistically significant forecasting power on the 2y yield, 3y yield, 7y yield and 30y yield; this is not surprising, because long-term yields are not as much driven by macroeconomic, financial and monetary variables as short-term yields. Long-term yields mostly depend on expectations of future short rates over many years, which are latent and difficult to model and observe. As a result, long-term yields are more difficult to forecast. \n",
    "\n",
    "Generally, the models that best succeed in producing classifiers with a statistically significant forecasting power are XGBoost and Random Forest. On this dataset, logistic regression produces slightly fewer significantly performing classifiers. This therefore illustrates an advantage of tree-based models, which manage to capture nonlinearities in the data and thus outperform logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f0684",
   "metadata": {},
   "source": [
    "## B- Analysis of the out-of-sample accuracy of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421e5a3",
   "metadata": {},
   "source": [
    "Now, we can observe and analyze the average out-of-sample accuracy of all the models that were trained over the 79 fifteen years rolling windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3d8f6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {\n",
    "            \"lr 0.03\":pd.read_csv(\"results of models/accuracies logistic regression, 15y train test.csv\",index_col=0).mean(),\n",
    "             \"lr 0.03 pca\":pd.read_csv(\"results of models/accuracies logistic regression pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.035\":pd.read_csv(\"results of models/accuracies logistic regression, MI 0.035, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.04\":pd.read_csv(\"results of models/accuracies logistic regression, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.05\":pd.read_csv(\"results of models/accuracies logistic regression, MI 0.05, 15y train test.csv\", index_col=0).mean(),\n",
    "            \"rf 0.03\":pd.read_csv(\"results of models/accuracies random forest, no pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.03 pca\":pd.read_csv(\"results of models/accuracies random forest pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.035\":pd.read_csv(\"results of models/accuracies random forest, MI 0.035, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.04\":pd.read_csv(\"results of models/accuracies random forest, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.05\":pd.read_csv(\"results of models/accuracies random forest, MI 0.05, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.03\":pd.read_csv(\"results of models/accuracies xgboost, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.03 pca\":pd.read_csv(\"results of models/accuracies xgboost, pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.035\":pd.read_csv(\"results of models/accuracies xgboost, MI 0.035, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.04\":pd.read_csv(\"results of models/accuracies xgboost, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.05\":pd.read_csv(\"results of models/accuracies xgboost, MI 0.05, 15y train test.csv\", index_col=0).mean()\n",
    "             }\n",
    "accuracies = pd.DataFrame(accuracies)\n",
    "\n",
    "accuracies_lstm = pd.read_csv(\"results of models/accuracies_lstm_cls.csv\",index_col = 0).mean()\n",
    "accuracies_lstm.name = 'LSTM 0.02'\n",
    "\n",
    "accuracies = pd.concat([accuracies,accuracies_lstm],axis = 1).round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11136b5d",
   "metadata": {},
   "source": [
    "The dataframe below represents the average out-of-sample accuracy of each model over the 79 15 years rolling windows. The columns are the performance of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "dfa0a6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average out-of-sample accuracy for lr 0.03</th>\n",
       "      <th>average out-of-sample accuracy for lr 0.03 pca</th>\n",
       "      <th>average out-of-sample accuracy for lr 0.035</th>\n",
       "      <th>average out-of-sample accuracy for lr 0.04</th>\n",
       "      <th>average out-of-sample accuracy for lr 0.05</th>\n",
       "      <th>average out-of-sample accuracy for rf 0.03</th>\n",
       "      <th>average out-of-sample accuracy for rf 0.03 pca</th>\n",
       "      <th>average out-of-sample accuracy for rf 0.035</th>\n",
       "      <th>average out-of-sample accuracy for rf 0.04</th>\n",
       "      <th>average out-of-sample accuracy for rf 0.05</th>\n",
       "      <th>average out-of-sample accuracy for xg 0.03</th>\n",
       "      <th>average out-of-sample accuracy for xg 0.03 pca</th>\n",
       "      <th>average out-of-sample accuracy for xg 0.035</th>\n",
       "      <th>average out-of-sample accuracy for xg 0.04</th>\n",
       "      <th>average out-of-sample accuracy for xg 0.05</th>\n",
       "      <th>average out-of-sample accuracy for LSTM 0.02</th>\n",
       "      <th>average out-of-sample accuracy for the majority class classifier benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2y yield</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3y yield</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5y yield</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7y yield</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10y yield</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20y yield</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30y yield</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           average out-of-sample accuracy for lr 0.03  \\\n",
       "1m yield                                         0.58   \n",
       "3m yield                                         0.68   \n",
       "6m yield                                         0.64   \n",
       "1y yield                                         0.57   \n",
       "2y yield                                         0.56   \n",
       "3y yield                                         0.55   \n",
       "5y yield                                         0.50   \n",
       "7y yield                                         0.55   \n",
       "10y yield                                        0.54   \n",
       "20y yield                                        0.50   \n",
       "30y yield                                        0.53   \n",
       "\n",
       "           average out-of-sample accuracy for lr 0.03 pca  \\\n",
       "1m yield                                             0.61   \n",
       "3m yield                                             0.67   \n",
       "6m yield                                             0.63   \n",
       "1y yield                                             0.57   \n",
       "2y yield                                             0.59   \n",
       "3y yield                                             0.55   \n",
       "5y yield                                             0.55   \n",
       "7y yield                                             0.53   \n",
       "10y yield                                            0.52   \n",
       "20y yield                                            0.51   \n",
       "30y yield                                            0.51   \n",
       "\n",
       "           average out-of-sample accuracy for lr 0.035  \\\n",
       "1m yield                                          0.62   \n",
       "3m yield                                          0.71   \n",
       "6m yield                                          0.68   \n",
       "1y yield                                          0.62   \n",
       "2y yield                                          0.58   \n",
       "3y yield                                          0.53   \n",
       "5y yield                                          0.55   \n",
       "7y yield                                          0.53   \n",
       "10y yield                                         0.48   \n",
       "20y yield                                         0.51   \n",
       "30y yield                                         0.48   \n",
       "\n",
       "           average out-of-sample accuracy for lr 0.04  \\\n",
       "1m yield                                         0.64   \n",
       "3m yield                                         0.71   \n",
       "6m yield                                         0.65   \n",
       "1y yield                                         0.62   \n",
       "2y yield                                         0.54   \n",
       "3y yield                                         0.54   \n",
       "5y yield                                         0.54   \n",
       "7y yield                                         0.53   \n",
       "10y yield                                        0.48   \n",
       "20y yield                                        0.49   \n",
       "30y yield                                        0.49   \n",
       "\n",
       "           average out-of-sample accuracy for lr 0.05  \\\n",
       "1m yield                                         0.63   \n",
       "3m yield                                         0.65   \n",
       "6m yield                                         0.64   \n",
       "1y yield                                         0.59   \n",
       "2y yield                                         0.55   \n",
       "3y yield                                         0.53   \n",
       "5y yield                                         0.50   \n",
       "7y yield                                         0.51   \n",
       "10y yield                                        0.48   \n",
       "20y yield                                        0.43   \n",
       "30y yield                                        0.46   \n",
       "\n",
       "           average out-of-sample accuracy for rf 0.03  \\\n",
       "1m yield                                         0.64   \n",
       "3m yield                                         0.70   \n",
       "6m yield                                         0.67   \n",
       "1y yield                                         0.59   \n",
       "2y yield                                         0.56   \n",
       "3y yield                                         0.53   \n",
       "5y yield                                         0.54   \n",
       "7y yield                                         0.54   \n",
       "10y yield                                        0.51   \n",
       "20y yield                                        0.49   \n",
       "30y yield                                        0.48   \n",
       "\n",
       "           average out-of-sample accuracy for rf 0.03 pca  \\\n",
       "1m yield                                             0.61   \n",
       "3m yield                                             0.62   \n",
       "6m yield                                             0.57   \n",
       "1y yield                                             0.54   \n",
       "2y yield                                             0.54   \n",
       "3y yield                                             0.53   \n",
       "5y yield                                             0.56   \n",
       "7y yield                                             0.54   \n",
       "10y yield                                            0.52   \n",
       "20y yield                                            0.53   \n",
       "30y yield                                            0.53   \n",
       "\n",
       "           average out-of-sample accuracy for rf 0.035  \\\n",
       "1m yield                                          0.64   \n",
       "3m yield                                          0.70   \n",
       "6m yield                                          0.67   \n",
       "1y yield                                          0.59   \n",
       "2y yield                                          0.56   \n",
       "3y yield                                          0.53   \n",
       "5y yield                                          0.51   \n",
       "7y yield                                          0.51   \n",
       "10y yield                                         0.49   \n",
       "20y yield                                         0.47   \n",
       "30y yield                                         0.47   \n",
       "\n",
       "           average out-of-sample accuracy for rf 0.04  \\\n",
       "1m yield                                         0.64   \n",
       "3m yield                                         0.70   \n",
       "6m yield                                         0.67   \n",
       "1y yield                                         0.59   \n",
       "2y yield                                         0.53   \n",
       "3y yield                                         0.55   \n",
       "5y yield                                         0.52   \n",
       "7y yield                                         0.52   \n",
       "10y yield                                        0.50   \n",
       "20y yield                                        0.49   \n",
       "30y yield                                        0.49   \n",
       "\n",
       "           average out-of-sample accuracy for rf 0.05  \\\n",
       "1m yield                                         0.65   \n",
       "3m yield                                         0.69   \n",
       "6m yield                                         0.67   \n",
       "1y yield                                         0.60   \n",
       "2y yield                                         0.55   \n",
       "3y yield                                         0.56   \n",
       "5y yield                                         0.52   \n",
       "7y yield                                         0.55   \n",
       "10y yield                                        0.53   \n",
       "20y yield                                        0.53   \n",
       "30y yield                                        0.49   \n",
       "\n",
       "           average out-of-sample accuracy for xg 0.03  \\\n",
       "1m yield                                         0.64   \n",
       "3m yield                                         0.68   \n",
       "6m yield                                         0.66   \n",
       "1y yield                                         0.56   \n",
       "2y yield                                         0.53   \n",
       "3y yield                                         0.50   \n",
       "5y yield                                         0.53   \n",
       "7y yield                                         0.49   \n",
       "10y yield                                        0.51   \n",
       "20y yield                                        0.51   \n",
       "30y yield                                        0.53   \n",
       "\n",
       "           average out-of-sample accuracy for xg 0.03 pca  \\\n",
       "1m yield                                             0.59   \n",
       "3m yield                                             0.55   \n",
       "6m yield                                             0.50   \n",
       "1y yield                                             0.56   \n",
       "2y yield                                             0.53   \n",
       "3y yield                                             0.51   \n",
       "5y yield                                             0.51   \n",
       "7y yield                                             0.50   \n",
       "10y yield                                            0.51   \n",
       "20y yield                                            0.52   \n",
       "30y yield                                            0.51   \n",
       "\n",
       "           average out-of-sample accuracy for xg 0.035  \\\n",
       "1m yield                                          0.62   \n",
       "3m yield                                          0.69   \n",
       "6m yield                                          0.68   \n",
       "1y yield                                          0.53   \n",
       "2y yield                                          0.52   \n",
       "3y yield                                          0.48   \n",
       "5y yield                                          0.50   \n",
       "7y yield                                          0.51   \n",
       "10y yield                                         0.49   \n",
       "20y yield                                         0.52   \n",
       "30y yield                                         0.52   \n",
       "\n",
       "           average out-of-sample accuracy for xg 0.04  \\\n",
       "1m yield                                         0.61   \n",
       "3m yield                                         0.69   \n",
       "6m yield                                         0.67   \n",
       "1y yield                                         0.52   \n",
       "2y yield                                         0.52   \n",
       "3y yield                                         0.49   \n",
       "5y yield                                         0.50   \n",
       "7y yield                                         0.50   \n",
       "10y yield                                        0.47   \n",
       "20y yield                                        0.50   \n",
       "30y yield                                        0.50   \n",
       "\n",
       "           average out-of-sample accuracy for xg 0.05  \\\n",
       "1m yield                                         0.62   \n",
       "3m yield                                         0.68   \n",
       "6m yield                                         0.66   \n",
       "1y yield                                         0.56   \n",
       "2y yield                                         0.53   \n",
       "3y yield                                         0.50   \n",
       "5y yield                                         0.49   \n",
       "7y yield                                         0.51   \n",
       "10y yield                                        0.50   \n",
       "20y yield                                        0.51   \n",
       "30y yield                                        0.50   \n",
       "\n",
       "           average out-of-sample accuracy for LSTM 0.02  \\\n",
       "1m yield                                           0.63   \n",
       "3m yield                                           0.62   \n",
       "6m yield                                           0.63   \n",
       "1y yield                                           0.57   \n",
       "2y yield                                           0.57   \n",
       "3y yield                                           0.50   \n",
       "5y yield                                           0.49   \n",
       "7y yield                                           0.47   \n",
       "10y yield                                          0.48   \n",
       "20y yield                                          0.52   \n",
       "30y yield                                          0.52   \n",
       "\n",
       "           average out-of-sample accuracy for the majority class classifier benchmark  \n",
       "1m yield                                                0.59                           \n",
       "3m yield                                                0.55                           \n",
       "6m yield                                                0.50                           \n",
       "1y yield                                                0.56                           \n",
       "2y yield                                                0.53                           \n",
       "3y yield                                                0.51                           \n",
       "5y yield                                                0.51                           \n",
       "7y yield                                                0.50                           \n",
       "10y yield                                               0.51                           \n",
       "20y yield                                               0.52                           \n",
       "30y yield                                               0.51                           "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracies.index = [\"1m yield\",\"3m yield\",\"6m yield\",\"1y yield\",\"2y yield\",\"3y yield\",\"5y yield\",\"7y yield\",\"10y yield\",\"20y yield\",\"30y yield\"]\n",
    "accuracies = accuracies.add_prefix(\"average out-of-sample accuracy for \")\n",
    "accuracies[\"average out-of-sample accuracy for the majority class classifier benchmark\"] = a.values.round(2)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257f82e",
   "metadata": {},
   "source": [
    "For each maturity in the yield curve, we will identify the model providing the best average out-of-sample accuracy over the 79 15 years rolling training periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "1b6db92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best model</th>\n",
       "      <th>Best average out-of-sample accuracy</th>\n",
       "      <th>statistical significance of the forecasting power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>rf 0.05</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2y yield</th>\n",
       "      <td>lr 0.03 pca</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3y yield</th>\n",
       "      <td>rf 0.05</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5y yield</th>\n",
       "      <td>rf 0.03 pca</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7y yield</th>\n",
       "      <td>lr 0.03</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10y yield</th>\n",
       "      <td>lr 0.03</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20y yield</th>\n",
       "      <td>rf 0.03 pca</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30y yield</th>\n",
       "      <td>lr 0.03</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Best model  Best average out-of-sample accuracy  \\\n",
       "1m yield       rf 0.05                                 0.65   \n",
       "3m yield      lr 0.035                                 0.71   \n",
       "6m yield      lr 0.035                                 0.68   \n",
       "1y yield      lr 0.035                                 0.62   \n",
       "2y yield   lr 0.03 pca                                 0.59   \n",
       "3y yield       rf 0.05                                 0.56   \n",
       "5y yield   rf 0.03 pca                                 0.56   \n",
       "7y yield       lr 0.03                                 0.55   \n",
       "10y yield      lr 0.03                                 0.54   \n",
       "20y yield  rf 0.03 pca                                 0.53   \n",
       "30y yield      lr 0.03                                 0.53   \n",
       "\n",
       "           statistical significance of the forecasting power  \n",
       "1m yield                                                   1  \n",
       "3m yield                                                   1  \n",
       "6m yield                                                   1  \n",
       "1y yield                                                   1  \n",
       "2y yield                                                   0  \n",
       "3y yield                                                   0  \n",
       "5y yield                                                   1  \n",
       "7y yield                                                   0  \n",
       "10y yield                                                  0  \n",
       "20y yield                                                  0  \n",
       "30y yield                                                  0  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = pd.DataFrame({\"Best model\":[col[35:] for col in accuracies.idxmax(axis=1)],\n",
    "                            \"Best average out-of-sample accuracy\": accuracies.max(axis=1), \n",
    "                            \"statistical significance of the forecasting power\": [pval.loc[ind,x] for ind, x in zip(accuracies.idxmax(axis=1).index,[col[35:] for col in accuracies.idxmax(axis=1)]) ]\n",
    "                            })\n",
    "best_models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204b95c",
   "metadata": {},
   "source": [
    "We can also provide the best statistically significant model for each point of the yield curve for which we have one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "35823066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jean-\\AppData\\Local\\Temp\\ipykernel_15764\\179885682.py:8: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  \"best significant model\": acc_sig.idxmax(axis=1),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best significant model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>rf 0.04</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5y yield</th>\n",
       "      <td>rf 0.03 pca</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10y yield</th>\n",
       "      <td>xg 0.04</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20y yield</th>\n",
       "      <td>lr 0.05</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          best significant model  accuracy\n",
       "1m yield                 rf 0.04      0.65\n",
       "3m yield                lr 0.035      0.71\n",
       "6m yield                lr 0.035      0.68\n",
       "1y yield                lr 0.035      0.62\n",
       "5y yield             rf 0.03 pca      0.51\n",
       "10y yield                xg 0.04      0.47\n",
       "20y yield                lr 0.05      0.43"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalc= pval.drop(labels = ['Number of significative models'],axis =0)\n",
    "ac = accuracies\n",
    "ac =ac.drop(labels = ['average out-of-sample accuracy for rf 0.03 pca','average out-of-sample accuracy for the majority class classifier benchmark'],axis = 1)\n",
    "ac.columns = pvalc.columns\n",
    "acc_sig = ac.where(pvalc == 1)\n",
    "\n",
    "best_models = pd.DataFrame({\n",
    "    \"best significant model\": acc_sig.idxmax(axis=1),\n",
    "    \"accuracy\": acc_sig.max(axis=1)\n",
    "})\n",
    "best_models.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a220f",
   "metadata": {},
   "source": [
    "##### Some important observations on the models, the features used and the overall accuracy:\n",
    "\n",
    "- we can see that in most cases, logistic regression is the model performing the highest average out-of-sample accuracy. 7 out of 11 yield maturities are better forecast with logistic regression. But only 3 of those models are significative. \n",
    "\n",
    "- Concerning the 4 other yield maturities that are not better forecast with logistic regression, the model with the highest average out-of-sample accuracy is the random forest.\n",
    "\n",
    "- Overall, our models manage to get a satisfying out-of-sample accuracy on the short-end of the yield curve, i.e. on yields of bonds with maturity in less than 2 years: for maturities of one year or less, we manage to get average out-of-sample accuracies above 60% and even up to 71%. We are rather satisfied with these figures and these models could be useful signals to implement trading strategies. However we could not implement a strategy as we could not access data on US bond prices.\n",
    "\n",
    "- It is more difficult to forecast the medium-end and long-end of the yield curve (yields of bonds with maturity above 1y): for these yields, we get an average out-of-sample accuracy between 0.53 and 0.59. This is less satisfying and our models provide a weaker signal on those yields. The lower predictive power of our models on the long-end of the yield curve confirms the lack of statistical significance of the forecasting power of the models on these yields.\n",
    "\n",
    "- Interestingly, the random forest sometimes performs better than logistic regression to forecast the long-end of the yield curve. This could suggest that there is some non-linear relationship between some features and the long-term yields that is not captured very well by a linear model like logistic regression.\n",
    "\n",
    "- Even if in some cases, random forests provide a higher out-of-sample accuracy than linear regression, this improvement is only marginal: for instance, to forecast the 5y yield, logistic regression has a 55% out-of-sample accuracy and random forest 56%. This improvement may be marginal compared to the increase in complexity and the loss of interpretability of the model.\n",
    "\n",
    "- For most yields, the datasets containing features with mutual information above 0.03 or 0.035 are the datasets providing the best trained models. These are the datasets containing a set of macroeconomic and financial variables, as well as functions of the past yields (lags, rolling means, quantiles, ...).\n",
    "\n",
    "- However, when it comes to the shortest maturity yield, ie the 1 month yield, we see that the dataset providing the trained model with the best out-of-sample accuracy is the dataset containing features with mutual information above 0.05. This dataset contains only functions of the past yield, so it is interesting to see that we can obtain a 65% out-of-sample accuracy to predict 1 month yields only with previous values of the yields. This could suggest that the trend-following and mean-reverting behavior of the 1 month yield is stronger than for other yields, and that it could be suited for trading strategies exploiting this behavior.\n",
    "\n",
    "\n",
    "Another interesting thing is to look at values forecast by our models. By looking at the average proportion of ones forecast by our models, we can get some insights on the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8dbdf1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proportions of 1 forecast by lr 0.03</th>\n",
       "      <th>Proportions of 1 forecast by lr 0.03 pca</th>\n",
       "      <th>Proportions of 1 forecast by lr 0.035</th>\n",
       "      <th>Proportions of 1 forecast by lr 0.04</th>\n",
       "      <th>Proportions of 1 forecast by lr 0.05</th>\n",
       "      <th>Proportions of 1 forecast by rf 0.03</th>\n",
       "      <th>Proportions of 1 forecast by rf 0.03 pca</th>\n",
       "      <th>Proportions of 1 forecast by rf 0.035</th>\n",
       "      <th>Proportions of 1 forecast by rf 0.04</th>\n",
       "      <th>Proportions of 1 forecast by rf 0.05</th>\n",
       "      <th>Proportions of 1 forecast by xg 0.03</th>\n",
       "      <th>Proportions of 1 forecast by xg 0.03 pca</th>\n",
       "      <th>Proportions of 1 forecast by xg 0.035</th>\n",
       "      <th>Proportions of 1 forecast by xg 0.04</th>\n",
       "      <th>Proportions of 1 forecast by xg 0.05</th>\n",
       "      <th>Proportions of 1 forecast by LSTM 0.02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2y yield</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3y yield</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5y yield</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7y yield</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10y yield</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20y yield</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30y yield</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Proportions of 1 forecast by lr 0.03  \\\n",
       "1m yield                                   0.41   \n",
       "3m yield                                   0.41   \n",
       "6m yield                                   0.48   \n",
       "1y yield                                   0.50   \n",
       "2y yield                                   0.63   \n",
       "3y yield                                   0.59   \n",
       "5y yield                                   0.49   \n",
       "7y yield                                   0.52   \n",
       "10y yield                                  0.50   \n",
       "20y yield                                  0.50   \n",
       "30y yield                                  0.58   \n",
       "\n",
       "           Proportions of 1 forecast by lr 0.03 pca  \\\n",
       "1m yield                                       0.40   \n",
       "3m yield                                       0.41   \n",
       "6m yield                                       0.42   \n",
       "1y yield                                       0.46   \n",
       "2y yield                                       0.60   \n",
       "3y yield                                       0.56   \n",
       "5y yield                                       0.49   \n",
       "7y yield                                       0.50   \n",
       "10y yield                                      0.50   \n",
       "20y yield                                      0.49   \n",
       "30y yield                                      0.59   \n",
       "\n",
       "           Proportions of 1 forecast by lr 0.035  \\\n",
       "1m yield                                    0.37   \n",
       "3m yield                                    0.36   \n",
       "6m yield                                    0.44   \n",
       "1y yield                                    0.42   \n",
       "2y yield                                    0.55   \n",
       "3y yield                                    0.54   \n",
       "5y yield                                    0.52   \n",
       "7y yield                                    0.53   \n",
       "10y yield                                   0.51   \n",
       "20y yield                                   0.54   \n",
       "30y yield                                   0.59   \n",
       "\n",
       "           Proportions of 1 forecast by lr 0.04  \\\n",
       "1m yield                                   0.36   \n",
       "3m yield                                   0.38   \n",
       "6m yield                                   0.50   \n",
       "1y yield                                   0.50   \n",
       "2y yield                                   0.62   \n",
       "3y yield                                   0.59   \n",
       "5y yield                                   0.56   \n",
       "7y yield                                   0.58   \n",
       "10y yield                                  0.58   \n",
       "20y yield                                  0.67   \n",
       "30y yield                                  0.76   \n",
       "\n",
       "           Proportions of 1 forecast by lr 0.05  \\\n",
       "1m yield                                   0.41   \n",
       "3m yield                                   0.46   \n",
       "6m yield                                   0.52   \n",
       "1y yield                                   0.57   \n",
       "2y yield                                   0.61   \n",
       "3y yield                                   0.60   \n",
       "5y yield                                   0.58   \n",
       "7y yield                                   0.63   \n",
       "10y yield                                  0.59   \n",
       "20y yield                                  0.65   \n",
       "30y yield                                  0.65   \n",
       "\n",
       "           Proportions of 1 forecast by rf 0.03  \\\n",
       "1m yield                                   0.26   \n",
       "3m yield                                   0.33   \n",
       "6m yield                                   0.42   \n",
       "1y yield                                   0.31   \n",
       "2y yield                                   0.34   \n",
       "3y yield                                   0.37   \n",
       "5y yield                                   0.37   \n",
       "7y yield                                   0.35   \n",
       "10y yield                                  0.28   \n",
       "20y yield                                  0.29   \n",
       "30y yield                                  0.33   \n",
       "\n",
       "           Proportions of 1 forecast by rf 0.03 pca  \\\n",
       "1m yield                                       0.12   \n",
       "3m yield                                       0.19   \n",
       "6m yield                                       0.33   \n",
       "1y yield                                       0.05   \n",
       "2y yield                                       0.11   \n",
       "3y yield                                       0.17   \n",
       "5y yield                                       0.28   \n",
       "7y yield                                       0.23   \n",
       "10y yield                                      0.26   \n",
       "20y yield                                      0.28   \n",
       "30y yield                                      0.30   \n",
       "\n",
       "           Proportions of 1 forecast by rf 0.035  \\\n",
       "1m yield                                    0.27   \n",
       "3m yield                                    0.33   \n",
       "6m yield                                    0.42   \n",
       "1y yield                                    0.30   \n",
       "2y yield                                    0.35   \n",
       "3y yield                                    0.36   \n",
       "5y yield                                    0.41   \n",
       "7y yield                                    0.34   \n",
       "10y yield                                   0.28   \n",
       "20y yield                                   0.35   \n",
       "30y yield                                   0.36   \n",
       "\n",
       "           Proportions of 1 forecast by rf 0.04  \\\n",
       "1m yield                                   0.27   \n",
       "3m yield                                   0.33   \n",
       "6m yield                                   0.41   \n",
       "1y yield                                   0.32   \n",
       "2y yield                                   0.34   \n",
       "3y yield                                   0.36   \n",
       "5y yield                                   0.38   \n",
       "7y yield                                   0.41   \n",
       "10y yield                                  0.32   \n",
       "20y yield                                  0.35   \n",
       "30y yield                                  0.41   \n",
       "\n",
       "           Proportions of 1 forecast by rf 0.05  \\\n",
       "1m yield                                   0.28   \n",
       "3m yield                                   0.35   \n",
       "6m yield                                   0.41   \n",
       "1y yield                                   0.32   \n",
       "2y yield                                   0.30   \n",
       "3y yield                                   0.36   \n",
       "5y yield                                   0.36   \n",
       "7y yield                                   0.36   \n",
       "10y yield                                  0.30   \n",
       "20y yield                                  0.36   \n",
       "30y yield                                  0.44   \n",
       "\n",
       "           Proportions of 1 forecast by xg 0.03  \\\n",
       "1m yield                                   0.20   \n",
       "3m yield                                   0.31   \n",
       "6m yield                                   0.43   \n",
       "1y yield                                   0.08   \n",
       "2y yield                                   0.11   \n",
       "3y yield                                   0.10   \n",
       "5y yield                                   0.15   \n",
       "7y yield                                   0.12   \n",
       "10y yield                                  0.06   \n",
       "20y yield                                  0.04   \n",
       "30y yield                                  0.06   \n",
       "\n",
       "           Proportions of 1 forecast by xg 0.03 pca  \\\n",
       "1m yield                                       0.00   \n",
       "3m yield                                       0.00   \n",
       "6m yield                                       0.03   \n",
       "1y yield                                       0.00   \n",
       "2y yield                                       0.00   \n",
       "3y yield                                       0.00   \n",
       "5y yield                                       0.00   \n",
       "7y yield                                       0.00   \n",
       "10y yield                                      0.00   \n",
       "20y yield                                      0.00   \n",
       "30y yield                                      0.00   \n",
       "\n",
       "           Proportions of 1 forecast by xg 0.035  \\\n",
       "1m yield                                    0.21   \n",
       "3m yield                                    0.32   \n",
       "6m yield                                    0.43   \n",
       "1y yield                                    0.07   \n",
       "2y yield                                    0.12   \n",
       "3y yield                                    0.10   \n",
       "5y yield                                    0.12   \n",
       "7y yield                                    0.13   \n",
       "10y yield                                   0.05   \n",
       "20y yield                                   0.03   \n",
       "30y yield                                   0.06   \n",
       "\n",
       "           Proportions of 1 forecast by xg 0.04  \\\n",
       "1m yield                                   0.20   \n",
       "3m yield                                   0.32   \n",
       "6m yield                                   0.40   \n",
       "1y yield                                   0.09   \n",
       "2y yield                                   0.13   \n",
       "3y yield                                   0.11   \n",
       "5y yield                                   0.15   \n",
       "7y yield                                   0.13   \n",
       "10y yield                                  0.09   \n",
       "20y yield                                  0.07   \n",
       "30y yield                                  0.07   \n",
       "\n",
       "           Proportions of 1 forecast by xg 0.05  \\\n",
       "1m yield                                   0.17   \n",
       "3m yield                                   0.33   \n",
       "6m yield                                   0.39   \n",
       "1y yield                                   0.08   \n",
       "2y yield                                   0.11   \n",
       "3y yield                                   0.08   \n",
       "5y yield                                   0.09   \n",
       "7y yield                                   0.08   \n",
       "10y yield                                  0.05   \n",
       "20y yield                                  0.02   \n",
       "30y yield                                  0.03   \n",
       "\n",
       "           Proportions of 1 forecast by LSTM 0.02  \n",
       "1m yield                                     0.00  \n",
       "3m yield                                     0.00  \n",
       "6m yield                                     0.00  \n",
       "1y yield                                     0.00  \n",
       "2y yield                                     0.00  \n",
       "3y yield                                     0.01  \n",
       "5y yield                                     0.00  \n",
       "7y yield                                     0.01  \n",
       "10y yield                                    0.01  \n",
       "20y yield                                    0.01  \n",
       "30y yield                                    0.01  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = {\n",
    "            \"lr 0.03\":pd.read_csv(\"results of models/forecast logistic regression, 15y train test.csv\",index_col=0).mean(),\n",
    "             \"lr 0.03 pca\":pd.read_csv(\"results of models/forecast logistic regression pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.035\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.035, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.04\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.05\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.05, 15y train test.csv\", index_col=0).mean(),\n",
    "            \"rf 0.03\":pd.read_csv(\"results of models/forecast random forest, no pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.03 pca\":pd.read_csv(\"results of models/forecast random forest pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.035\":pd.read_csv(\"results of models/forecast random forest, MI 0.035, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.04\":pd.read_csv(\"results of models/forecast random forest, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.05\":pd.read_csv(\"results of models/forecast random forest, MI 0.05, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.03\":pd.read_csv(\"results of models/forecast xgboost, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.03 pca\":pd.read_csv(\"results of models/forecast xgboost, pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.035\":pd.read_csv(\"results of models/forecast xgboost, MI 0.035, 15y train test.csv\",index_col=0).mean(),\n",
    "             \"xg 0.04\":pd.read_csv(\"results of models/forecast xgboost, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.05\":pd.read_csv(\"results of models/forecast xgboost, MI 0.05, 15y train test.csv\", index_col=0).mean()\n",
    "             }\n",
    "forecast = pd.DataFrame(forecast)\n",
    "\n",
    "forecast_lstm = pd.read_csv(\"results of models/forecast_LSTM_cls_12864128_0.02MI_2patience_52LB_evalsscores.csv\",index_col=0)\n",
    "forecast_lstm = (forecast_lstm>0.5).astype(int).mean()\n",
    "forecast_lstm.name = 'LSTM 0.02'\n",
    "\n",
    "forecast_avg = pd.concat([forecast,forecast_lstm],axis =1).round(2)\n",
    "forecast_avg.index =[\"1m yield\",\"3m yield\",\"6m yield\",\"1y yield\",\"2y yield\",\"3y yield\",\"5y yield\",\"7y yield\",\"10y yield\",\"20y yield\",\"30y yield\"]\n",
    "forecast_avg = forecast_avg.add_prefix(\"Proportions of 1 forecast by \")\n",
    "forecast_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306972e1",
   "metadata": {},
   "source": [
    "Let's compare the distribution of classes forecast by our models with the true distribution of classes in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f39bbd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y_DGS1MO    0.588608\n",
       "Y_DGS3MO    0.553797\n",
       "Y_DGS6MO    0.503165\n",
       "Y_DGS1      0.556962\n",
       "Y_DGS2      0.525316\n",
       "Y_DGS3      0.509494\n",
       "Y_DGS5      0.506329\n",
       "Y_DGS7      0.503165\n",
       "Y_DGS10     0.506329\n",
       "Y_DGS20     0.522152\n",
       "Y_DGS30     0.512658\n",
       "dtype: float64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409b9fc",
   "metadata": {},
   "source": [
    "We can see that the classes predicted by the logistic regression and random forest are relatively well balanced and not too different to the true distribution of classes in data. However, the XGboost models predict a very small number of ones: the proportion of ones in the predictions of XGboost is often lower than 0.1. This is even truer for the LSTM model. \n",
    "\n",
    "## C) Ensemble learning\n",
    "\n",
    "We will now try to implement ensemble learning models: we will implement an ensemble learning model that is specialized on forecasting the short-end of the yield curve. We won't try to build models for the other parts of the yield curve as the models that we have are already not statistically significatively performant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "68d29b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the short end of the yield curve we will use these predictors ['lr 0.035', 'lr 0.04', 'rf 0.05']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_columns_shortend =  accuracies.head(4).mean(axis=0).sort_values(ascending=False).head(3).index.tolist()\n",
    "print(\"for the short end of the yield curve we will use these predictors\", [col[35:] for col in top_columns_shortend])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ddd15e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_short = pd.DataFrame(index = Yw.iloc[780:Yw.shape[0]-1].index, columns = Yw.columns)\n",
    "accura = accuracies[top_columns_shortend]\n",
    "\n",
    "for col, col2 in zip(\n",
    "    Yw.columns,\n",
    "    [\"1m yield\",\"3m yield\",\"6m yield\",\"1y yield\",\"2y yield\",\"3y yield\",\n",
    "     \"5y yield\",\"7y yield\",\"10y yield\",\"20y yield\",\"30y yield\"]\n",
    "):\n",
    "\n",
    "    weights = accura.loc[col2]/accura.loc[col2].sum()\n",
    "    weights = weights.to_dict()\n",
    "\n",
    "    forecast = {\n",
    "        key: df.rename(columns={col: key})\n",
    "        for key, df in {\n",
    "            \"lr 0.035\": pd.read_csv(\"results of models/forecast logistic regression, MI 0.035, 15y train test.csv\", index_col=0)[[col]],\n",
    "            \"lr 0.04\": pd.read_csv(\"results of models/forecast logistic regression, MI 0.04, 15y train test.csv\", index_col=0)[[col]],\n",
    "            \"rf 0.05\": pd.read_csv(\"results of models/forecast random forest, MI 0.05, 15y train test.csv\", index_col=0)[[col]],\n",
    "        }.items()\n",
    "    }\n",
    "    forecast_agg = pd.concat(forecast.values(), axis=1)\n",
    "\n",
    "    weighted_preds = forecast_agg.copy()\n",
    "    for model in forecast_agg.columns:\n",
    "        weighted_preds[model] = forecast_agg[model] * weights[f'average out-of-sample accuracy for {model}']\n",
    "    \n",
    "    forecast_agg['ensemble'] = weighted_preds.sum(axis=1)\n",
    "\n",
    "    ensemble_short[col] = (forecast_agg['ensemble'] > 0.5).astype(int)\n",
    "\n",
    "Yw_true = Yw.iloc[780:Yw.shape[0]-1]\n",
    "accu = (ensemble_short == Yw_true).mean().round(2)\n",
    "accu.index = accuracies.index\n",
    "accuracies['average out-of-sample accuracy for short end of yield curve ensemble model'] = accu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51191e5c",
   "metadata": {},
   "source": [
    "We get an improvement of 1% of accuracy on some specific points of the yield curve by aggregating the top 3 predictors. However this is a marginal improvement that has been performed without cross validation and on the whole history of predictions so it could not have been used before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e406f2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best model</th>\n",
       "      <th>Best average out-of-sample accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>rf 0.05</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>short end of yield curve ensemble model</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>lr 0.035</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2y yield</th>\n",
       "      <td>lr 0.03 pca</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3y yield</th>\n",
       "      <td>rf 0.05</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5y yield</th>\n",
       "      <td>short end of yield curve ensemble model</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7y yield</th>\n",
       "      <td>lr 0.03</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10y yield</th>\n",
       "      <td>lr 0.03</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20y yield</th>\n",
       "      <td>rf 0.03 pca</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30y yield</th>\n",
       "      <td>lr 0.03</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Best model  \\\n",
       "1m yield                                   rf 0.05   \n",
       "3m yield   short end of yield curve ensemble model   \n",
       "6m yield                                  lr 0.035   \n",
       "1y yield                                  lr 0.035   \n",
       "2y yield                               lr 0.03 pca   \n",
       "3y yield                                   rf 0.05   \n",
       "5y yield   short end of yield curve ensemble model   \n",
       "7y yield                                   lr 0.03   \n",
       "10y yield                                  lr 0.03   \n",
       "20y yield                              rf 0.03 pca   \n",
       "30y yield                                  lr 0.03   \n",
       "\n",
       "           Best average out-of-sample accuracy  \n",
       "1m yield                                  0.65  \n",
       "3m yield                                  0.72  \n",
       "6m yield                                  0.68  \n",
       "1y yield                                  0.62  \n",
       "2y yield                                  0.59  \n",
       "3y yield                                  0.56  \n",
       "5y yield                                  0.57  \n",
       "7y yield                                  0.55  \n",
       "10y yield                                 0.54  \n",
       "20y yield                                 0.53  \n",
       "30y yield                                 0.53  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = pd.DataFrame({\"Best model\":[col[35:] for col in accuracies.idxmax(axis=1)],\n",
    "                            \"Best average out-of-sample accuracy\": accuracies.max(axis=1)\n",
    "                            })\n",
    "best_models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a0bd9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3614553c",
   "metadata": {},
   "source": [
    "## D) Evolution of the performance of the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db18e2",
   "metadata": {},
   "source": [
    "We will plot the evolution through time of the 3 months rolling average out-of-sample accuracy for the statistically significant models. This will allow us to see if the models are consistently performing through time or if they are only reliable at some specific periods of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c7e0f216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr 0.03</th>\n",
       "      <th>lr 0.03 pca</th>\n",
       "      <th>lr 0.035</th>\n",
       "      <th>lr 0.04</th>\n",
       "      <th>lr 0.05</th>\n",
       "      <th>rf 0.03</th>\n",
       "      <th>rf 0.03 pca</th>\n",
       "      <th>rf 0.035</th>\n",
       "      <th>rf 0.04</th>\n",
       "      <th>rf 0.05</th>\n",
       "      <th>xg 0.03</th>\n",
       "      <th>xg 0.035</th>\n",
       "      <th>xg 0.04</th>\n",
       "      <th>xg 0.05</th>\n",
       "      <th>LSTM 0.02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1m yield</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m yield</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m yield</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1y yield</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr 0.03  lr 0.03 pca  lr 0.035  lr 0.04  lr 0.05  rf 0.03  \\\n",
       "1m yield      NaN          NaN       NaN      NaN      NaN     0.64   \n",
       "3m yield     0.68         0.67      0.71     0.71     0.65     0.70   \n",
       "6m yield     0.64         0.63      0.68     0.65     0.64     0.67   \n",
       "1y yield      NaN          NaN      0.62      NaN      NaN      NaN   \n",
       "\n",
       "          rf 0.03 pca  rf 0.035  rf 0.04  rf 0.05  xg 0.03  xg 0.035  xg 0.04  \\\n",
       "1m yield          NaN       NaN     0.65     0.64     0.59       NaN      NaN   \n",
       "3m yield         0.70      0.70     0.69     0.68     0.55      0.69     0.69   \n",
       "6m yield         0.67      0.67     0.67     0.66     0.50      0.68     0.67   \n",
       "1y yield          NaN       NaN      NaN      NaN      NaN      0.53     0.52   \n",
       "\n",
       "          xg 0.05  LSTM 0.02  \n",
       "1m yield      NaN       0.63  \n",
       "3m yield     0.68       0.62  \n",
       "6m yield     0.66        NaN  \n",
       "1y yield      NaN       0.57  "
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sig.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = {\n",
    "            \"lr 0.03\":pd.read_csv(\"results of models/forecast logistic regression, 15y train test.csv\",index_col=0).mean(),\n",
    "             \"lr 0.03 pca\":pd.read_csv(\"results of models/forecast logistic regression pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.035\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.035, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.04\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"lr 0.05\":pd.read_csv(\"results of models/forecast logistic regression, MI 0.05, 15y train test.csv\", index_col=0).mean(),\n",
    "            \"rf 0.03\":pd.read_csv(\"results of models/forecast random forest, no pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.03 pca\":pd.read_csv(\"results of models/forecast random forest pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.035\":pd.read_csv(\"results of models/forecast random forest, MI 0.035, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.04\":pd.read_csv(\"results of models/forecast random forest, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"rf 0.05\":pd.read_csv(\"results of models/forecast random forest, MI 0.05, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.03\":pd.read_csv(\"results of models/forecast xgboost, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.03 pca\":pd.read_csv(\"results of models/forecast xgboost, pca, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.035\":pd.read_csv(\"results of models/forecast xgboost, MI 0.035, 15y train test.csv\",index_col=0).mean(),\n",
    "             \"xg 0.04\":pd.read_csv(\"results of models/forecast xgboost, MI 0.04, 15y train test.csv\", index_col=0).mean(),\n",
    "             \"xg 0.05\":pd.read_csv(\"results of models/forecast xgboost, MI 0.05, 15y train test.csv\", index_col=0).mean()\n",
    "             }\n",
    "forecast = pd.DataFrame(forecast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2096c",
   "metadata": {},
   "source": [
    "## E) Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df37175",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
