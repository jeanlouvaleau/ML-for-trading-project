{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663276e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RidgeCV, MultiTaskLassoCV, MultiTaskElasticNetCV, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor,MultiOutputClassifier\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371adc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce457d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f13923",
   "metadata": {},
   "source": [
    "# I- Training linear models on daily data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261e7b5",
   "metadata": {},
   "source": [
    "We will try to train models on both daily and weekly data. We may see some different dynamics between daily and weekly data: it could be easier to train a model on weekly data because there is less autocorrelation between datapoints. However in the meanwhile, the dataset on daily datapoints may be bigger so it could also be easier to train models on daily data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e53cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('data', 'US', 'us_data.csv')\n",
    "dus = pd.read_csv(datapath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_inf = dus.columns[np.isinf(dus.to_numpy()).any(axis=0)]\n",
    "print(cols_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus.hist(figsize=(23, 23), bins=100)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec41c5",
   "metadata": {},
   "source": [
    "### A) Creating new features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86313b39",
   "metadata": {},
   "source": [
    "Now we need to add the lagged values of yields as features. We have to choose lags and yields to add as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for USyield in ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']:\n",
    "    series = dus[USyield]\n",
    "    fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "    plot_acf(series, lags=90,title = f'ACF {USyield}', ax = axes[0])\n",
    "    plot_pacf(series, lags=90,title = f'PACF {USyield}',ax = axes[1])\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlim(0.5, 90)  # décale le début après 0\n",
    "        ax.set_ylim(-0.2, 0.2) \n",
    "\n",
    "        if USyield in ['DGS5','DGS7','DGS10', 'DGS20', 'DGS30']:\n",
    "            \n",
    "            ax.axvline(x=25, color='red', linestyle='--', linewidth=1)\n",
    "            ax.axvline(x=50, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa2f66",
   "metadata": {},
   "source": [
    "- We can see that on short term yields, there is much more autocorrelation in the data, up to more than 30 days. Returns in the past few days are highly correlated to returns in the next days. \n",
    "- However, on long term yields, there is much less autocorrelation and returns in the past 2 days are only slightly correlated to next day return. Surprisingly we see some persistent autocorrelation between returns at day t and t-25 and t-50. \n",
    "\n",
    "For maturities less than 1y, we'll add the following lags:\n",
    "- t-1,t-2,t-5,t-10,t-15,t-20,t-25,t-30,t-40,t-50\n",
    "\n",
    "For maturities more than 1y, we will add:\n",
    "- t-1,t-2,t-10,t-25,t-50\n",
    "\n",
    "We will probably need to do some PCA to combine features as they will be very correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3581d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [1,2,5,10,15,20,25,30,40,50]:\n",
    "    dus[f'DGS1MO_t-{lag}'] = dus['DGS1MO'].shift(lag-1)\n",
    "    dus[f'DGS3MO_t-{lag}'] = dus['DGS3MO'].shift(lag-1)\n",
    "    dus[f'DGS6MO_t-{lag}'] = dus['DGS6MO'].shift(lag-1)\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "  \n",
    "\n",
    "for lag in [1,2,10,15,25,50]:\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "    dus[f'DGS2_t-{lag}'] = dus['DGS2'].shift(lag-1)\n",
    "    dus[f'DGS3_t-{lag}'] = dus['DGS3'].shift(lag-1)\n",
    "    dus[f'DGS5_t-{lag}'] = dus['DGS5'].shift(lag-1)\n",
    "    dus[f'DGS7_t-{lag}'] = dus['DGS7'].shift(lag-1)\n",
    "    dus[f'DGS10_t-{lag}'] = dus['DGS10'].shift(lag-1)\n",
    "    dus[f'DGS20_t-{lag}'] = dus['DGS20'].shift(lag-1)\n",
    "    dus[f'DGS30_t-{lag}'] = dus['DGS30'].shift(lag-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variables to forecast \n",
    "\n",
    "dus['Y_1MO'] = dus['DGS1MO'].shift(-1)\n",
    "dus['Y_3MO'] = dus['DGS3MO'].shift(-1)\n",
    "dus['Y_6MO'] = dus['DGS6MO'].shift(-1)\n",
    "dus['Y_1year'] = dus['DGS1'].shift(-1)\n",
    "dus['Y_2year'] = dus['DGS2'].shift(-1)\n",
    "dus['Y_3year'] = dus['DGS3'].shift(-1)\n",
    "dus['Y_5year'] = dus['DGS5'].shift(-1)\n",
    "dus['Y_7year'] = dus['DGS7'].shift(-1)\n",
    "dus['Y_10year'] = dus['DGS10'].shift(-1)\n",
    "dus['Y_20year'] = dus['DGS20'].shift(-1)\n",
    "dus['Y_30year'] = dus['DGS30'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now remove the original yield columns\n",
    "dus = dus.drop(columns=['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c8c90",
   "metadata": {},
   "source": [
    "We can now look at the heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,25))\n",
    "sns.heatmap(dus.corr(), cmap='seismic', center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514c74a",
   "metadata": {},
   "source": [
    "Overall the features have a very low correlation with the target, so we'll remove the least correlated ones: \n",
    "\n",
    "- the lagged features that have a correlation coefficient < 0.05 in absolute value with all target variables. \n",
    "- the other features that have a correlation coefficient < 0.03 in absolute value with all target variables. We do a distinction between lagged features and other features because filtering all features with the 0.05 threshold removes somes features that should have a predictive impact: sp500, gold, VIX for instance. \n",
    "\n",
    "Moreover, given the very high correlation between lagged features, we'll apply a PCA in the pipeline on those to limit the number of colinear features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0962fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dus[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n",
    "dus_lagged_features = dus[[col for col in dus.columns if '_t-' in col]]\n",
    "dus_other =dus.drop(columns=[col for col in dus.columns if '_t-' in col])\n",
    "\n",
    "corrs = pd.DataFrame({\n",
    "    target: dus_lagged_features.corrwith(Y[target]) for target in Y.columns\n",
    "}).abs()  \n",
    "\n",
    "# repérer les colonnes où la corrélation absolue < 0.05 pour toutes les targets\n",
    "mask = (corrs < 0.05).all(axis=1)\n",
    "low_corr_features = corrs.index[mask]\n",
    "\n",
    "# supprimer ces colonnes\n",
    "dus_filtered = dus.drop(columns=low_corr_features)\n",
    "\n",
    "\n",
    "\n",
    "corrs = pd.DataFrame({\n",
    "    target: dus_other.corrwith(Y[target]) for target in Y.columns\n",
    "}).abs()  \n",
    "\n",
    "# repérer les colonnes où la corrélation absolue < 0.05 pour toutes les targets\n",
    "mask = (corrs < 0.03).all(axis=1)\n",
    "low_corr_features_2 = corrs.index[mask]\n",
    "\n",
    "# supprimer ces colonnes\n",
    "dus_filtered = dus_filtered.drop(columns=low_corr_features_2)\n",
    "\n",
    "print(f\"{len(low_corr_features) + len(low_corr_features_2)} features were deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low_corr_features)\n",
    "print(low_corr_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdeb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(dus_filtered.corr(), cmap='seismic', center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb294fcf",
   "metadata": {},
   "source": [
    "### B) PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1768633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus_filtered = dus_filtered.dropna()\n",
    "X = dus_filtered[['USGOOD', 'USCONS', 'MANEMP', 'DMANEMP', 'NDMANEMP', 'USWTRADE',\n",
    "       'USFIRE', 'PERMIT', 'UMCSENT', 'M2SL', 'M2REAL', 'TOTRESNS', 'CPIAUCSL',\n",
    "       'CPIAPPSL', 'CPITRNSL', 'CUSR0000SAC', 'CPIULFSL', 'CUUR0000SA0L2',\n",
    "       'PCEPI', 'DNDGRG3M086SBEA', 'MTSDS133FMS', 'GFDEGDQ188S',\n",
    "       'IRLTLT01DEM156N', 'IRLTLT01JPM156N', 'IRLTLT01GBM156N',\n",
    "       'IRLTLT01CAM156N', 'IRLTLT01AUM156N', 'IRLTLT01FRM156N', 'NASDAQCOM',\n",
    "       'AAA', 'BAA', 'DEXCAUS', 'DEXUSAL', 'NFCI', 'FEDFUNDS', 'BOGMBASE',\n",
    "       'WSHOSHO', 'T5YIE', 'T10YIE', 'log return gold', 'log return sp500',\n",
    "       'DGS1MO_t-1', 'DGS3MO_t-1', 'DGS6MO_t-1', 'DGS1_t-1', 'DGS1MO_t-2',\n",
    "       'DGS3MO_t-2', 'DGS6MO_t-2', 'DGS1MO_t-5', 'DGS3MO_t-5', 'DGS6MO_t-5',\n",
    "       'DGS3MO_t-10', 'DGS6MO_t-10', 'DGS1_t-10', 'DGS1MO_t-15', 'DGS3MO_t-15',\n",
    "       'DGS6MO_t-15', 'DGS1MO_t-20', 'DGS3MO_t-20', 'DGS6MO_t-20', 'DGS1_t-20',\n",
    "       'DGS3MO_t-30', 'DGS6MO_t-40', 'DGS1MO_t-50', 'DGS2_t-1', 'DGS3_t-1',\n",
    "       'DGS10_t-1', 'DGS20_t-1', 'DGS30_t-1', 'DGS7_t-50', 'DGS10_t-50',\n",
    "       'DGS20_t-50', 'DGS30_t-50']]\n",
    "\n",
    "Y = dus_filtered[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47038b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Number of components kept:\", pca.n_components_)\n",
    "print(\"cumulative explained variance :\", pca.explained_variance_ratio_.cumsum())\n",
    "print(\"Composantes principales (coefficients sur les features originales) :\")\n",
    "print(pca.components_)\n",
    "\n",
    "print(\"Exemple des nouvelles features transformées :\")\n",
    "print(X_pca[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculer la contribution absolue sur PC1 et PC2\n",
    "pc1, pc2 = np.abs(pca.components_[:2])\n",
    "importance = pc1 + pc2\n",
    "\n",
    "# garder les n features les plus importantes\n",
    "n = 30\n",
    "top_idx = np.argsort(importance)[-n:]\n",
    "top_labels = X.columns[top_idx]\n",
    "top_components = pca.components_[:2, top_idx]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "circle = plt.Circle((0,0), 1, color='gray', fill=False)\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(top_components[0,:], top_components[1,:])):\n",
    "    plt.arrow(0, 0, x, y, color='r', alpha=0.6, head_width=0.02)\n",
    "    plt.text(x*1.15, y*1.15, top_labels[i], color='b', ha='center', va='center', fontsize=9)\n",
    "\n",
    "plt.xlim(-1.1, 1.1)\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Correlation circle (top features)\")\n",
    "plt.grid()\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af776ae0",
   "metadata": {},
   "source": [
    "We can see that features are overall very correlated, so we'll train some models with PCA and some without."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4584738",
   "metadata": {},
   "source": [
    "### C) Training a ridge model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f7a26",
   "metadata": {},
   "source": [
    "We do a walk forward cross validation:\n",
    "- we train our model on 4 years of data (= approximately 1000 data points)\n",
    "- we do prediction for the next month (21 days)\n",
    "- wa add a PCA to the pipeline to deal with correlated features. We'll also train a model without PCA to see how it changes the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "window_train = 252 *4\n",
    "window_pred = 21          \n",
    "alphas = np.logspace(-3, 3, 20)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "plt.close('all')  # ferme toutes les figures existantes\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per model with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per model without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per model with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per model without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7249b4",
   "metadata": {},
   "source": [
    "- When looking at the in sample R2 of our models, we see that the R2 is overall low, but that it is better on short term yields, ie from 1 month to 1 year, and significantly lower for long-term yields. \n",
    "- we see significant variations in R2 in 2011 and 2020, probably because of outliers. \n",
    "\n",
    "- The out of sample R2 is close to zero or even negative so there is no predictive power in our model.\n",
    "\n",
    "- adding a PCA in the pipeline do not change anything to the in sample R2. However, the hit rate is slightly less variable when adding the PCA, suggesting a bit less overfitting (although the out of sample results are as bad).\n",
    "- The hit rate seems to be close to 0.5 on average for all models and all samples. So it appears the model does not do anything better than predicting at random - it completely overfits the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5de84f",
   "metadata": {},
   "source": [
    "## Training Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-5, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 252 *4\n",
    "window_pred = 21          \n",
    "alphas = np.logspace(-5, 2, 20)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('lasso', MultiTaskLassoCV(fit_intercept=False,alphas=alphas, cv=tscv))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('lasso', MultiTaskLassoCV(fit_intercept=False,alphas=alphas, cv=tscv))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "alpha,selected_features = [],[]\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "alpha_nopca,selected_features_nopca = [],[]\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    alpha.append(pipe.named_steps['lasso'].alpha_)\n",
    "    selected_features.append(np.sum(np.any(pipe.named_steps['lasso'].coef_!=0,axis=0)))\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "    alpha_nopca.append(pipe_nopca.named_steps['lasso'].alpha_)\n",
    "    selected_features_nopca.append(np.sum(np.any(pipe_nopca.named_steps['lasso'].coef_!=0,axis=0)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0852b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs = pd.DataFrame(selected_features)\n",
    "fs.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs_nopca = pd.DataFrame(selected_features_nopca)\n",
    "fs_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "alphadf = pd.DataFrame(alpha)\n",
    "alphadf.index = [date[0] for date in dates_pred]\n",
    "\n",
    "alphadf_nopca = pd.DataFrame(alpha_nopca)\n",
    "alphadf_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(5,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per maturity with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per maturity without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per maturity with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per maturity without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "fs.plot(ax = ax[3,0], title = 'Evolution of number of selected features with PCA, per sample')\n",
    "ax[3,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "fs_nopca.plot(ax = ax[3,1], title = 'Evolution of number of selected features without PCA, per sample')\n",
    "ax[3,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "alphadf.plot(ax = ax[4,0], title = 'Evolution of alpha selected by cross validation - model with PCA, per sample')\n",
    "ax[4,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "alphadf_nopca.plot(ax = ax[4,1], title = 'Evolution of alpha selected by cross validation - model without PCA, per sample')\n",
    "ax[4,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129a4af",
   "metadata": {},
   "source": [
    "Lasso performance is even worse than that of ridge because there are some periods for which the model selects no features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c5160",
   "metadata": {},
   "source": [
    "## Training Elastic net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 252 *10\n",
    "window_pred = 21          \n",
    "alphas = np.logspace(-3, 2, 20)\n",
    "l1_ratios = [0.25,0.5,0.75]\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=0.5, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=l1_ratios, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "alpha,selected_features,l1 = [],[],[]\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "alpha_nopca,selected_features_nopca,l1_nopca = [],[],[]\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    alpha.append(pipe.named_steps['elasticnet'].alpha_)\n",
    "    selected_features.append(np.sum(np.any(pipe.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1.append(pipe.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "    alpha_nopca.append(pipe_nopca.named_steps['elasticnet'].alpha_)\n",
    "    selected_features_nopca.append(np.sum(np.any(pipe_nopca.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1_nopca.append(pipe_nopca.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489868d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs = pd.DataFrame(selected_features)\n",
    "fs.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs_nopca = pd.DataFrame(selected_features_nopca)\n",
    "fs_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "alphadf = pd.DataFrame(alpha)\n",
    "alphadf.index = [date[0] for date in dates_pred]\n",
    "\n",
    "alphadf_nopca = pd.DataFrame(alpha_nopca)\n",
    "alphadf_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "l1df = pd.DataFrame(l1)\n",
    "l1df.index = [date[0] for date in dates_pred]\n",
    "\n",
    "l1df_nopca = pd.DataFrame(l1_nopca)\n",
    "l1df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(6,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per maturity with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per maturity without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per maturity with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per maturity without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "fs.plot(ax = ax[3,0], title = 'Evolution of number of selected features with PCA, per sample')\n",
    "ax[3,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "fs_nopca.plot(ax = ax[3,1], title = 'Evolution of number of selected features without PCA, per sample')\n",
    "ax[3,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "alphadf.plot(ax = ax[4,0], title = 'Evolution of alpha selected by cross validation - model with PCA, per sample')\n",
    "ax[4,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "alphadf_nopca.plot(ax = ax[4,1], title = 'Evolution of alpha selected by cross validation - model without PCA, per sample')\n",
    "ax[4,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "l1df.plot(ax = ax[5,0], title = 'Evolution of L1 ratio selected by cross validation - model with PCA, per sample')\n",
    "ax[5,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "l1df_nopca.plot(ax = ax[5,1], title = 'Evolution of L1 ratio selected by cross validation - model without PCA, per sample')\n",
    "ax[5,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09193bf",
   "metadata": {},
   "source": [
    "Overall all these linear models work very poorly, which is not surprising given the low correlation between features and past yields. We can now try to work on weekly data, which may be a bit less noisy: hopefully our model will be able to better identify some trends and patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08c70c",
   "metadata": {},
   "source": [
    "# II) Training linear models on weekly data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('data', 'US', 'us_data_weekly.csv')\n",
    "dus = pd.read_csv(datapath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe448618",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus = dus[dus.index>'2003-01-03']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db708b",
   "metadata": {},
   "source": [
    "### A) Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for USyield in ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']:\n",
    "    series = dus[USyield]\n",
    "    fig, axes = plt.subplots(1,2, figsize=(14,6))\n",
    "    plot_acf(series, lags=50,title = f'ACF {USyield}', ax = axes[0])\n",
    "    plot_pacf(series, lags=50,title = f'PACF {USyield}',ax = axes[1])\n",
    "    \n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlim(0.5, 50)  # décale le début après 0\n",
    "        ax.set_ylim(-0.2, 0.2) \n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd433bc6",
   "metadata": {},
   "source": [
    "- We can see that on short term yields, there is much more autocorrelation in the data, up to 40 lags. Returns in the past few weeks (and so on the past year) are highly correlated to returns in the next week. \n",
    "- However, on long term yields, there is much less autocorrelation and returns in the past 2 weeks are only very slightly correlated to next day return. Surprisingly we see some persistent autocorrelation between returns at day t and t-25 and t-50. \n",
    "\n",
    "For maturities less than 1y, we'll add the following lags:\n",
    "- t-1,t-2,t-5,t-10,t-15,t-20,t-25,t-30,t-40\n",
    "\n",
    "For maturities more than 1y, we will add:\n",
    "- t-1,t-2,t-10\n",
    "\n",
    "We will probably need to do some PCA to combine features as they will be very correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeeec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [1,2,5,10,15,20,25,30,40,50]:\n",
    "    dus[f'DGS1MO_t-{lag}'] = dus['DGS1MO'].shift(lag-1)\n",
    "    dus[f'DGS3MO_t-{lag}'] = dus['DGS3MO'].shift(lag-1)\n",
    "    dus[f'DGS6MO_t-{lag}'] = dus['DGS6MO'].shift(lag-1)\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "  \n",
    "\n",
    "for lag in [1,2,10]:\n",
    "    dus[f'DGS1_t-{lag}'] = dus['DGS1'].shift(lag-1)\n",
    "    dus[f'DGS2_t-{lag}'] = dus['DGS2'].shift(lag-1)\n",
    "    dus[f'DGS3_t-{lag}'] = dus['DGS3'].shift(lag-1)\n",
    "    dus[f'DGS5_t-{lag}'] = dus['DGS5'].shift(lag-1)\n",
    "    dus[f'DGS7_t-{lag}'] = dus['DGS7'].shift(lag-1)\n",
    "    dus[f'DGS10_t-{lag}'] = dus['DGS10'].shift(lag-1)\n",
    "    dus[f'DGS20_t-{lag}'] = dus['DGS20'].shift(lag-1)\n",
    "    dus[f'DGS30_t-{lag}'] = dus['DGS30'].shift(lag-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variables to forecast \n",
    "\n",
    "dus['Y_1MO'] = dus['DGS1MO'].shift(-1)\n",
    "dus['Y_3MO'] = dus['DGS3MO'].shift(-1)\n",
    "dus['Y_6MO'] = dus['DGS6MO'].shift(-1)\n",
    "dus['Y_1year'] = dus['DGS1'].shift(-1)\n",
    "dus['Y_2year'] = dus['DGS2'].shift(-1)\n",
    "dus['Y_3year'] = dus['DGS3'].shift(-1)\n",
    "dus['Y_5year'] = dus['DGS5'].shift(-1)\n",
    "dus['Y_7year'] = dus['DGS7'].shift(-1)\n",
    "dus['Y_10year'] = dus['DGS10'].shift(-1)\n",
    "dus['Y_20year'] = dus['DGS20'].shift(-1)\n",
    "dus['Y_30year'] = dus['DGS30'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be9808",
   "metadata": {},
   "source": [
    "We'll also add statistical features like the mean, variance, autocorrelation, quantiles of the time series to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ts_features(df, cols, max_lag=30, windows=[20, 60]):\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for col in cols:\n",
    "        y = df[col]\n",
    "\n",
    "  \n",
    "        # --- Statistiques glissantes ---\n",
    "        for w in windows:\n",
    "            features[f'{col}_mean_{w}'] = y.rolling(w).mean()\n",
    "            features[f'{col}_std_{w}'] = y.rolling(w).std()\n",
    "            features[f'{col}_q25_{w}'] = y.rolling(w).quantile(0.25)\n",
    "            features[f'{col}_q75_{w}'] = y.rolling(w).quantile(0.75)\n",
    "            features[f'{col}_q05_{w}'] = y.rolling(w).quantile(0.1)\n",
    "            features[f'{col}_q90_{w}'] = y.rolling(w).quantile(0.9)\n",
    "            features[f'{col}_range_{w}'] = y.rolling(w).max() - y.rolling(w).min() \n",
    "        \n",
    "       \n",
    "        # --- Autocorrélations locales ---\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            features[f'{col}_autocorr_{lag}'] = (\n",
    "                y.rolling(window=max(windows)).apply(lambda x: x.autocorr(lag=lag), raw=False)\n",
    "            )\n",
    "        \n",
    "    return features\n",
    "\n",
    "# Exemple d’usage :\n",
    "cols = ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3',\n",
    "        'DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']\n",
    "\n",
    "dus_features = add_ts_features(dus, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae323cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus_features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus = dus.merge(dus_features, how = 'inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dus = dus.dropna()\n",
    "dus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now remove the original yield columns\n",
    "dus = dus.drop(columns=['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3','DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6d6c4",
   "metadata": {},
   "source": [
    "Many features aren't that much correlated to the target, so we'll remove all features with correlation lower than 0.1 to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dus[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n",
    "\n",
    "corrs = pd.DataFrame({\n",
    "    target: dus.corrwith(Y[target]) for target in Y.columns\n",
    "}).abs()  \n",
    "\n",
    "# repérer les colonnes où la corrélation absolue < 0.05 pour toutes les targets\n",
    "mask = (corrs < 0.1).all(axis=1)\n",
    "low_corr_features = corrs.index[mask]\n",
    "\n",
    "# supprimer ces colonnes\n",
    "dus_filtered = dus.drop(columns=low_corr_features)\n",
    "\n",
    "print(f\"{len(low_corr_features)} features were deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a959c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c80cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,25))\n",
    "sns.heatmap(dus_filtered.corr(), cmap='seismic', center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dus_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9ecb7",
   "metadata": {},
   "source": [
    "### B) Training a ridge model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259923a",
   "metadata": {},
   "source": [
    "We can now try to train a ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dus_filtered[['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year']]\n",
    "\n",
    "X = dus_filtered.drop(columns = ['Y_1MO', 'Y_3MO', 'Y_6MO', 'Y_1year', 'Y_2year', 'Y_3year', 'Y_5year', 'Y_7year', 'Y_10year', 'Y_20year', 'Y_30year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316231bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52*5 #we train our model on 5 years of data and test it on the next month \n",
    "window_pred = 4          \n",
    "alphas = np.logspace(-1, 3, 20)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('ridge', MultiOutputRegressor(RidgeCV(fit_intercept=False,alphas=alphas, cv=tscv)))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "plt.close('all')  # ferme toutes les figures existantes\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per model with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per model without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per model without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per model with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per model without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab5e46",
   "metadata": {},
   "source": [
    "Results are slightly better than when working on daily data, but we still only learn noise and completely overfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83421aee",
   "metadata": {},
   "source": [
    "### B) Training an elastic net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52*5\n",
    "window_pred = 4         \n",
    "alphas = np.logspace(-2, 2, 20)\n",
    "l1_ratios = [0.25,0.5,0.75]\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.95)),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=0.5, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "pipe_nopca = Pipeline([\n",
    "    ('scaler',StandardScaler()),   \n",
    "    ('elasticnet', MultiTaskElasticNetCV(alphas=alphas, cv=tscv, l1_ratio=l1_ratios, fit_intercept=False,max_iter=5000))\n",
    "])\n",
    "\n",
    "preds = []\n",
    "dates_pred = []\n",
    "r2_is_list = []\n",
    "r2_os_list=[]\n",
    "hit_rate_list = []\n",
    "alpha,selected_features,l1 = [],[],[]\n",
    "\n",
    "preds_nopca = []\n",
    "dates_pred_nopca = []\n",
    "r2_is_list_nopca = []\n",
    "r2_os_list_nopca=[]\n",
    "hit_rate_list_nopca = []\n",
    "alpha_nopca,selected_features_nopca,l1_nopca = [],[],[]\n",
    "\n",
    "for start in tqdm(range(0, len(X) - window_train - window_pred + 1, window_pred)):\n",
    "  \n",
    "    end_train = start + window_train\n",
    "    end_pred = end_train + window_pred\n",
    "\n",
    "    X_train = X.iloc[start:end_train]\n",
    "    Y_train = Y.iloc[start:end_train]\n",
    "\n",
    "    X_test = X.iloc[end_train:end_pred]\n",
    "    Y_test = Y.iloc[end_train:end_pred]\n",
    "\n",
    "\n",
    "    # model with PCA \n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "\n",
    "    preds.append(Y_pred)\n",
    "    dates_pred.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred), axis=0)\n",
    "    r2_is_list.append(r2_is)\n",
    "    r2_os_list.append(r2_oos)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    alpha.append(pipe.named_steps['elasticnet'].alpha_)\n",
    "    selected_features.append(np.sum(np.any(pipe.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1.append(pipe.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "    # model without PCA \n",
    "    pipe_nopca.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred_nopca = pipe_nopca.predict(X_test)\n",
    "\n",
    "    preds_nopca.append(Y_pred)\n",
    "    dates_pred_nopca.append(X.index[end_train:end_pred])\n",
    "\n",
    "    mse = mean_squared_error(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    r2_is = r2_score(Y_train, pipe_nopca.predict(X_train), multioutput='raw_values')\n",
    "    r2_oos = r2_score(Y_test, Y_pred_nopca, multioutput='raw_values')\n",
    "    hit_rate = np.mean(np.sign(Y_test.values) == np.sign(Y_pred_nopca), axis=0)\n",
    "    r2_is_list_nopca.append(r2_is)\n",
    "    r2_os_list_nopca.append(r2_oos)\n",
    "    hit_rate_list_nopca.append(hit_rate)\n",
    "    alpha_nopca.append(pipe_nopca.named_steps['elasticnet'].alpha_)\n",
    "    selected_features_nopca.append(np.sum(np.any(pipe_nopca.named_steps['elasticnet'].coef_!=0,axis=0)))\n",
    "    l1_nopca.append(pipe_nopca.named_steps['elasticnet'].l1_ratio_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_is_df = pd.DataFrame(r2_is_list) \n",
    "r2_is_df_nopca = pd.DataFrame(r2_is_list_nopca) \n",
    "r2_is_df.columns = Y.columns\n",
    "r2_is_df_nopca.columns = Y.columns\n",
    "r2_is_df.index = [date[0] for date in dates_pred]\n",
    "r2_is_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "r2_os_df = pd.DataFrame(r2_os_list)  \n",
    "r2_os_df.columns = Y.columns\n",
    "r2_os_df.index = [date[0] for date in dates_pred]\n",
    "r2_os_df_nopca = pd.DataFrame(r2_os_list_nopca) \n",
    "r2_os_df_nopca.columns = Y.columns\n",
    "r2_os_df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "hr = pd.DataFrame(hit_rate_list) \n",
    "hr.columns = Y.columns\n",
    "hr.index = [date[0] for date in dates_pred]\n",
    "hr_nopca = pd.DataFrame(hit_rate_list_nopca) \n",
    "hr_nopca.columns = Y.columns\n",
    "hr_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs = pd.DataFrame(selected_features)\n",
    "fs.index = [date[0] for date in dates_pred]\n",
    "\n",
    "fs_nopca = pd.DataFrame(selected_features_nopca)\n",
    "fs_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "alphadf = pd.DataFrame(alpha)\n",
    "alphadf.index = [date[0] for date in dates_pred]\n",
    "\n",
    "alphadf_nopca = pd.DataFrame(alpha_nopca)\n",
    "alphadf_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "l1df = pd.DataFrame(l1)\n",
    "l1df.index = [date[0] for date in dates_pred]\n",
    "\n",
    "l1df_nopca = pd.DataFrame(l1_nopca)\n",
    "l1df_nopca.index = [date[0] for date in dates_pred]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(6,2,figsize=(28,28))\n",
    "\n",
    "r2_is_df.plot(ax = ax[0,0],title = 'Evolution of in sample R2 per maturity with PCA, per sample')\n",
    "ax[0,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_is_df_nopca.plot(ax = ax[0,1],title = 'Evolution of in sample R2 per maturity without PCA, per sample')\n",
    "ax[0,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "r2_os_df.plot(ax = ax[1,0], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity with PCA, per sample')\n",
    "ax[1,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "r2_os_df_nopca.plot(ax = ax[1,1], ylim =(-0.3,0.3), title = 'Evolution of out-sample R2 per maturity without PCA, per sample')\n",
    "ax[1,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "hr.plot(ax = ax[2,0], title = 'Evolution of out-sample hit rate per maturity with PCA, per sample')\n",
    "ax[2,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "hr_nopca.plot(ax = ax[2,1], title = 'Evolution of out-sample hit rate per maturity without PCA, per sample')\n",
    "ax[2,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "fs.plot(ax = ax[3,0], title = 'Evolution of number of selected features with PCA, per sample')\n",
    "ax[3,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "fs_nopca.plot(ax = ax[3,1], title = 'Evolution of number of selected features without PCA, per sample')\n",
    "ax[3,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "alphadf.plot(ax = ax[4,0], title = 'Evolution of alpha selected by cross validation - model with PCA, per sample')\n",
    "ax[4,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "alphadf_nopca.plot(ax = ax[4,1], title = 'Evolution of alpha selected by cross validation - model without PCA, per sample')\n",
    "ax[4,1].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "\n",
    "l1df.plot(ax = ax[5,0], title = 'Evolution of L1 ratio selected by cross validation - model with PCA, per sample')\n",
    "ax[5,0].grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
    "l1df_nopca.plot(ax = ax[5,1], title = 'Evolution of L1 ratio selected by cross validation - model without PCA, per sample')\n",
    "ax[5,1].grid(True, axis='y', linestyle='--', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27653ef",
   "metadata": {},
   "source": [
    "The results are also disappointing. Overall this is not surprising, we've seen that our features have a low correlation with the yield so the predictive power of these models is logically very low. We'll now try to do binary classification, maybe it could work better. Moreover, we'll focus on more complex models to see if they can extract non linear relationships between features and yields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa254c",
   "metadata": {},
   "source": [
    "# III - Binary classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e7f1e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('data', 'US', 'us_data_weekly.csv')\n",
    "dus_weekly = pd.read_csv(datapath, index_col=0)\n",
    "dus_weekly = dus_weekly.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aafec19",
   "metadata": {},
   "source": [
    "### A) Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cc344f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_ts_features(df, cols, max_lag=20, windows=[10,20,50]):\n",
    "\n",
    "    all_features = {}\n",
    "\n",
    "    for col in cols:\n",
    "        y = df[col]\n",
    "\n",
    "        # --- Rolling statistics ---\n",
    "        for w in windows:\n",
    "            roll = y.rolling(w)\n",
    "            all_features[f'{col}_mean_{w}'] = roll.mean()\n",
    "            all_features[f'{col}_std_{w}'] = roll.std()\n",
    "            all_features[f'{col}_q25_{w}'] = roll.quantile(0.25)\n",
    "            all_features[f'{col}_q75_{w}'] = roll.quantile(0.75)\n",
    "            all_features[f'{col}_q05_{w}'] = roll.quantile(0.05)\n",
    "            all_features[f'{col}_q90_{w}'] = roll.quantile(0.9)\n",
    "            all_features[f'{col}_range_{w}'] = roll.max() - roll.min()\n",
    "\n",
    "            # Z-score et momentum\n",
    "            all_features[f'{col}_zscore_{w}'] = (y - roll.mean()) / roll.std()\n",
    "            all_features[f'{col}_momentum_{w}'] = y - y.shift(w)\n",
    "\n",
    "        # Ratio de moyennes rapides / lentes\n",
    "        all_features[f'{col}_ratio_{10}_{50}'] = (\n",
    "            y.rolling(10).mean() / y.rolling(50).mean()\n",
    "        )\n",
    "\n",
    "        # Volatilité annualisée approx\n",
    "        all_features[f'{col}_vol_20'] = y.rolling(20).std() * np.sqrt(52)\n",
    "\n",
    "        # --- Lags bruts ---\n",
    "        for lag in [1,2,3,4,5,10,15,20,25,30,40,50]:\n",
    "            all_features[f'{col}_lag_{lag}'] = y.shift(lag-1)\n",
    "\n",
    "        # --- Autocorrélations (in-sample) ---\n",
    "        \n",
    "        acf_vals = acf(y.dropna(), nlags=max_lag, fft=True)\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            all_features[f'{col}_autocorr_{lag}'] = acf_vals[lag]\n",
    "\n",
    "    # --- Construction finale ---\n",
    "    features = pd.DataFrame(all_features, index=df.index)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "58251785",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3',\n",
    "        'DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']\n",
    "\n",
    "dus_features = add_ts_features(dus_weekly, cols)\n",
    "dus_features= dus_features.dropna()\n",
    "dus_weekly = dus_weekly.merge(dus_features, how = 'inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "890a9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols: \n",
    "    dus_weekly[f'Y_{col}'] = (dus_weekly[col]>0).astype(int).shift(-1)\n",
    "\n",
    "\n",
    "dus_weekly= dus_weekly.dropna()\n",
    "dus_weekly = dus_weekly.replace([np.inf, -np.inf], np.nan)\n",
    "dus_weekly = dus_weekly.ffill()\n",
    "\n",
    "#we can now remove the original yield columns\n",
    "dus_weekly = dus_weekly.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9d9a2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 738 features in the dataset\n"
     ]
    }
   ],
   "source": [
    "Yw = dus_weekly[[f'Y_{col}' for col in cols]]\n",
    "Xw = dus_weekly.drop(columns = [f'Y_{col}' for col in cols])\n",
    "\n",
    "print(f\"there are {Xw.shape[1]} features in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f3a58",
   "metadata": {},
   "source": [
    "We augmented the dataset by adding a very large amount of features created from the yields time series. however, many of these features are not informative so we need to remove them before training our model. \n",
    "\n",
    "We'll filter features by keeping only those with a mutual information score above than a given threshold. We'll create several datasets of features containing features filtered for the thresholds 0.03, 0.035, 0.04, 0.05 and train models on these specific datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "initial_number_of_features = Xw.shape[1]\n",
    "\n",
    "threshold_list = [0.03,0.035,0.04,0.05]\n",
    "\n",
    "datasets = {t:pd.DataFrame() for t in threshold_list}\n",
    "\n",
    "for threshold_mi in tqdm(threshold_list): \n",
    "    selected_features_w = set()\n",
    "    for col in Yw.columns:\n",
    "        mi = mutual_info_classif(Xw, Yw[col])\n",
    "        top_features_i = Xw.columns[mi > threshold_mi]  \n",
    "        selected_features_w.update(top_features_i)\n",
    "\n",
    "    datasets[threshold_mi] = Xw[list(selected_features_w)]\n",
    "\n",
    "    print(f'we removed {initial_number_of_features-len(selected_features_w)} features in the weekly dataset for threshold {threshold_mi}')\n",
    "    print(f'Number of variables in the dataset with MI threshold {threshold_mi}:',datasets[threshold_mi].shape[1])\n",
    "    print(f'Macro and market variables in the dataset with MI threshold {threshold_mi}:', [col for col in datasets[threshold_mi].columns if 'DGS' not in col])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4c612",
   "metadata": {},
   "source": [
    "Notice that many of the macro and market variables that we extracted from the FRED website do not share much mutual information with the target since many of these variables are removed with the threshold we used. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819007b",
   "metadata": {},
   "source": [
    "### B) Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c619595",
   "metadata": {},
   "source": [
    "We define the following pipelines for our logistic regression models.\n",
    "We train our model on a rolling window of 15 years of data (with cross validation without leakage of future information) and then predict the 4 next weeks. We then update the rolling window, train another model, predict the 4 next weekds and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52 * 15\n",
    "window_pred = 4\n",
    "\n",
    "alphas = np.logspace(-5, 2, 30)\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', MultiOutputClassifier(\n",
    "        LogisticRegressionCV(\n",
    "            penalty='l2',\n",
    "            cv=tscv,\n",
    "            Cs=alphas,\n",
    "            fit_intercept=False,\n",
    "            scoring='accuracy',\n",
    "            max_iter=5000)))\n",
    "])\n",
    "\n",
    "pipepca = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.99)), \n",
    "    ('logreg', MultiOutputClassifier(\n",
    "        LogisticRegressionCV(\n",
    "            penalty='l2',\n",
    "            cv=tscv,\n",
    "            Cs=alphas,\n",
    "            fit_intercept=False,\n",
    "            scoring='accuracy',\n",
    "            max_iter=5000)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0e368",
   "metadata": {},
   "source": [
    "We train logistic regression models for the 4 datasets containing features with mutual information larger than 0.03, 0.035, 0.04, 0.05 respectively. Then we save the results in datasets. \n",
    "\n",
    "The dataset with variables with mutual information > 0.03 contains 266 features, which is very high compared to the numer of points in the training datasets (52*15 lines), so we'll also train a model that performs a PCA before applying the logistic regression in order to reduce the number of features and see if it can improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model on dataset with features with mutual information above 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [15:03<00:00, 11.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.03 is:\n",
      "Y_DGS1MO    0.607595\n",
      "Y_DGS3MO    0.658228\n",
      "Y_DGS6MO    0.664557\n",
      "Y_DGS1      0.582278\n",
      "Y_DGS2      0.518987\n",
      "Y_DGS3      0.563291\n",
      "Y_DGS5      0.553797\n",
      "Y_DGS7      0.518987\n",
      "Y_DGS10     0.503165\n",
      "Y_DGS20     0.477848\n",
      "Y_DGS30     0.560127\n",
      "dtype: float64\n",
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.03 and PCA is:\n",
      "Y_DGS1MO    0.636076\n",
      "Y_DGS3MO    0.680380\n",
      "Y_DGS6MO    0.655063\n",
      "Y_DGS1      0.572785\n",
      "Y_DGS2      0.537975\n",
      "Y_DGS3      0.575949\n",
      "Y_DGS5      0.522152\n",
      "Y_DGS7      0.506329\n",
      "Y_DGS10     0.569620\n",
      "Y_DGS20     0.496835\n",
      "Y_DGS30     0.512658\n",
      "dtype: float64\n",
      "training model on dataset with features with mutual information above 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [11:14<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.035 is:\n",
      "Y_DGS1MO    0.607595\n",
      "Y_DGS3MO    0.658228\n",
      "Y_DGS6MO    0.664557\n",
      "Y_DGS1      0.582278\n",
      "Y_DGS2      0.518987\n",
      "Y_DGS3      0.563291\n",
      "Y_DGS5      0.553797\n",
      "Y_DGS7      0.518987\n",
      "Y_DGS10     0.503165\n",
      "Y_DGS20     0.477848\n",
      "Y_DGS30     0.560127\n",
      "dtype: float64\n",
      "training model on dataset with features with mutual information above 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [12:30<00:00,  9.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > 0.04 is:\n",
      "Y_DGS1MO    0.607595\n",
      "Y_DGS3MO    0.658228\n",
      "Y_DGS6MO    0.664557\n",
      "Y_DGS1      0.582278\n",
      "Y_DGS2      0.518987\n",
      "Y_DGS3      0.563291\n",
      "Y_DGS5      0.553797\n",
      "Y_DGS7      0.518987\n",
      "Y_DGS10     0.503165\n",
      "Y_DGS20     0.477848\n",
      "Y_DGS30     0.560127\n",
      "dtype: float64\n",
      "training model on dataset with features with mutual information above 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 56/79 [09:45<04:00, 10.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[271], line 121\u001b[0m\n\u001b[0;32m    118\u001b[0m Yw_test \u001b[38;5;241m=\u001b[39m Yw\u001b[38;5;241m.\u001b[39miloc[end_train:end_pred]\n\u001b[0;32m    119\u001b[0m y_true\u001b[38;5;241m.\u001b[39mappend(Yw_test)\n\u001b[1;32m--> 121\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXw_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYw_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m Yw_pred \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(Xw_test)\n\u001b[0;32m    125\u001b[0m y_predl2\u001b[38;5;241m.\u001b[39mappend(Yw_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\multioutput.py:543\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\multioutput.py:274\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\multioutput.py:63\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     61\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1994\u001b[0m, in \u001b[0;36mLogisticRegressionCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     prefer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1994\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1997\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintercept_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2015\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2016\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2018\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_encoded_labels\u001b[49m\n\u001b[0;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\n\u001b[0;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml1_ratios_\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[38;5;66;03m# _log_reg_scoring_path will output different shapes depending on the\u001b[39;00m\n\u001b[0;32m   2025\u001b[0m \u001b[38;5;66;03m# multi_class param, so we need to reshape the outputs accordingly.\u001b[39;00m\n\u001b[0;32m   2026\u001b[0m \u001b[38;5;66;03m# Cs is of shape (n_classes . n_folds . n_l1_ratios, n_Cs) and all the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2033\u001b[0m \u001b[38;5;66;03m#  (n_classes, n_folds, n_Cs . n_l1_ratios) or\u001b[39;00m\n\u001b[0;32m   2034\u001b[0m \u001b[38;5;66;03m#  (1, n_folds, n_Cs . n_l1_ratios)\u001b[39;00m\n\u001b[0;32m   2035\u001b[0m coefs_paths, Cs, scores, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:746\u001b[0m, in \u001b[0;36m_log_reg_scoring_path\u001b[1;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio, score_params)\u001b[0m\n\u001b[0;32m    743\u001b[0m     sw_train \u001b[38;5;241m=\u001b[39m sample_weight[train]\n\u001b[0;32m    744\u001b[0m     sw_test \u001b[38;5;241m=\u001b[39m sample_weight[test]\n\u001b[1;32m--> 746\u001b[0m coefs, Cs, n_iter \u001b[38;5;241m=\u001b[39m \u001b[43m_logistic_regression_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msw_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39msolver, multi_class\u001b[38;5;241m=\u001b[39mmulti_class)\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# The score method of Logistic Regression has a classes_ attribute.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:451\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    447\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    448\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    449\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    450\u001b[0m ]\n\u001b[1;32m--> 451\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    466\u001b[0m     solver,\n\u001b[0;32m    467\u001b[0m     opt_res,\n\u001b[0;32m    468\u001b[0m     max_iter,\n\u001b[0;32m    469\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    470\u001b[0m )\n\u001b[0;32m    471\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\optimize\\_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    739\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[0;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\optimize\\_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\optimize\\_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\optimize\\_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\optimize\\_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\optimize\\_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_linear_loss.py:316\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 316\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m sw_sum \u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(sample_weight)\n\u001b[0;32m    323\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m sw_sum\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\_loss\\loss.py:258\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    256\u001b[0m     gradient_out \u001b[38;5;241m=\u001b[39m gradient_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_out, gradient_out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for threshold in threshold_list:\n",
    "\n",
    "    print(f'training model on dataset with features with mutual information above {threshold}')\n",
    "\n",
    "    Xw = datasets[threshold]\n",
    "\n",
    "    # for the dataset containing features with mutual information above 0.03:\n",
    "    # we'll train our logistic model with and without PCA since there are many features in this dataset\n",
    "    if threshold == 0.03:\n",
    "\n",
    "\n",
    "        accuraciesl2 = {col: [] for col in Y.columns}\n",
    "        accuraciesl2pca = {col: [] for col in Y.columns}\n",
    "        alphal2 = {col: [] for col in Y.columns}\n",
    "        alphal2pca = {col: [] for col in Y.columns}\n",
    "        feature_importancel2 = {col: [] for col in Y.columns}\n",
    "        feature_importancel2pca = {col: [] for col in Y.columns}\n",
    "        y_true = []\n",
    "        y_predl2 = []\n",
    "        y_predl2pca = []\n",
    "\n",
    "\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "        \n",
    "            pipe.fit(Xw_train, Yw_train)\n",
    "            pipepca.fit(Xw_train, Yw_train)\n",
    "\n",
    "\n",
    "            Yw_pred = pipe.predict(Xw_test)\n",
    "            Yw_predpca = pipepca.predict(Xw_test)\n",
    "\n",
    "            y_predl2.append(Yw_pred)\n",
    "            y_predl2pca.append(Yw_predpca)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuraciesl2[col].append(acc)\n",
    "\n",
    "                acc = accuracy_score(Yw_test[col], Yw_predpca[:, i])\n",
    "                accuraciesl2pca[col].append(acc)\n",
    "\n",
    "                # parameters chosen\n",
    "                best_C = pipe.named_steps['logreg'].estimators_[i].C_[0]\n",
    "                alphal2[col].append(best_C)\n",
    "\n",
    "                best_C = pipepca.named_steps['logreg'].estimators_[i].C_[0]\n",
    "                alphal2pca[col].append(best_C)\n",
    "\n",
    "                # feature importance\n",
    "                coefs = np.abs(pipe.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "                feature_importancel2[col].append(coefs)\n",
    "\n",
    "                coefs = np.abs(pipepca.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "                feature_importancel2pca[col].append(coefs)\n",
    "\n",
    "        ### saving the results\n",
    "        acc = pd.DataFrame(accuraciesl2,columns = Yw.columns)\n",
    "        params = pd.DataFrame(alphal2, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importancel2, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_predl2).reshape(-1, np.array(y_predl2).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies logistic regression, 15y train test.csv')\n",
    "        params.to_csv('results of models/params logistic regression, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance logistic regression, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast logistic regression, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values logistic regression, 15y train test.csv')\n",
    "\n",
    "        acc = pd.DataFrame(accuraciesl2pca,columns = Yw.columns)\n",
    "        params = pd.DataFrame(alphal2pca, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importancel2pca, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_predl2pca).reshape(-1, np.array(y_predl2pca).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} and PCA is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies logistic regression pca, 15y train test.csv')\n",
    "        params.to_csv('results of models/params logistic regression pca, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance logistic regression pca, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast logistic regression pca, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values logistic regression pca, 15y train test.csv')\n",
    "\n",
    "    #for other datasets, we train models without applying a PCA before. \n",
    "    else: \n",
    "\n",
    "\n",
    "        accuraciesl2 = {col: [] for col in Y.columns}\n",
    "        alphal2 = {col: [] for col in Y.columns}\n",
    "        feature_importancel2 = {col: [] for col in Y.columns}\n",
    "        y_true = []\n",
    "        y_predl2 = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            pipe.fit(Xw_train, Yw_train)\n",
    "\n",
    "            Yw_pred = pipe.predict(Xw_test)\n",
    "\n",
    "            y_predl2.append(Yw_pred)\n",
    "\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuraciesl2[col].append(acc)\n",
    "\n",
    "\n",
    "                # alpha optimal choisi\n",
    "                best_C = pipe.named_steps['logreg'].estimators_[i].C_[0]\n",
    "                alphal2[col].append(best_C)\n",
    "\n",
    "                # importance des features = moyenne absolue des coefficients\n",
    "                coefs = np.abs(pipe.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "                feature_importancel2[col].append(coefs)\n",
    "\n",
    "        acc = pd.DataFrame(accuraciesl2,columns = Yw.columns)\n",
    "        params = pd.DataFrame(alphal2, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importancel2, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_predl2).reshape(-1, np.array(y_predl2).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies logistic regression, MI 0.035, 15y train test.csv')\n",
    "        params.to_csv('results of models/params logistic regression, MI 0.035, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance logistic regression, MI 0.035, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast logistic regression, MI 0.035, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values logistic regression, MI 0.035, 15y train test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b634cc3",
   "metadata": {},
   "source": [
    "Logistic regression without PCA, for the dataset containing features with a mutual information above 0.035. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:14<00:00,  1.34s/it]\n",
      "100%|██████████| 79/79 [15:33<00:00, 11.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# accuraciesl2 = {col: [] for col in Y.columns}\n",
    "# alphal2 = {col: [] for col in Y.columns}\n",
    "# feature_importancel2 = {col: [] for col in Y.columns}\n",
    "# y_true = []\n",
    "# y_predl2 = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw35.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw35.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    " \n",
    "#     pipe.fit(Xw_train, Yw_train)\n",
    "\n",
    "\n",
    "\n",
    "#     Yw_pred = pipe.predict(Xw_test)\n",
    "\n",
    "\n",
    "#     y_predl2.append(Yw_pred)\n",
    "\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuraciesl2[col].append(acc)\n",
    "\n",
    "\n",
    "#         # alpha optimal choisi\n",
    "#         best_C = pipe.named_steps['logreg'].estimators_[i].C_[0]\n",
    "#         alphal2[col].append(best_C)\n",
    "\n",
    "#         # importance des features = moyenne absolue des coefficients\n",
    "#         coefs = np.abs(pipe.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "#         feature_importancel2[col].append(coefs)\n",
    "\n",
    "# acc = pd.DataFrame(accuraciesl2,columns = Yw.columns)\n",
    "# params = pd.DataFrame(alphal2, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importancel2, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_predl2).reshape(-1, np.array(y_predl2).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies logistic regression, MI 0.035, 15y train test.csv')\n",
    "# params.to_csv('params logistic regression, MI 0.035, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance logistic regression, MI 0.035, 15y train test.csv')\n",
    "# ypred.to_csv('forecast logistic regression, MI 0.035, 15y train test.csv')\n",
    "# ytrue.to_csv('true values logistic regression, MI 0.035, 15y train test.csv')\n",
    "\n",
    "# acc.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799fe35",
   "metadata": {},
   "source": [
    "Logistic regression without PCA, for the dataset containing features with a mutual information above 0.04. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543876d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuraciesl2 = {col: [] for col in Y.columns}\n",
    "# alphal2 = {col: [] for col in Y.columns}\n",
    "# feature_importancel2 = {col: [] for col in Y.columns}\n",
    "# y_true = []\n",
    "# y_predl2 = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw4.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw4.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    " \n",
    "#     pipe.fit(Xw_train, Yw_train)\n",
    "\n",
    "\n",
    "\n",
    "#     Yw_pred = pipe.predict(Xw_test)\n",
    "\n",
    "\n",
    "#     y_predl2.append(Yw_pred)\n",
    "\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuraciesl2[col].append(acc)\n",
    "\n",
    "\n",
    "#         # alpha optimal choisi\n",
    "#         best_C = pipe.named_steps['logreg'].estimators_[i].C_[0]\n",
    "#         alphal2[col].append(best_C)\n",
    "\n",
    "#         # importance des features = moyenne absolue des coefficients\n",
    "#         coefs = np.abs(pipe.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "#         feature_importancel2[col].append(coefs)\n",
    "\n",
    "# acc = pd.DataFrame(accuraciesl2,columns = Yw.columns)\n",
    "# params = pd.DataFrame(alphal2, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importancel2, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_predl2).reshape(-1, np.array(y_predl2).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies logistic regression, MI 0.04, 15y train test.csv')\n",
    "# params.to_csv('params logistic regression, MI 0.04, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance logistic regression, MI 0.04, 15y train test.csv')\n",
    "# ypred.to_csv('forecast logistic regression, MI 0.04, 15y train test.csv')\n",
    "# ytrue.to_csv('true values logistic regression, MI 0.04, 15y train test.csv')\n",
    "\n",
    "# acc.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b875e",
   "metadata": {},
   "source": [
    "Logistic regression without PCA, for the dataset containing features with a mutual information above 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuraciesl2 = {col: [] for col in Y.columns}\n",
    "# alphal2 = {col: [] for col in Y.columns}\n",
    "# feature_importancel2 = {col: [] for col in Y.columns}\n",
    "# y_true = []\n",
    "# y_predl2 = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw5.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw5.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    " \n",
    "#     pipe.fit(Xw_train, Yw_train)\n",
    "\n",
    "\n",
    "\n",
    "#     Yw_pred = pipe.predict(Xw_test)\n",
    "\n",
    "\n",
    "#     y_predl2.append(Yw_pred)\n",
    "\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuraciesl2[col].append(acc)\n",
    "\n",
    "\n",
    "#         # alpha optimal choisi\n",
    "#         best_C = pipe.named_steps['logreg'].estimators_[i].C_[0]\n",
    "#         alphal2[col].append(best_C)\n",
    "\n",
    "#         # importance des features = moyenne absolue des coefficients\n",
    "#         coefs = np.abs(pipe.named_steps['logreg'].estimators_[i].coef_).flatten()\n",
    "#         feature_importancel2[col].append(coefs)\n",
    "\n",
    "# acc = pd.DataFrame(accuraciesl2,columns = Yw.columns)\n",
    "# params = pd.DataFrame(alphal2, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importancel2, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_predl2).reshape(-1, np.array(y_predl2).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies logistic regression, MI 0.05, 15y train test.csv')\n",
    "# params.to_csv('params logistic regression, MI 0.05, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance logistic regression, MI 0.05, 15y train test.csv')\n",
    "# ypred.to_csv('forecast logistic regression, MI 0.05, 15y train test.csv')\n",
    "# ytrue.to_csv('true values logistic regression, MI 0.05, 15y train test.csv')\n",
    "\n",
    "# acc.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b29dd",
   "metadata": {},
   "source": [
    "## C) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9a75c",
   "metadata": {},
   "source": [
    "We'll now train XGboost models to see whether it can capture non linearities in the data and improve accuracy of out-of-sample predictions. Once again, we'll train some models on the 4 datasets that we created. \n",
    "\n",
    "For the first dataset (with features with a MI>0.03), we'll also train a model that performs a PCA to reduce the number of features before applying XGboost. \n",
    "\n",
    "The pipelines that we'll use are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2777039",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52 * 15\n",
    "window_pred = 4\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "\n",
    "# parameters to test in cross validation \n",
    "param_grid = {\n",
    " 'xgb__estimator__n_estimators': [100, 200],\n",
    " 'xgb__estimator__learning_rate': [0.01, 0.05],\n",
    " 'xgb__estimator__max_depth': [4,7],\n",
    " 'xgb__estimator__subsample': [0.5, 0.7],\n",
    " 'xgb__estimator__colsample_bytree': [0.4, 0.8],\n",
    " 'xgb__estimator__min_child_weight': [5, 10],\n",
    " 'xgb__estimator__reg_alpha': [0.5, 1.0],\n",
    " 'xgb__estimator__reg_lambda': [5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pipeline without PCA \n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', MultiOutputClassifier(\n",
    "        XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "#pipeline with PCA \n",
    "pipepca = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca',PCA(n_components = 0.99)),\n",
    "    ('xgb', MultiOutputClassifier(\n",
    "        XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "#and we'll use gridsearchCV to cross validate the model:\n",
    "GridSearchCV(pipepca, #or pipe\n",
    "            param_grid,\n",
    "            cv=tscv,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ace69",
   "metadata": {},
   "source": [
    "We now train XGBoost models on the datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1eb9b7",
   "metadata": {},
   "source": [
    "# AUDRIC FAIS TOURNER LE BLOC DE CODE CI DESSOUS STP (+ le bloc juste au dessus aussi pour que ca fonctionne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e61701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_list:\n",
    "\n",
    "    print(f'training model on dataset with features with mutual information above {threshold}')\n",
    "\n",
    "    Xw = datasets[threshold]\n",
    "\n",
    "    # for the dataset containing features with mutual information above 0.03:\n",
    "    # we'll train our xgboost model with and without PCA since there are many features in this dataset\n",
    "    if threshold == 0.03:\n",
    "\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies xgboost, 15y train test.csv')\n",
    "        params.to_csv('results of models/params xgboost, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance xgboost, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast xgboost, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values xgboost, 15y train test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #### Now we do the same training but this time we add the PCA in the pipeline before training the model\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "\n",
    "        \n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipepca,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} and PCA is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies xgboost, pca, 15y train test.csv')\n",
    "        params.to_csv('results of models/params xgboost, pca, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance xgboost, pca, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast xgboost, pca, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values xgboost, pca, 15y train test.csv')\n",
    "    \n",
    "\n",
    "    # for other datasets with larger mutual information threshold, we don't apply PCA and train the model directly \n",
    "    else:\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "        \n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv(f'results of models/accuracies xgboost, MI {threshold}, 15y train test.csv')\n",
    "        params.to_csv(f'results of models/params xgboost, MI {threshold}, 15y train test.csv')\n",
    "        feature_imp.to_csv(f'results of models/feature importance xgboost, MI {threshold}, 15y train test.csv')\n",
    "        ypred.to_csv(f'results of models/forecast xgboost, MI {threshold}, 15y train test.csv')\n",
    "        ytrue.to_csv(f'results of models/true values xgboost, MI {threshold}, 15y train test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# params_by_target = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv=tscv,\n",
    "#                         scoring='accuracy',\n",
    "#                         n_jobs=-1,\n",
    "#                         verbose=0)\n",
    "\n",
    "#     grid.fit(Xw_train, Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         print(col, np.mean(accuracies[col]))\n",
    "\n",
    "#         # feature importance pour la i-ème sortie\n",
    "#         est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "#         importance = est.feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "\n",
    "#         # hyperparamètres de l'estimateur i\n",
    "#         params = est.get_params()\n",
    "#         params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies xgboost, 15y train test.csv')\n",
    "# params.to_csv('params xgboost, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance xgboost, 15y train test.csv')\n",
    "# ypred.to_csv('forecast xgboost, 15y train test.csv')\n",
    "# ytrue.to_csv('true values xgboost, 15y train test.csv')\n",
    "\n",
    "# print(acc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bb627",
   "metadata": {},
   "source": [
    "We now train XGBoost models for the dataset containing features with a mutual information above 0.03, but this time we include a PCA to reduce the number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# params_by_target = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "#     grid = GridSearchCV(pipepca,\n",
    "#                         param_grid,\n",
    "#                         cv=tscv,\n",
    "#                         scoring='accuracy',\n",
    "#                         n_jobs=-1,\n",
    "#                         verbose=0)\n",
    "\n",
    "#     grid.fit(Xw_train, Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         print(col, np.mean(accuracies[col]))\n",
    "\n",
    "#         # feature importance pour la i-ème sortie\n",
    "#         est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "#         importance = est.feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "\n",
    "#         # hyperparamètres de l'estimateur i\n",
    "#         params = est.get_params()\n",
    "#         params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies xgboost, pca, 15y train test.csv')\n",
    "# params.to_csv('params xgboost, pca, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance xgboost, pca, 15y train test.csv')\n",
    "# ypred.to_csv('forecast xgboost, pca, 15y train test.csv')\n",
    "# ytrue.to_csv('true values xgboost, pca, 15y train test.csv')\n",
    "\n",
    "# print(acc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2eb4cb",
   "metadata": {},
   "source": [
    "Results are surprisingly very disappointing for XGBoost. When looking at predictions made by this model, we see that the prediction vectors are almost always 0. There are very few ones in the predictions, and since classes are well balanced, this results in a performance close to predicting yields randomly. \n",
    "\n",
    "We will now try to run this model on the other datasets of features such that their mutual information is >0.035 or 0.04 or 0.05 to see if there are any improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b454c29",
   "metadata": {},
   "source": [
    "For the dataset with MI >0.035:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# params_by_target = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw35.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw35.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv=tscv,\n",
    "#                         scoring='accuracy',\n",
    "#                         n_jobs=-1,\n",
    "#                         verbose=0)\n",
    "\n",
    "#     grid.fit(Xw_train, Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         print(col, np.mean(accuracies[col]))\n",
    "\n",
    "#         # feature importance pour la i-ème sortie\n",
    "#         est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "#         importance = est.feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "\n",
    "#         # hyperparamètres de l'estimateur i\n",
    "#         params = est.get_params()\n",
    "#         params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "# acc.to_csv('accuracies xgboost, MI 0.035, 15y train test.csv')\n",
    "# params.to_csv('params xgboost, MI 0.035, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance xgboost, MI 0.035, 15y train test.csv')\n",
    "# ypred.to_csv('forecast xgboost, MI 0.035, 15y train test.csv')\n",
    "# ytrue.to_csv('true values xgboost, MI 0.035, 15y train test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f8acb",
   "metadata": {},
   "source": [
    "For the dataset with MI > 0.04:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38405575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:16<00:00,  1.46s/it]\n",
      "  1%|▏         | 1/79 [10:36<13:47:11, 636.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.5\n",
      "Y_DGS3MO 0.75\n",
      "Y_DGS6MO 0.5\n",
      "Y_DGS1 0.0\n",
      "Y_DGS2 0.0\n",
      "Y_DGS3 0.25\n",
      "Y_DGS5 0.25\n",
      "Y_DGS7 0.0\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/79 [20:35<13:08:54, 614.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.5\n",
      "Y_DGS3MO 0.625\n",
      "Y_DGS6MO 0.5\n",
      "Y_DGS1 0.125\n",
      "Y_DGS2 0.125\n",
      "Y_DGS3 0.25\n",
      "Y_DGS5 0.25\n",
      "Y_DGS7 0.125\n",
      "Y_DGS10 0.375\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/79 [29:53<12:25:26, 588.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.5\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.5833333333333334\n",
      "Y_DGS1 0.16666666666666666\n",
      "Y_DGS2 0.25\n",
      "Y_DGS3 0.3333333333333333\n",
      "Y_DGS5 0.25\n",
      "Y_DGS7 0.25\n",
      "Y_DGS10 0.3333333333333333\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/79 [39:36<12:13:06, 586.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.4375\n",
      "Y_DGS3MO 0.75\n",
      "Y_DGS6MO 0.4375\n",
      "Y_DGS1 0.25\n",
      "Y_DGS2 0.25\n",
      "Y_DGS3 0.4375\n",
      "Y_DGS5 0.375\n",
      "Y_DGS7 0.375\n",
      "Y_DGS10 0.375\n",
      "Y_DGS20 0.4375\n",
      "Y_DGS30 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/79 [48:28<11:38:59, 566.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.5\n",
      "Y_DGS3MO 0.75\n",
      "Y_DGS6MO 0.55\n",
      "Y_DGS1 0.3\n",
      "Y_DGS2 0.3\n",
      "Y_DGS3 0.45\n",
      "Y_DGS5 0.45\n",
      "Y_DGS7 0.4\n",
      "Y_DGS10 0.35\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/79 [57:29<11:18:45, 557.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.5416666666666666\n",
      "Y_DGS3MO 0.7083333333333334\n",
      "Y_DGS6MO 0.5833333333333334\n",
      "Y_DGS1 0.375\n",
      "Y_DGS2 0.375\n",
      "Y_DGS3 0.5\n",
      "Y_DGS5 0.5\n",
      "Y_DGS7 0.4166666666666667\n",
      "Y_DGS10 0.3333333333333333\n",
      "Y_DGS20 0.4583333333333333\n",
      "Y_DGS30 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/79 [1:06:40<11:06:46, 555.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6071428571428571\n",
      "Y_DGS3MO 0.75\n",
      "Y_DGS6MO 0.6071428571428571\n",
      "Y_DGS1 0.42857142857142855\n",
      "Y_DGS2 0.4642857142857143\n",
      "Y_DGS3 0.5714285714285714\n",
      "Y_DGS5 0.5714285714285714\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.42857142857142855\n",
      "Y_DGS20 0.4642857142857143\n",
      "Y_DGS30 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/79 [1:16:33<11:11:52, 567.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.59375\n",
      "Y_DGS3MO 0.71875\n",
      "Y_DGS6MO 0.59375\n",
      "Y_DGS1 0.46875\n",
      "Y_DGS2 0.5\n",
      "Y_DGS3 0.59375\n",
      "Y_DGS5 0.5625\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.4375\n",
      "Y_DGS20 0.46875\n",
      "Y_DGS30 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/79 [1:24:37<10:31:47, 541.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6111111111111112\n",
      "Y_DGS3MO 0.7222222222222222\n",
      "Y_DGS6MO 0.6111111111111112\n",
      "Y_DGS1 0.5\n",
      "Y_DGS2 0.5277777777777778\n",
      "Y_DGS3 0.6111111111111112\n",
      "Y_DGS5 0.5833333333333334\n",
      "Y_DGS7 0.5277777777777778\n",
      "Y_DGS10 0.4722222222222222\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 10/79 [1:32:55<10:07:19, 528.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6\n",
      "Y_DGS3MO 0.7\n",
      "Y_DGS6MO 0.575\n",
      "Y_DGS1 0.475\n",
      "Y_DGS2 0.5\n",
      "Y_DGS3 0.6\n",
      "Y_DGS5 0.575\n",
      "Y_DGS7 0.525\n",
      "Y_DGS10 0.475\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/79 [1:41:47<9:59:46, 529.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6136363636363636\n",
      "Y_DGS3MO 0.7272727272727273\n",
      "Y_DGS6MO 0.5909090909090909\n",
      "Y_DGS1 0.5\n",
      "Y_DGS2 0.5227272727272727\n",
      "Y_DGS3 0.6136363636363636\n",
      "Y_DGS5 0.5909090909090909\n",
      "Y_DGS7 0.5454545454545454\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5227272727272727\n",
      "Y_DGS30 0.5681818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/79 [1:50:53<9:56:30, 534.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6458333333333334\n",
      "Y_DGS3MO 0.7291666666666666\n",
      "Y_DGS6MO 0.5833333333333334\n",
      "Y_DGS1 0.5\n",
      "Y_DGS2 0.5208333333333334\n",
      "Y_DGS3 0.6041666666666666\n",
      "Y_DGS5 0.5833333333333334\n",
      "Y_DGS7 0.5416666666666666\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5416666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/79 [2:01:52<10:29:31, 572.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6346153846153846\n",
      "Y_DGS3MO 0.6923076923076923\n",
      "Y_DGS6MO 0.5769230769230769\n",
      "Y_DGS1 0.5\n",
      "Y_DGS2 0.5576923076923077\n",
      "Y_DGS3 0.5961538461538461\n",
      "Y_DGS5 0.5961538461538461\n",
      "Y_DGS7 0.5384615384615384\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5192307692307693\n",
      "Y_DGS30 0.5576923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/79 [2:12:54<10:49:09, 599.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.625\n",
      "Y_DGS3MO 0.6785714285714286\n",
      "Y_DGS6MO 0.5714285714285714\n",
      "Y_DGS1 0.5178571428571429\n",
      "Y_DGS2 0.5714285714285714\n",
      "Y_DGS3 0.6071428571428571\n",
      "Y_DGS5 0.6071428571428571\n",
      "Y_DGS7 0.5535714285714286\n",
      "Y_DGS10 0.5178571428571429\n",
      "Y_DGS20 0.5357142857142857\n",
      "Y_DGS30 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/79 [2:23:49<10:57:07, 616.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6166666666666667\n",
      "Y_DGS3MO 0.65\n",
      "Y_DGS6MO 0.5833333333333334\n",
      "Y_DGS1 0.5333333333333333\n",
      "Y_DGS2 0.5666666666666667\n",
      "Y_DGS3 0.6166666666666667\n",
      "Y_DGS5 0.6166666666666667\n",
      "Y_DGS7 0.5666666666666667\n",
      "Y_DGS10 0.5166666666666667\n",
      "Y_DGS20 0.5333333333333333\n",
      "Y_DGS30 0.5666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/79 [2:35:45<11:18:22, 646.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.609375\n",
      "Y_DGS3MO 0.640625\n",
      "Y_DGS6MO 0.59375\n",
      "Y_DGS1 0.546875\n",
      "Y_DGS2 0.5625\n",
      "Y_DGS3 0.609375\n",
      "Y_DGS5 0.609375\n",
      "Y_DGS7 0.578125\n",
      "Y_DGS10 0.53125\n",
      "Y_DGS20 0.546875\n",
      "Y_DGS30 0.578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 17/79 [2:44:29<10:29:41, 609.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6323529411764706\n",
      "Y_DGS3MO 0.6617647058823529\n",
      "Y_DGS6MO 0.6176470588235294\n",
      "Y_DGS1 0.5735294117647058\n",
      "Y_DGS2 0.5882352941176471\n",
      "Y_DGS3 0.6176470588235294\n",
      "Y_DGS5 0.6176470588235294\n",
      "Y_DGS7 0.5882352941176471\n",
      "Y_DGS10 0.5441176470588235\n",
      "Y_DGS20 0.5441176470588235\n",
      "Y_DGS30 0.5882352941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 18/79 [2:56:05<10:46:02, 635.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.625\n",
      "Y_DGS3MO 0.6527777777777778\n",
      "Y_DGS6MO 0.6111111111111112\n",
      "Y_DGS1 0.5555555555555556\n",
      "Y_DGS2 0.5972222222222222\n",
      "Y_DGS3 0.6388888888888888\n",
      "Y_DGS5 0.625\n",
      "Y_DGS7 0.5972222222222222\n",
      "Y_DGS10 0.5555555555555556\n",
      "Y_DGS20 0.5555555555555556\n",
      "Y_DGS30 0.5972222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/79 [3:04:48<10:01:33, 601.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6447368421052632\n",
      "Y_DGS3MO 0.6710526315789473\n",
      "Y_DGS6MO 0.6052631578947368\n",
      "Y_DGS1 0.5657894736842105\n",
      "Y_DGS2 0.6052631578947368\n",
      "Y_DGS3 0.6447368421052632\n",
      "Y_DGS5 0.631578947368421\n",
      "Y_DGS7 0.5921052631578947\n",
      "Y_DGS10 0.5394736842105263\n",
      "Y_DGS20 0.5394736842105263\n",
      "Y_DGS30 0.5789473684210527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/79 [3:13:21<9:25:28, 575.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6375\n",
      "Y_DGS3MO 0.65\n",
      "Y_DGS6MO 0.6125\n",
      "Y_DGS1 0.575\n",
      "Y_DGS2 0.6125\n",
      "Y_DGS3 0.65\n",
      "Y_DGS5 0.6375\n",
      "Y_DGS7 0.6\n",
      "Y_DGS10 0.55\n",
      "Y_DGS20 0.5375\n",
      "Y_DGS30 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 21/79 [3:21:20<8:48:09, 546.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6309523809523809\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.6309523809523809\n",
      "Y_DGS1 0.5952380952380952\n",
      "Y_DGS2 0.6309523809523809\n",
      "Y_DGS3 0.6666666666666666\n",
      "Y_DGS5 0.6428571428571429\n",
      "Y_DGS7 0.6071428571428571\n",
      "Y_DGS10 0.5595238095238095\n",
      "Y_DGS20 0.5476190476190477\n",
      "Y_DGS30 0.5595238095238095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/79 [3:29:16<8:18:57, 525.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6363636363636364\n",
      "Y_DGS3MO 0.6704545454545454\n",
      "Y_DGS6MO 0.625\n",
      "Y_DGS1 0.5909090909090909\n",
      "Y_DGS2 0.625\n",
      "Y_DGS3 0.6590909090909091\n",
      "Y_DGS5 0.6363636363636364\n",
      "Y_DGS7 0.6022727272727273\n",
      "Y_DGS10 0.5568181818181818\n",
      "Y_DGS20 0.5454545454545454\n",
      "Y_DGS30 0.5568181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/79 [3:37:52<8:07:36, 522.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6304347826086957\n",
      "Y_DGS3MO 0.6739130434782609\n",
      "Y_DGS6MO 0.6304347826086957\n",
      "Y_DGS1 0.5978260869565217\n",
      "Y_DGS2 0.6304347826086957\n",
      "Y_DGS3 0.6630434782608695\n",
      "Y_DGS5 0.6304347826086957\n",
      "Y_DGS7 0.6086956521739131\n",
      "Y_DGS10 0.5652173913043478\n",
      "Y_DGS20 0.5543478260869565\n",
      "Y_DGS30 0.5652173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/79 [3:46:17<7:54:06, 517.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6354166666666666\n",
      "Y_DGS3MO 0.6770833333333334\n",
      "Y_DGS6MO 0.6354166666666666\n",
      "Y_DGS1 0.6041666666666666\n",
      "Y_DGS2 0.6145833333333334\n",
      "Y_DGS3 0.65625\n",
      "Y_DGS5 0.6145833333333334\n",
      "Y_DGS7 0.59375\n",
      "Y_DGS10 0.5520833333333334\n",
      "Y_DGS20 0.5416666666666666\n",
      "Y_DGS30 0.5520833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 25/79 [3:54:58<7:46:34, 518.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.64\n",
      "Y_DGS3MO 0.67\n",
      "Y_DGS6MO 0.65\n",
      "Y_DGS1 0.61\n",
      "Y_DGS2 0.61\n",
      "Y_DGS3 0.65\n",
      "Y_DGS5 0.61\n",
      "Y_DGS7 0.59\n",
      "Y_DGS10 0.55\n",
      "Y_DGS20 0.54\n",
      "Y_DGS30 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 26/79 [4:03:30<7:36:12, 516.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6538461538461539\n",
      "Y_DGS3MO 0.6730769230769231\n",
      "Y_DGS6MO 0.6634615384615384\n",
      "Y_DGS1 0.625\n",
      "Y_DGS2 0.6153846153846154\n",
      "Y_DGS3 0.6442307692307693\n",
      "Y_DGS5 0.6057692307692307\n",
      "Y_DGS7 0.5865384615384616\n",
      "Y_DGS10 0.5384615384615384\n",
      "Y_DGS20 0.5288461538461539\n",
      "Y_DGS30 0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/79 [4:11:57<7:25:10, 513.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6481481481481481\n",
      "Y_DGS3MO 0.6759259259259259\n",
      "Y_DGS6MO 0.6666666666666666\n",
      "Y_DGS1 0.6296296296296297\n",
      "Y_DGS2 0.6203703703703703\n",
      "Y_DGS3 0.6481481481481481\n",
      "Y_DGS5 0.6018518518518519\n",
      "Y_DGS7 0.5925925925925926\n",
      "Y_DGS10 0.5462962962962963\n",
      "Y_DGS20 0.5370370370370371\n",
      "Y_DGS30 0.5462962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/79 [4:20:28<7:15:50, 512.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6607142857142857\n",
      "Y_DGS3MO 0.6785714285714286\n",
      "Y_DGS6MO 0.6696428571428571\n",
      "Y_DGS1 0.6428571428571429\n",
      "Y_DGS2 0.625\n",
      "Y_DGS3 0.6517857142857143\n",
      "Y_DGS5 0.5982142857142857\n",
      "Y_DGS7 0.5892857142857143\n",
      "Y_DGS10 0.5446428571428571\n",
      "Y_DGS20 0.5357142857142857\n",
      "Y_DGS30 0.5446428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 29/79 [4:29:12<7:09:58, 515.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6551724137931034\n",
      "Y_DGS3MO 0.6810344827586207\n",
      "Y_DGS6MO 0.6724137931034483\n",
      "Y_DGS1 0.6379310344827587\n",
      "Y_DGS2 0.6206896551724138\n",
      "Y_DGS3 0.6379310344827587\n",
      "Y_DGS5 0.5775862068965517\n",
      "Y_DGS7 0.5689655172413793\n",
      "Y_DGS10 0.5258620689655172\n",
      "Y_DGS20 0.5172413793103449\n",
      "Y_DGS30 0.5258620689655172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/79 [4:38:02<7:04:54, 520.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6583333333333333\n",
      "Y_DGS3MO 0.6833333333333333\n",
      "Y_DGS6MO 0.6666666666666666\n",
      "Y_DGS1 0.6416666666666667\n",
      "Y_DGS2 0.625\n",
      "Y_DGS3 0.6333333333333333\n",
      "Y_DGS5 0.5666666666666667\n",
      "Y_DGS7 0.5583333333333333\n",
      "Y_DGS10 0.5166666666666667\n",
      "Y_DGS20 0.5083333333333333\n",
      "Y_DGS30 0.5166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/79 [4:45:54<6:44:44, 505.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6693548387096774\n",
      "Y_DGS3MO 0.6854838709677419\n",
      "Y_DGS6MO 0.6693548387096774\n",
      "Y_DGS1 0.6370967741935484\n",
      "Y_DGS2 0.6290322580645161\n",
      "Y_DGS3 0.6370967741935484\n",
      "Y_DGS5 0.5725806451612904\n",
      "Y_DGS7 0.5645161290322581\n",
      "Y_DGS10 0.5241935483870968\n",
      "Y_DGS20 0.5241935483870968\n",
      "Y_DGS30 0.532258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 32/79 [4:54:46<6:42:21, 513.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6796875\n",
      "Y_DGS3MO 0.6875\n",
      "Y_DGS6MO 0.671875\n",
      "Y_DGS1 0.640625\n",
      "Y_DGS2 0.625\n",
      "Y_DGS3 0.625\n",
      "Y_DGS5 0.5625\n",
      "Y_DGS7 0.5625\n",
      "Y_DGS10 0.5234375\n",
      "Y_DGS20 0.5234375\n",
      "Y_DGS30 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 33/79 [5:03:53<6:41:33, 523.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6742424242424242\n",
      "Y_DGS3MO 0.6742424242424242\n",
      "Y_DGS6MO 0.6590909090909091\n",
      "Y_DGS1 0.6363636363636364\n",
      "Y_DGS2 0.6212121212121212\n",
      "Y_DGS3 0.6212121212121212\n",
      "Y_DGS5 0.5681818181818182\n",
      "Y_DGS7 0.5681818181818182\n",
      "Y_DGS10 0.5378787878787878\n",
      "Y_DGS20 0.5378787878787878\n",
      "Y_DGS30 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 34/79 [5:11:42<6:20:31, 507.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6764705882352942\n",
      "Y_DGS3MO 0.6691176470588235\n",
      "Y_DGS6MO 0.6691176470588235\n",
      "Y_DGS1 0.6470588235294118\n",
      "Y_DGS2 0.6176470588235294\n",
      "Y_DGS3 0.6176470588235294\n",
      "Y_DGS5 0.5735294117647058\n",
      "Y_DGS7 0.5735294117647058\n",
      "Y_DGS10 0.5441176470588235\n",
      "Y_DGS20 0.5441176470588235\n",
      "Y_DGS30 0.5514705882352942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/79 [5:21:00<6:23:00, 522.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6857142857142857\n",
      "Y_DGS3MO 0.6714285714285714\n",
      "Y_DGS6MO 0.6714285714285714\n",
      "Y_DGS1 0.65\n",
      "Y_DGS2 0.6142857142857143\n",
      "Y_DGS3 0.6142857142857143\n",
      "Y_DGS5 0.5714285714285714\n",
      "Y_DGS7 0.5714285714285714\n",
      "Y_DGS10 0.55\n",
      "Y_DGS20 0.55\n",
      "Y_DGS30 0.5571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 36/79 [5:28:34<5:59:40, 501.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6875\n",
      "Y_DGS3MO 0.6805555555555556\n",
      "Y_DGS6MO 0.6736111111111112\n",
      "Y_DGS1 0.6458333333333334\n",
      "Y_DGS2 0.6180555555555556\n",
      "Y_DGS3 0.6111111111111112\n",
      "Y_DGS5 0.5694444444444444\n",
      "Y_DGS7 0.5694444444444444\n",
      "Y_DGS10 0.5416666666666666\n",
      "Y_DGS20 0.5486111111111112\n",
      "Y_DGS30 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 37/79 [5:37:35<5:59:33, 513.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6891891891891891\n",
      "Y_DGS3MO 0.6756756756756757\n",
      "Y_DGS6MO 0.6756756756756757\n",
      "Y_DGS1 0.6418918918918919\n",
      "Y_DGS2 0.6148648648648649\n",
      "Y_DGS3 0.6013513513513513\n",
      "Y_DGS5 0.5608108108108109\n",
      "Y_DGS7 0.5608108108108109\n",
      "Y_DGS10 0.527027027027027\n",
      "Y_DGS20 0.5405405405405406\n",
      "Y_DGS30 0.5472972972972973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/79 [5:47:05<6:02:33, 530.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6776315789473685\n",
      "Y_DGS3MO 0.6776315789473685\n",
      "Y_DGS6MO 0.6776315789473685\n",
      "Y_DGS1 0.631578947368421\n",
      "Y_DGS2 0.6118421052631579\n",
      "Y_DGS3 0.5986842105263158\n",
      "Y_DGS5 0.5592105263157895\n",
      "Y_DGS7 0.5592105263157895\n",
      "Y_DGS10 0.5328947368421053\n",
      "Y_DGS20 0.5460526315789473\n",
      "Y_DGS30 0.5526315789473685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/79 [5:55:51<5:52:46, 529.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6794871794871795\n",
      "Y_DGS3MO 0.6794871794871795\n",
      "Y_DGS6MO 0.6794871794871795\n",
      "Y_DGS1 0.6153846153846154\n",
      "Y_DGS2 0.6089743589743589\n",
      "Y_DGS3 0.5897435897435898\n",
      "Y_DGS5 0.5641025641025641\n",
      "Y_DGS7 0.5641025641025641\n",
      "Y_DGS10 0.5384615384615384\n",
      "Y_DGS20 0.5512820512820513\n",
      "Y_DGS30 0.5576923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 40/79 [6:05:41<5:55:44, 547.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.675\n",
      "Y_DGS3MO 0.68125\n",
      "Y_DGS6MO 0.66875\n",
      "Y_DGS1 0.60625\n",
      "Y_DGS2 0.6\n",
      "Y_DGS3 0.5875\n",
      "Y_DGS5 0.55625\n",
      "Y_DGS7 0.55625\n",
      "Y_DGS10 0.53125\n",
      "Y_DGS20 0.55\n",
      "Y_DGS30 0.55625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 41/79 [6:15:01<5:49:05, 551.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6829268292682927\n",
      "Y_DGS3MO 0.6646341463414634\n",
      "Y_DGS6MO 0.6524390243902439\n",
      "Y_DGS1 0.5914634146341463\n",
      "Y_DGS2 0.5853658536585366\n",
      "Y_DGS3 0.573170731707317\n",
      "Y_DGS5 0.5487804878048781\n",
      "Y_DGS7 0.5487804878048781\n",
      "Y_DGS10 0.524390243902439\n",
      "Y_DGS20 0.5426829268292683\n",
      "Y_DGS30 0.5548780487804879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 42/79 [6:24:09<5:39:15, 550.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6845238095238095\n",
      "Y_DGS3MO 0.6547619047619048\n",
      "Y_DGS6MO 0.6547619047619048\n",
      "Y_DGS1 0.5892857142857143\n",
      "Y_DGS2 0.5892857142857143\n",
      "Y_DGS3 0.5654761904761905\n",
      "Y_DGS5 0.5416666666666666\n",
      "Y_DGS7 0.5416666666666666\n",
      "Y_DGS10 0.5238095238095238\n",
      "Y_DGS20 0.5357142857142857\n",
      "Y_DGS30 0.5476190476190477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/79 [6:32:04<5:16:37, 527.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6744186046511628\n",
      "Y_DGS3MO 0.6511627906976745\n",
      "Y_DGS6MO 0.6453488372093024\n",
      "Y_DGS1 0.5813953488372093\n",
      "Y_DGS2 0.5813953488372093\n",
      "Y_DGS3 0.5581395348837209\n",
      "Y_DGS5 0.5348837209302325\n",
      "Y_DGS7 0.5348837209302325\n",
      "Y_DGS10 0.5174418604651163\n",
      "Y_DGS20 0.5290697674418605\n",
      "Y_DGS30 0.5406976744186046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 44/79 [6:40:06<4:59:49, 513.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6647727272727273\n",
      "Y_DGS3MO 0.6534090909090909\n",
      "Y_DGS6MO 0.6534090909090909\n",
      "Y_DGS1 0.5738636363636364\n",
      "Y_DGS2 0.5738636363636364\n",
      "Y_DGS3 0.5511363636363636\n",
      "Y_DGS5 0.5284090909090909\n",
      "Y_DGS7 0.5284090909090909\n",
      "Y_DGS10 0.5113636363636364\n",
      "Y_DGS20 0.5227272727272727\n",
      "Y_DGS30 0.5340909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 45/79 [6:47:51<4:42:57, 499.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6611111111111111\n",
      "Y_DGS3MO 0.6555555555555556\n",
      "Y_DGS6MO 0.6555555555555556\n",
      "Y_DGS1 0.5666666666666667\n",
      "Y_DGS2 0.5722222222222222\n",
      "Y_DGS3 0.55\n",
      "Y_DGS5 0.5333333333333333\n",
      "Y_DGS7 0.5333333333333333\n",
      "Y_DGS10 0.5166666666666667\n",
      "Y_DGS20 0.5277777777777778\n",
      "Y_DGS30 0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 46/79 [6:57:19<4:45:56, 519.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6467391304347826\n",
      "Y_DGS3MO 0.6467391304347826\n",
      "Y_DGS6MO 0.6630434782608695\n",
      "Y_DGS1 0.5597826086956522\n",
      "Y_DGS2 0.5652173913043478\n",
      "Y_DGS3 0.5434782608695652\n",
      "Y_DGS5 0.5271739130434783\n",
      "Y_DGS7 0.5271739130434783\n",
      "Y_DGS10 0.5108695652173914\n",
      "Y_DGS20 0.5217391304347826\n",
      "Y_DGS30 0.5271739130434783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/79 [7:04:59<4:27:38, 501.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6382978723404256\n",
      "Y_DGS3MO 0.648936170212766\n",
      "Y_DGS6MO 0.6702127659574468\n",
      "Y_DGS1 0.5585106382978723\n",
      "Y_DGS2 0.5638297872340425\n",
      "Y_DGS3 0.5478723404255319\n",
      "Y_DGS5 0.5319148936170213\n",
      "Y_DGS7 0.5319148936170213\n",
      "Y_DGS10 0.5159574468085106\n",
      "Y_DGS20 0.526595744680851\n",
      "Y_DGS30 0.5319148936170213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 48/79 [7:12:22<4:10:13, 484.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.640625\n",
      "Y_DGS3MO 0.6510416666666666\n",
      "Y_DGS6MO 0.671875\n",
      "Y_DGS1 0.5625\n",
      "Y_DGS2 0.5625\n",
      "Y_DGS3 0.5520833333333334\n",
      "Y_DGS5 0.5364583333333334\n",
      "Y_DGS7 0.53125\n",
      "Y_DGS10 0.515625\n",
      "Y_DGS20 0.5260416666666666\n",
      "Y_DGS30 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 49/79 [7:19:46<3:56:10, 472.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6428571428571429\n",
      "Y_DGS3MO 0.6581632653061225\n",
      "Y_DGS6MO 0.6785714285714286\n",
      "Y_DGS1 0.5561224489795918\n",
      "Y_DGS2 0.5561224489795918\n",
      "Y_DGS3 0.5408163265306123\n",
      "Y_DGS5 0.5255102040816326\n",
      "Y_DGS7 0.5204081632653061\n",
      "Y_DGS10 0.5051020408163265\n",
      "Y_DGS20 0.5204081632653061\n",
      "Y_DGS30 0.5255102040816326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 50/79 [7:27:05<3:43:23, 462.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.645\n",
      "Y_DGS3MO 0.665\n",
      "Y_DGS6MO 0.685\n",
      "Y_DGS1 0.55\n",
      "Y_DGS2 0.545\n",
      "Y_DGS3 0.53\n",
      "Y_DGS5 0.515\n",
      "Y_DGS7 0.51\n",
      "Y_DGS10 0.495\n",
      "Y_DGS20 0.51\n",
      "Y_DGS30 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 51/79 [7:34:15<3:31:07, 452.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6470588235294118\n",
      "Y_DGS3MO 0.6715686274509803\n",
      "Y_DGS6MO 0.6911764705882353\n",
      "Y_DGS1 0.5441176470588235\n",
      "Y_DGS2 0.5392156862745098\n",
      "Y_DGS3 0.5245098039215687\n",
      "Y_DGS5 0.5196078431372549\n",
      "Y_DGS7 0.5098039215686274\n",
      "Y_DGS10 0.4950980392156863\n",
      "Y_DGS20 0.5098039215686274\n",
      "Y_DGS30 0.5147058823529411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 52/79 [7:41:19<3:19:47, 443.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6442307692307693\n",
      "Y_DGS3MO 0.6730769230769231\n",
      "Y_DGS6MO 0.6875\n",
      "Y_DGS1 0.5432692307692307\n",
      "Y_DGS2 0.5336538461538461\n",
      "Y_DGS3 0.5288461538461539\n",
      "Y_DGS5 0.5144230769230769\n",
      "Y_DGS7 0.5048076923076923\n",
      "Y_DGS10 0.4855769230769231\n",
      "Y_DGS20 0.5096153846153846\n",
      "Y_DGS30 0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 53/79 [7:48:25<3:10:06, 438.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6415094339622641\n",
      "Y_DGS3MO 0.6698113207547169\n",
      "Y_DGS6MO 0.6839622641509434\n",
      "Y_DGS1 0.5377358490566038\n",
      "Y_DGS2 0.5283018867924528\n",
      "Y_DGS3 0.5235849056603774\n",
      "Y_DGS5 0.5094339622641509\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.4811320754716981\n",
      "Y_DGS20 0.5047169811320755\n",
      "Y_DGS30 0.5235849056603774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/79 [7:55:27<3:00:39, 433.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6435185185185185\n",
      "Y_DGS3MO 0.6712962962962963\n",
      "Y_DGS6MO 0.6851851851851852\n",
      "Y_DGS1 0.5370370370370371\n",
      "Y_DGS2 0.5324074074074074\n",
      "Y_DGS3 0.5277777777777778\n",
      "Y_DGS5 0.5046296296296297\n",
      "Y_DGS7 0.49074074074074076\n",
      "Y_DGS10 0.47685185185185186\n",
      "Y_DGS20 0.5138888888888888\n",
      "Y_DGS30 0.5277777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 55/79 [8:02:32<2:52:26, 431.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6409090909090909\n",
      "Y_DGS3MO 0.6727272727272727\n",
      "Y_DGS6MO 0.6909090909090909\n",
      "Y_DGS1 0.5272727272727272\n",
      "Y_DGS2 0.5227272727272727\n",
      "Y_DGS3 0.5181818181818182\n",
      "Y_DGS5 0.5\n",
      "Y_DGS7 0.4863636363636364\n",
      "Y_DGS10 0.4681818181818182\n",
      "Y_DGS20 0.509090909090909\n",
      "Y_DGS30 0.5227272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 56/79 [8:09:34<2:44:09, 428.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6383928571428571\n",
      "Y_DGS3MO 0.6741071428571429\n",
      "Y_DGS6MO 0.6875\n",
      "Y_DGS1 0.5223214285714286\n",
      "Y_DGS2 0.5223214285714286\n",
      "Y_DGS3 0.5133928571428571\n",
      "Y_DGS5 0.4955357142857143\n",
      "Y_DGS7 0.48214285714285715\n",
      "Y_DGS10 0.4642857142857143\n",
      "Y_DGS20 0.5089285714285714\n",
      "Y_DGS30 0.5267857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 57/79 [8:16:33<2:36:03, 425.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.631578947368421\n",
      "Y_DGS3MO 0.6754385964912281\n",
      "Y_DGS6MO 0.6929824561403509\n",
      "Y_DGS1 0.5175438596491229\n",
      "Y_DGS2 0.5175438596491229\n",
      "Y_DGS3 0.5087719298245614\n",
      "Y_DGS5 0.49122807017543857\n",
      "Y_DGS7 0.4780701754385965\n",
      "Y_DGS10 0.4605263157894737\n",
      "Y_DGS20 0.5043859649122807\n",
      "Y_DGS30 0.5219298245614035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 58/79 [8:23:37<2:28:45, 425.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.625\n",
      "Y_DGS3MO 0.6724137931034483\n",
      "Y_DGS6MO 0.6939655172413793\n",
      "Y_DGS1 0.5129310344827587\n",
      "Y_DGS2 0.5172413793103449\n",
      "Y_DGS3 0.5086206896551724\n",
      "Y_DGS5 0.49137931034482757\n",
      "Y_DGS7 0.4827586206896552\n",
      "Y_DGS10 0.46120689655172414\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5172413793103449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 59/79 [8:30:35<2:20:58, 422.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6186440677966102\n",
      "Y_DGS3MO 0.6694915254237288\n",
      "Y_DGS6MO 0.690677966101695\n",
      "Y_DGS1 0.5084745762711864\n",
      "Y_DGS2 0.5169491525423728\n",
      "Y_DGS3 0.5042372881355932\n",
      "Y_DGS5 0.4915254237288136\n",
      "Y_DGS7 0.4830508474576271\n",
      "Y_DGS10 0.4576271186440678\n",
      "Y_DGS20 0.5042372881355932\n",
      "Y_DGS30 0.5169491525423728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 60/79 [8:37:33<2:13:29, 421.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6125\n",
      "Y_DGS3MO 0.675\n",
      "Y_DGS6MO 0.6916666666666667\n",
      "Y_DGS1 0.5041666666666667\n",
      "Y_DGS2 0.5208333333333334\n",
      "Y_DGS3 0.5041666666666667\n",
      "Y_DGS5 0.49166666666666664\n",
      "Y_DGS7 0.4875\n",
      "Y_DGS10 0.4625\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 61/79 [8:44:20<2:05:08, 417.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.610655737704918\n",
      "Y_DGS3MO 0.6762295081967213\n",
      "Y_DGS6MO 0.6926229508196722\n",
      "Y_DGS1 0.5\n",
      "Y_DGS2 0.5245901639344263\n",
      "Y_DGS3 0.5040983606557377\n",
      "Y_DGS5 0.4959016393442623\n",
      "Y_DGS7 0.4918032786885246\n",
      "Y_DGS10 0.46311475409836067\n",
      "Y_DGS20 0.4959016393442623\n",
      "Y_DGS30 0.5081967213114754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/79 [8:51:05<1:57:08, 413.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6088709677419355\n",
      "Y_DGS3MO 0.6774193548387096\n",
      "Y_DGS6MO 0.6895161290322581\n",
      "Y_DGS1 0.5040322580645161\n",
      "Y_DGS2 0.5282258064516129\n",
      "Y_DGS3 0.5080645161290323\n",
      "Y_DGS5 0.5\n",
      "Y_DGS7 0.4959677419354839\n",
      "Y_DGS10 0.4637096774193548\n",
      "Y_DGS20 0.4959677419354839\n",
      "Y_DGS30 0.5080645161290323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 63/79 [8:57:48<1:49:25, 410.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6031746031746031\n",
      "Y_DGS3MO 0.6746031746031746\n",
      "Y_DGS6MO 0.6904761904761905\n",
      "Y_DGS1 0.5079365079365079\n",
      "Y_DGS2 0.5317460317460317\n",
      "Y_DGS3 0.5079365079365079\n",
      "Y_DGS5 0.503968253968254\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.45634920634920634\n",
      "Y_DGS20 0.4880952380952381\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 64/79 [9:04:29<1:41:54, 407.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6015625\n",
      "Y_DGS3MO 0.66796875\n",
      "Y_DGS6MO 0.68359375\n",
      "Y_DGS1 0.515625\n",
      "Y_DGS2 0.52734375\n",
      "Y_DGS3 0.5078125\n",
      "Y_DGS5 0.50390625\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.4609375\n",
      "Y_DGS20 0.4921875\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 65/79 [9:11:08<1:34:31, 405.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6038461538461538\n",
      "Y_DGS3MO 0.6653846153846154\n",
      "Y_DGS6MO 0.6807692307692308\n",
      "Y_DGS1 0.5153846153846153\n",
      "Y_DGS2 0.5269230769230769\n",
      "Y_DGS3 0.5076923076923077\n",
      "Y_DGS5 0.5038461538461538\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.46153846153846156\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 66/79 [9:17:47<1:27:19, 403.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6060606060606061\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.6742424242424242\n",
      "Y_DGS1 0.5189393939393939\n",
      "Y_DGS2 0.5303030303030303\n",
      "Y_DGS3 0.5113636363636364\n",
      "Y_DGS5 0.5075757575757576\n",
      "Y_DGS7 0.5037878787878788\n",
      "Y_DGS10 0.4659090909090909\n",
      "Y_DGS20 0.5037878787878788\n",
      "Y_DGS30 0.5037878787878788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 67/79 [9:24:19<1:19:56, 399.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6082089552238806\n",
      "Y_DGS3MO 0.667910447761194\n",
      "Y_DGS6MO 0.6716417910447762\n",
      "Y_DGS1 0.5186567164179104\n",
      "Y_DGS2 0.5298507462686567\n",
      "Y_DGS3 0.5111940298507462\n",
      "Y_DGS5 0.5074626865671642\n",
      "Y_DGS7 0.503731343283582\n",
      "Y_DGS10 0.4664179104477612\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 68/79 [9:30:39<1:12:14, 394.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6102941176470589\n",
      "Y_DGS3MO 0.6654411764705882\n",
      "Y_DGS6MO 0.6617647058823529\n",
      "Y_DGS1 0.5110294117647058\n",
      "Y_DGS2 0.5220588235294118\n",
      "Y_DGS3 0.5073529411764706\n",
      "Y_DGS5 0.5073529411764706\n",
      "Y_DGS7 0.5036764705882353\n",
      "Y_DGS10 0.46691176470588236\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 69/79 [9:36:55<1:04:44, 388.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6086956521739131\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.6630434782608695\n",
      "Y_DGS1 0.5144927536231884\n",
      "Y_DGS2 0.5253623188405797\n",
      "Y_DGS3 0.5108695652173914\n",
      "Y_DGS5 0.5108695652173914\n",
      "Y_DGS7 0.5072463768115942\n",
      "Y_DGS10 0.47101449275362317\n",
      "Y_DGS20 0.5036231884057971\n",
      "Y_DGS30 0.5036231884057971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 70/79 [9:43:10<57:39, 384.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6071428571428571\n",
      "Y_DGS3MO 0.6714285714285714\n",
      "Y_DGS6MO 0.6642857142857143\n",
      "Y_DGS1 0.5071428571428571\n",
      "Y_DGS2 0.5214285714285715\n",
      "Y_DGS3 0.5035714285714286\n",
      "Y_DGS5 0.5035714285714286\n",
      "Y_DGS7 0.5035714285714286\n",
      "Y_DGS10 0.46785714285714286\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 71/79 [9:49:24<50:50, 381.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6091549295774648\n",
      "Y_DGS3MO 0.6690140845070423\n",
      "Y_DGS6MO 0.6690140845070423\n",
      "Y_DGS1 0.5070422535211268\n",
      "Y_DGS2 0.5246478873239436\n",
      "Y_DGS3 0.5035211267605634\n",
      "Y_DGS5 0.5035211267605634\n",
      "Y_DGS7 0.5035211267605634\n",
      "Y_DGS10 0.47183098591549294\n",
      "Y_DGS20 0.5035211267605634\n",
      "Y_DGS30 0.5035211267605634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 72/79 [9:55:42<44:22, 380.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6111111111111112\n",
      "Y_DGS3MO 0.6701388888888888\n",
      "Y_DGS6MO 0.6701388888888888\n",
      "Y_DGS1 0.5104166666666666\n",
      "Y_DGS2 0.5277777777777778\n",
      "Y_DGS3 0.5069444444444444\n",
      "Y_DGS5 0.5034722222222222\n",
      "Y_DGS7 0.5034722222222222\n",
      "Y_DGS10 0.4722222222222222\n",
      "Y_DGS20 0.5069444444444444\n",
      "Y_DGS30 0.5034722222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 73/79 [10:02:12<38:18, 383.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6095890410958904\n",
      "Y_DGS3MO 0.6746575342465754\n",
      "Y_DGS6MO 0.6712328767123288\n",
      "Y_DGS1 0.5136986301369864\n",
      "Y_DGS2 0.5273972602739726\n",
      "Y_DGS3 0.5068493150684932\n",
      "Y_DGS5 0.5034246575342466\n",
      "Y_DGS7 0.5034246575342466\n",
      "Y_DGS10 0.4726027397260274\n",
      "Y_DGS20 0.5068493150684932\n",
      "Y_DGS30 0.5034246575342466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 74/79 [10:08:28<31:45, 381.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6047297297297297\n",
      "Y_DGS3MO 0.6756756756756757\n",
      "Y_DGS6MO 0.668918918918919\n",
      "Y_DGS1 0.5168918918918919\n",
      "Y_DGS2 0.527027027027027\n",
      "Y_DGS3 0.5067567567567568\n",
      "Y_DGS5 0.5033783783783784\n",
      "Y_DGS7 0.5033783783783784\n",
      "Y_DGS10 0.47297297297297297\n",
      "Y_DGS20 0.5067567567567568\n",
      "Y_DGS30 0.5033783783783784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 75/79 [10:14:37<25:10, 377.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.61\n",
      "Y_DGS3MO 0.68\n",
      "Y_DGS6MO 0.6733333333333333\n",
      "Y_DGS1 0.52\n",
      "Y_DGS2 0.5266666666666666\n",
      "Y_DGS3 0.5066666666666667\n",
      "Y_DGS5 0.5066666666666667\n",
      "Y_DGS7 0.5066666666666667\n",
      "Y_DGS10 0.4766666666666667\n",
      "Y_DGS20 0.51\n",
      "Y_DGS30 0.5066666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 76/79 [10:20:49<18:47, 375.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6085526315789473\n",
      "Y_DGS3MO 0.680921052631579\n",
      "Y_DGS6MO 0.6743421052631579\n",
      "Y_DGS1 0.5230263157894737\n",
      "Y_DGS2 0.5296052631578947\n",
      "Y_DGS3 0.5032894736842105\n",
      "Y_DGS5 0.5032894736842105\n",
      "Y_DGS7 0.5032894736842105\n",
      "Y_DGS10 0.47368421052631576\n",
      "Y_DGS20 0.506578947368421\n",
      "Y_DGS30 0.5032894736842105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 77/79 [10:26:51<12:23, 371.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6136363636363636\n",
      "Y_DGS3MO 0.685064935064935\n",
      "Y_DGS6MO 0.672077922077922\n",
      "Y_DGS1 0.5227272727272727\n",
      "Y_DGS2 0.525974025974026\n",
      "Y_DGS3 0.4967532467532468\n",
      "Y_DGS5 0.5\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.4707792207792208\n",
      "Y_DGS20 0.5032467532467533\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 78/79 [10:32:58<06:10, 370.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6121794871794872\n",
      "Y_DGS3MO 0.6826923076923077\n",
      "Y_DGS6MO 0.6698717948717948\n",
      "Y_DGS1 0.5192307692307693\n",
      "Y_DGS2 0.5224358974358975\n",
      "Y_DGS3 0.4967948717948718\n",
      "Y_DGS5 0.5\n",
      "Y_DGS7 0.5\n",
      "Y_DGS10 0.47115384615384615\n",
      "Y_DGS20 0.5032051282051282\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [10:39:00<00:00, 485.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6139240506329114\n",
      "Y_DGS3MO 0.6867088607594937\n",
      "Y_DGS6MO 0.6740506329113924\n",
      "Y_DGS1 0.5189873417721519\n",
      "Y_DGS2 0.5189873417721519\n",
      "Y_DGS3 0.4936708860759494\n",
      "Y_DGS5 0.49683544303797467\n",
      "Y_DGS7 0.49683544303797467\n",
      "Y_DGS10 0.46835443037974683\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.49683544303797467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO    0.613924\n",
      "Y_DGS3MO    0.686709\n",
      "Y_DGS6MO    0.674051\n",
      "Y_DGS1      0.518987\n",
      "Y_DGS2      0.518987\n",
      "Y_DGS3      0.493671\n",
      "Y_DGS5      0.496835\n",
      "Y_DGS7      0.496835\n",
      "Y_DGS10     0.468354\n",
      "Y_DGS20     0.500000\n",
      "Y_DGS30     0.496835\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# params_by_target = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw4.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw4.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv=tscv,\n",
    "#                         scoring='accuracy',\n",
    "#                         n_jobs=-1,\n",
    "#                         verbose=0)\n",
    "\n",
    "#     grid.fit(Xw_train, Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         print(col, np.mean(accuracies[col]))\n",
    "\n",
    "#         # feature importance pour la i-ème sortie\n",
    "#         est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "#         importance = est.feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "\n",
    "#         # hyperparamètres de l'estimateur i\n",
    "#         params = est.get_params()\n",
    "#         params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "# acc.to_csv('accuracies xgboost, MI 0.04, 15y train test.csv')\n",
    "# params.to_csv('params xgboost, MI 0.04, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance xgboost, MI 0.04, 15y train test.csv')\n",
    "# ypred.to_csv('forecast xgboost, MI 0.04, 15y train test.csv')\n",
    "# ytrue.to_csv('true values xgboost, MI 0.04, 15y train test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604d398",
   "metadata": {},
   "source": [
    "And for the dataset with MI > 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:16<00:00,  1.52s/it]\n",
      "  1%|▏         | 1/79 [04:08<5:23:14, 248.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.75\n",
      "Y_DGS3MO 0.75\n",
      "Y_DGS6MO 0.5\n",
      "Y_DGS1 0.5\n",
      "Y_DGS2 0.25\n",
      "Y_DGS3 0.5\n",
      "Y_DGS5 0.75\n",
      "Y_DGS7 0.75\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.75\n",
      "Y_DGS30 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/79 [07:38<4:49:39, 225.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.625\n",
      "Y_DGS3MO 0.625\n",
      "Y_DGS6MO 0.375\n",
      "Y_DGS1 0.5\n",
      "Y_DGS2 0.25\n",
      "Y_DGS3 0.5\n",
      "Y_DGS5 0.625\n",
      "Y_DGS7 0.625\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.625\n",
      "Y_DGS30 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/79 [11:00<4:32:13, 214.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.5833333333333334\n",
      "Y_DGS3MO 0.5833333333333334\n",
      "Y_DGS6MO 0.25\n",
      "Y_DGS1 0.5833333333333334\n",
      "Y_DGS2 0.3333333333333333\n",
      "Y_DGS3 0.5\n",
      "Y_DGS5 0.5833333333333334\n",
      "Y_DGS7 0.5833333333333334\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/79 [14:23<4:22:58, 210.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.5\n",
      "Y_DGS3MO 0.5625\n",
      "Y_DGS6MO 0.3125\n",
      "Y_DGS1 0.625\n",
      "Y_DGS2 0.5\n",
      "Y_DGS3 0.625\n",
      "Y_DGS5 0.6875\n",
      "Y_DGS7 0.6875\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/79 [17:37<4:12:03, 204.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.55\n",
      "Y_DGS3MO 0.6\n",
      "Y_DGS6MO 0.35\n",
      "Y_DGS1 0.6\n",
      "Y_DGS2 0.5\n",
      "Y_DGS3 0.6\n",
      "Y_DGS5 0.65\n",
      "Y_DGS7 0.65\n",
      "Y_DGS10 0.55\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/79 [20:49<4:03:28, 200.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.625\n",
      "Y_DGS3MO 0.625\n",
      "Y_DGS6MO 0.4583333333333333\n",
      "Y_DGS1 0.6666666666666666\n",
      "Y_DGS2 0.5416666666666666\n",
      "Y_DGS3 0.625\n",
      "Y_DGS5 0.6666666666666666\n",
      "Y_DGS7 0.6666666666666666\n",
      "Y_DGS10 0.5833333333333334\n",
      "Y_DGS20 0.5416666666666666\n",
      "Y_DGS30 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/79 [24:01<3:57:00, 197.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6785714285714286\n",
      "Y_DGS3MO 0.6785714285714286\n",
      "Y_DGS6MO 0.5\n",
      "Y_DGS1 0.6785714285714286\n",
      "Y_DGS2 0.6071428571428571\n",
      "Y_DGS3 0.6785714285714286\n",
      "Y_DGS5 0.7142857142857143\n",
      "Y_DGS7 0.7142857142857143\n",
      "Y_DGS10 0.6428571428571429\n",
      "Y_DGS20 0.5714285714285714\n",
      "Y_DGS30 0.6071428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/79 [27:12<3:51:25, 195.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.65625\n",
      "Y_DGS3MO 0.65625\n",
      "Y_DGS6MO 0.5\n",
      "Y_DGS1 0.6875\n",
      "Y_DGS2 0.625\n",
      "Y_DGS3 0.6875\n",
      "Y_DGS5 0.6875\n",
      "Y_DGS7 0.6875\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.5625\n",
      "Y_DGS30 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/79 [30:23<3:46:21, 194.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6666666666666666\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.5277777777777778\n",
      "Y_DGS1 0.6944444444444444\n",
      "Y_DGS2 0.6388888888888888\n",
      "Y_DGS3 0.6944444444444444\n",
      "Y_DGS5 0.6944444444444444\n",
      "Y_DGS7 0.6944444444444444\n",
      "Y_DGS10 0.6388888888888888\n",
      "Y_DGS20 0.5833333333333334\n",
      "Y_DGS30 0.6388888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 10/79 [33:33<3:41:46, 192.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.65\n",
      "Y_DGS3MO 0.65\n",
      "Y_DGS6MO 0.5\n",
      "Y_DGS1 0.65\n",
      "Y_DGS2 0.6\n",
      "Y_DGS3 0.675\n",
      "Y_DGS5 0.675\n",
      "Y_DGS7 0.675\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.575\n",
      "Y_DGS30 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/79 [36:47<3:38:43, 192.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6590909090909091\n",
      "Y_DGS3MO 0.6818181818181818\n",
      "Y_DGS6MO 0.5227272727272727\n",
      "Y_DGS1 0.6590909090909091\n",
      "Y_DGS2 0.6136363636363636\n",
      "Y_DGS3 0.6818181818181818\n",
      "Y_DGS5 0.6818181818181818\n",
      "Y_DGS7 0.6818181818181818\n",
      "Y_DGS10 0.6363636363636364\n",
      "Y_DGS20 0.5909090909090909\n",
      "Y_DGS30 0.6136363636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/79 [40:00<3:35:34, 193.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6875\n",
      "Y_DGS3MO 0.6875\n",
      "Y_DGS6MO 0.5208333333333334\n",
      "Y_DGS1 0.6458333333333334\n",
      "Y_DGS2 0.6041666666666666\n",
      "Y_DGS3 0.6666666666666666\n",
      "Y_DGS5 0.6666666666666666\n",
      "Y_DGS7 0.6666666666666666\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.5625\n",
      "Y_DGS30 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/79 [43:16<3:33:18, 193.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6730769230769231\n",
      "Y_DGS3MO 0.6538461538461539\n",
      "Y_DGS6MO 0.5192307692307693\n",
      "Y_DGS1 0.6346153846153846\n",
      "Y_DGS2 0.6346153846153846\n",
      "Y_DGS3 0.6538461538461539\n",
      "Y_DGS5 0.6730769230769231\n",
      "Y_DGS7 0.6538461538461539\n",
      "Y_DGS10 0.6153846153846154\n",
      "Y_DGS20 0.5769230769230769\n",
      "Y_DGS30 0.5961538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/79 [46:33<3:31:13, 194.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6607142857142857\n",
      "Y_DGS3MO 0.6428571428571429\n",
      "Y_DGS6MO 0.5178571428571429\n",
      "Y_DGS1 0.6428571428571429\n",
      "Y_DGS2 0.6428571428571429\n",
      "Y_DGS3 0.6607142857142857\n",
      "Y_DGS5 0.6785714285714286\n",
      "Y_DGS7 0.6607142857142857\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.5892857142857143\n",
      "Y_DGS30 0.6071428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/79 [49:58<3:31:11, 197.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.65\n",
      "Y_DGS3MO 0.6166666666666667\n",
      "Y_DGS6MO 0.5333333333333333\n",
      "Y_DGS1 0.65\n",
      "Y_DGS2 0.6333333333333333\n",
      "Y_DGS3 0.6666666666666666\n",
      "Y_DGS5 0.6833333333333333\n",
      "Y_DGS7 0.6666666666666666\n",
      "Y_DGS10 0.6166666666666667\n",
      "Y_DGS20 0.5833333333333334\n",
      "Y_DGS30 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/79 [53:18<3:28:28, 198.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.640625\n",
      "Y_DGS3MO 0.609375\n",
      "Y_DGS6MO 0.546875\n",
      "Y_DGS1 0.65625\n",
      "Y_DGS2 0.625\n",
      "Y_DGS3 0.65625\n",
      "Y_DGS5 0.671875\n",
      "Y_DGS7 0.671875\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.59375\n",
      "Y_DGS30 0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 17/79 [56:40<3:26:15, 199.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6617647058823529\n",
      "Y_DGS3MO 0.6323529411764706\n",
      "Y_DGS6MO 0.5735294117647058\n",
      "Y_DGS1 0.6764705882352942\n",
      "Y_DGS2 0.6470588235294118\n",
      "Y_DGS3 0.6617647058823529\n",
      "Y_DGS5 0.6764705882352942\n",
      "Y_DGS7 0.6764705882352942\n",
      "Y_DGS10 0.6323529411764706\n",
      "Y_DGS20 0.5882352941176471\n",
      "Y_DGS30 0.6176470588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 18/79 [59:56<3:21:48, 198.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6527777777777778\n",
      "Y_DGS3MO 0.625\n",
      "Y_DGS6MO 0.5694444444444444\n",
      "Y_DGS1 0.6527777777777778\n",
      "Y_DGS2 0.6527777777777778\n",
      "Y_DGS3 0.6805555555555556\n",
      "Y_DGS5 0.6805555555555556\n",
      "Y_DGS7 0.6805555555555556\n",
      "Y_DGS10 0.6388888888888888\n",
      "Y_DGS20 0.5972222222222222\n",
      "Y_DGS30 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/79 [1:03:13<3:18:03, 198.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6710526315789473\n",
      "Y_DGS3MO 0.6447368421052632\n",
      "Y_DGS6MO 0.5657894736842105\n",
      "Y_DGS1 0.6578947368421053\n",
      "Y_DGS2 0.6578947368421053\n",
      "Y_DGS3 0.6842105263157895\n",
      "Y_DGS5 0.6842105263157895\n",
      "Y_DGS7 0.6710526315789473\n",
      "Y_DGS10 0.618421052631579\n",
      "Y_DGS20 0.5789473684210527\n",
      "Y_DGS30 0.6052631578947368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/79 [1:06:29<3:14:04, 197.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6625\n",
      "Y_DGS3MO 0.625\n",
      "Y_DGS6MO 0.575\n",
      "Y_DGS1 0.6625\n",
      "Y_DGS2 0.6625\n",
      "Y_DGS3 0.6875\n",
      "Y_DGS5 0.6875\n",
      "Y_DGS7 0.675\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.575\n",
      "Y_DGS30 0.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 21/79 [1:09:44<3:10:17, 196.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6547619047619048\n",
      "Y_DGS3MO 0.6428571428571429\n",
      "Y_DGS6MO 0.5952380952380952\n",
      "Y_DGS1 0.6785714285714286\n",
      "Y_DGS2 0.6785714285714286\n",
      "Y_DGS3 0.7023809523809523\n",
      "Y_DGS5 0.6904761904761905\n",
      "Y_DGS7 0.6785714285714286\n",
      "Y_DGS10 0.6309523809523809\n",
      "Y_DGS20 0.5833333333333334\n",
      "Y_DGS30 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/79 [1:13:01<3:06:55, 196.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6590909090909091\n",
      "Y_DGS3MO 0.6477272727272727\n",
      "Y_DGS6MO 0.5909090909090909\n",
      "Y_DGS1 0.6704545454545454\n",
      "Y_DGS2 0.6704545454545454\n",
      "Y_DGS3 0.6931818181818182\n",
      "Y_DGS5 0.6818181818181818\n",
      "Y_DGS7 0.6704545454545454\n",
      "Y_DGS10 0.625\n",
      "Y_DGS20 0.5795454545454546\n",
      "Y_DGS30 0.5795454545454546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/79 [1:16:15<3:02:57, 196.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6521739130434783\n",
      "Y_DGS3MO 0.6521739130434783\n",
      "Y_DGS6MO 0.5978260869565217\n",
      "Y_DGS1 0.6739130434782609\n",
      "Y_DGS2 0.6739130434782609\n",
      "Y_DGS3 0.6956521739130435\n",
      "Y_DGS5 0.6739130434782609\n",
      "Y_DGS7 0.6739130434782609\n",
      "Y_DGS10 0.6304347826086957\n",
      "Y_DGS20 0.5869565217391305\n",
      "Y_DGS30 0.5869565217391305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/79 [1:19:27<2:58:27, 194.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.65625\n",
      "Y_DGS3MO 0.65625\n",
      "Y_DGS6MO 0.6041666666666666\n",
      "Y_DGS1 0.6770833333333334\n",
      "Y_DGS2 0.65625\n",
      "Y_DGS3 0.6875\n",
      "Y_DGS5 0.65625\n",
      "Y_DGS7 0.65625\n",
      "Y_DGS10 0.6145833333333334\n",
      "Y_DGS20 0.5729166666666666\n",
      "Y_DGS30 0.5729166666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 25/79 [1:22:38<2:54:17, 193.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.66\n",
      "Y_DGS3MO 0.65\n",
      "Y_DGS6MO 0.62\n",
      "Y_DGS1 0.68\n",
      "Y_DGS2 0.65\n",
      "Y_DGS3 0.68\n",
      "Y_DGS5 0.65\n",
      "Y_DGS7 0.65\n",
      "Y_DGS10 0.61\n",
      "Y_DGS20 0.57\n",
      "Y_DGS30 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 26/79 [1:25:51<2:50:49, 193.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6730769230769231\n",
      "Y_DGS3MO 0.6538461538461539\n",
      "Y_DGS6MO 0.6346153846153846\n",
      "Y_DGS1 0.6923076923076923\n",
      "Y_DGS2 0.6538461538461539\n",
      "Y_DGS3 0.6730769230769231\n",
      "Y_DGS5 0.6442307692307693\n",
      "Y_DGS7 0.6442307692307693\n",
      "Y_DGS10 0.5961538461538461\n",
      "Y_DGS20 0.5576923076923077\n",
      "Y_DGS30 0.5576923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/79 [1:29:06<2:47:58, 193.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6666666666666666\n",
      "Y_DGS3MO 0.6574074074074074\n",
      "Y_DGS6MO 0.6388888888888888\n",
      "Y_DGS1 0.6944444444444444\n",
      "Y_DGS2 0.6574074074074074\n",
      "Y_DGS3 0.6759259259259259\n",
      "Y_DGS5 0.6481481481481481\n",
      "Y_DGS7 0.6481481481481481\n",
      "Y_DGS10 0.6018518518518519\n",
      "Y_DGS20 0.5648148148148148\n",
      "Y_DGS30 0.5648148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/79 [1:32:25<2:46:07, 195.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6785714285714286\n",
      "Y_DGS3MO 0.6607142857142857\n",
      "Y_DGS6MO 0.6428571428571429\n",
      "Y_DGS1 0.7053571428571429\n",
      "Y_DGS2 0.6607142857142857\n",
      "Y_DGS3 0.6785714285714286\n",
      "Y_DGS5 0.6428571428571429\n",
      "Y_DGS7 0.6428571428571429\n",
      "Y_DGS10 0.5982142857142857\n",
      "Y_DGS20 0.5625\n",
      "Y_DGS30 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 29/79 [1:35:54<2:46:11, 199.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6724137931034483\n",
      "Y_DGS3MO 0.6637931034482759\n",
      "Y_DGS6MO 0.646551724137931\n",
      "Y_DGS1 0.6982758620689655\n",
      "Y_DGS2 0.6551724137931034\n",
      "Y_DGS3 0.6637931034482759\n",
      "Y_DGS5 0.6206896551724138\n",
      "Y_DGS7 0.6206896551724138\n",
      "Y_DGS10 0.5775862068965517\n",
      "Y_DGS20 0.5431034482758621\n",
      "Y_DGS30 0.5517241379310345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/79 [1:39:17<2:43:46, 200.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.675\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.6416666666666667\n",
      "Y_DGS1 0.7\n",
      "Y_DGS2 0.6583333333333333\n",
      "Y_DGS3 0.6583333333333333\n",
      "Y_DGS5 0.6083333333333333\n",
      "Y_DGS7 0.6083333333333333\n",
      "Y_DGS10 0.5666666666666667\n",
      "Y_DGS20 0.5333333333333333\n",
      "Y_DGS30 0.5416666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/79 [1:42:49<2:43:22, 204.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6854838709677419\n",
      "Y_DGS3MO 0.6693548387096774\n",
      "Y_DGS6MO 0.6451612903225806\n",
      "Y_DGS1 0.6935483870967742\n",
      "Y_DGS2 0.6612903225806451\n",
      "Y_DGS3 0.6612903225806451\n",
      "Y_DGS5 0.6129032258064516\n",
      "Y_DGS7 0.6129032258064516\n",
      "Y_DGS10 0.5725806451612904\n",
      "Y_DGS20 0.5483870967741935\n",
      "Y_DGS30 0.5564516129032258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 32/79 [1:46:12<2:39:39, 203.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6953125\n",
      "Y_DGS3MO 0.671875\n",
      "Y_DGS6MO 0.6484375\n",
      "Y_DGS1 0.6953125\n",
      "Y_DGS2 0.65625\n",
      "Y_DGS3 0.6484375\n",
      "Y_DGS5 0.6015625\n",
      "Y_DGS7 0.609375\n",
      "Y_DGS10 0.5703125\n",
      "Y_DGS20 0.546875\n",
      "Y_DGS30 0.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 33/79 [1:49:32<2:35:16, 202.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6893939393939394\n",
      "Y_DGS3MO 0.6590909090909091\n",
      "Y_DGS6MO 0.6363636363636364\n",
      "Y_DGS1 0.6893939393939394\n",
      "Y_DGS2 0.6515151515151515\n",
      "Y_DGS3 0.6439393939393939\n",
      "Y_DGS5 0.5984848484848485\n",
      "Y_DGS7 0.6136363636363636\n",
      "Y_DGS10 0.5833333333333334\n",
      "Y_DGS20 0.5606060606060606\n",
      "Y_DGS30 0.5681818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 34/79 [1:52:50<2:30:50, 201.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6911764705882353\n",
      "Y_DGS3MO 0.6544117647058824\n",
      "Y_DGS6MO 0.6470588235294118\n",
      "Y_DGS1 0.6985294117647058\n",
      "Y_DGS2 0.6470588235294118\n",
      "Y_DGS3 0.6397058823529411\n",
      "Y_DGS5 0.6029411764705882\n",
      "Y_DGS7 0.6176470588235294\n",
      "Y_DGS10 0.5882352941176471\n",
      "Y_DGS20 0.5661764705882353\n",
      "Y_DGS30 0.5735294117647058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/79 [1:56:08<2:26:46, 200.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.7\n",
      "Y_DGS3MO 0.6571428571428571\n",
      "Y_DGS6MO 0.65\n",
      "Y_DGS1 0.7\n",
      "Y_DGS2 0.6428571428571429\n",
      "Y_DGS3 0.6357142857142857\n",
      "Y_DGS5 0.6\n",
      "Y_DGS7 0.6142857142857143\n",
      "Y_DGS10 0.5928571428571429\n",
      "Y_DGS20 0.5714285714285714\n",
      "Y_DGS30 0.5785714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 36/79 [1:59:28<2:23:23, 200.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.7013888888888888\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.6527777777777778\n",
      "Y_DGS1 0.6944444444444444\n",
      "Y_DGS2 0.6458333333333334\n",
      "Y_DGS3 0.6319444444444444\n",
      "Y_DGS5 0.5972222222222222\n",
      "Y_DGS7 0.6111111111111112\n",
      "Y_DGS10 0.5833333333333334\n",
      "Y_DGS20 0.5694444444444444\n",
      "Y_DGS30 0.5763888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 37/79 [2:02:57<2:21:55, 202.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.7027027027027027\n",
      "Y_DGS3MO 0.6621621621621622\n",
      "Y_DGS6MO 0.6554054054054054\n",
      "Y_DGS1 0.6891891891891891\n",
      "Y_DGS2 0.6418918918918919\n",
      "Y_DGS3 0.6216216216216216\n",
      "Y_DGS5 0.5878378378378378\n",
      "Y_DGS7 0.6013513513513513\n",
      "Y_DGS10 0.5675675675675675\n",
      "Y_DGS20 0.5608108108108109\n",
      "Y_DGS30 0.5675675675675675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/79 [2:06:12<2:17:05, 200.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6907894736842105\n",
      "Y_DGS3MO 0.6644736842105263\n",
      "Y_DGS6MO 0.6578947368421053\n",
      "Y_DGS1 0.6776315789473685\n",
      "Y_DGS2 0.6381578947368421\n",
      "Y_DGS3 0.618421052631579\n",
      "Y_DGS5 0.5855263157894737\n",
      "Y_DGS7 0.5986842105263158\n",
      "Y_DGS10 0.5723684210526315\n",
      "Y_DGS20 0.5657894736842105\n",
      "Y_DGS30 0.5723684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/79 [2:09:29<2:13:03, 199.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6923076923076923\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.6602564102564102\n",
      "Y_DGS1 0.6602564102564102\n",
      "Y_DGS2 0.6346153846153846\n",
      "Y_DGS3 0.6089743589743589\n",
      "Y_DGS5 0.5897435897435898\n",
      "Y_DGS7 0.6025641025641025\n",
      "Y_DGS10 0.5769230769230769\n",
      "Y_DGS20 0.5705128205128205\n",
      "Y_DGS30 0.5769230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 40/79 [2:12:44<2:08:52, 198.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6875\n",
      "Y_DGS3MO 0.66875\n",
      "Y_DGS6MO 0.65\n",
      "Y_DGS1 0.65\n",
      "Y_DGS2 0.625\n",
      "Y_DGS3 0.60625\n",
      "Y_DGS5 0.58125\n",
      "Y_DGS7 0.59375\n",
      "Y_DGS10 0.56875\n",
      "Y_DGS20 0.56875\n",
      "Y_DGS30 0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 41/79 [2:15:56<2:04:13, 196.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6951219512195121\n",
      "Y_DGS3MO 0.6524390243902439\n",
      "Y_DGS6MO 0.6341463414634146\n",
      "Y_DGS1 0.6341463414634146\n",
      "Y_DGS2 0.6097560975609756\n",
      "Y_DGS3 0.5914634146341463\n",
      "Y_DGS5 0.573170731707317\n",
      "Y_DGS7 0.5853658536585366\n",
      "Y_DGS10 0.5609756097560976\n",
      "Y_DGS20 0.5609756097560976\n",
      "Y_DGS30 0.573170731707317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 42/79 [2:19:09<2:00:27, 195.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6964285714285714\n",
      "Y_DGS3MO 0.6488095238095238\n",
      "Y_DGS6MO 0.6369047619047619\n",
      "Y_DGS1 0.6309523809523809\n",
      "Y_DGS2 0.6011904761904762\n",
      "Y_DGS3 0.5833333333333334\n",
      "Y_DGS5 0.5654761904761905\n",
      "Y_DGS7 0.5773809523809523\n",
      "Y_DGS10 0.5595238095238095\n",
      "Y_DGS20 0.5535714285714286\n",
      "Y_DGS30 0.5654761904761905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/79 [2:22:50<2:01:51, 203.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.686046511627907\n",
      "Y_DGS3MO 0.6569767441860465\n",
      "Y_DGS6MO 0.622093023255814\n",
      "Y_DGS1 0.6162790697674418\n",
      "Y_DGS2 0.5930232558139535\n",
      "Y_DGS3 0.5697674418604651\n",
      "Y_DGS5 0.5581395348837209\n",
      "Y_DGS7 0.5697674418604651\n",
      "Y_DGS10 0.5523255813953488\n",
      "Y_DGS20 0.5465116279069767\n",
      "Y_DGS30 0.5581395348837209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 44/79 [2:26:08<1:57:34, 201.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6761363636363636\n",
      "Y_DGS3MO 0.6590909090909091\n",
      "Y_DGS6MO 0.6306818181818182\n",
      "Y_DGS1 0.6022727272727273\n",
      "Y_DGS2 0.5852272727272727\n",
      "Y_DGS3 0.5625\n",
      "Y_DGS5 0.5511363636363636\n",
      "Y_DGS7 0.5625\n",
      "Y_DGS10 0.5454545454545454\n",
      "Y_DGS20 0.5397727272727273\n",
      "Y_DGS30 0.5511363636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 45/79 [2:29:25<1:53:26, 200.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6722222222222223\n",
      "Y_DGS3MO 0.6555555555555556\n",
      "Y_DGS6MO 0.6333333333333333\n",
      "Y_DGS1 0.6\n",
      "Y_DGS2 0.5833333333333334\n",
      "Y_DGS3 0.5666666666666667\n",
      "Y_DGS5 0.5555555555555556\n",
      "Y_DGS7 0.5666666666666667\n",
      "Y_DGS10 0.55\n",
      "Y_DGS20 0.5444444444444444\n",
      "Y_DGS30 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 46/79 [2:32:43<1:49:43, 199.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.657608695652174\n",
      "Y_DGS3MO 0.6630434782608695\n",
      "Y_DGS6MO 0.6413043478260869\n",
      "Y_DGS1 0.5978260869565217\n",
      "Y_DGS2 0.5760869565217391\n",
      "Y_DGS3 0.5597826086956522\n",
      "Y_DGS5 0.5489130434782609\n",
      "Y_DGS7 0.5597826086956522\n",
      "Y_DGS10 0.5434782608695652\n",
      "Y_DGS20 0.5380434782608695\n",
      "Y_DGS30 0.5434782608695652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/79 [2:36:00<1:45:56, 198.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6436170212765957\n",
      "Y_DGS3MO 0.6648936170212766\n",
      "Y_DGS6MO 0.648936170212766\n",
      "Y_DGS1 0.5957446808510638\n",
      "Y_DGS2 0.574468085106383\n",
      "Y_DGS3 0.5638297872340425\n",
      "Y_DGS5 0.5531914893617021\n",
      "Y_DGS7 0.5638297872340425\n",
      "Y_DGS10 0.5478723404255319\n",
      "Y_DGS20 0.5425531914893617\n",
      "Y_DGS30 0.5478723404255319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 48/79 [2:39:14<1:41:55, 197.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6458333333333334\n",
      "Y_DGS3MO 0.6666666666666666\n",
      "Y_DGS6MO 0.6510416666666666\n",
      "Y_DGS1 0.5989583333333334\n",
      "Y_DGS2 0.5729166666666666\n",
      "Y_DGS3 0.5677083333333334\n",
      "Y_DGS5 0.5572916666666666\n",
      "Y_DGS7 0.5625\n",
      "Y_DGS10 0.546875\n",
      "Y_DGS20 0.5416666666666666\n",
      "Y_DGS30 0.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 49/79 [2:42:34<1:39:00, 198.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6479591836734694\n",
      "Y_DGS3MO 0.673469387755102\n",
      "Y_DGS6MO 0.6581632653061225\n",
      "Y_DGS1 0.5918367346938775\n",
      "Y_DGS2 0.5663265306122449\n",
      "Y_DGS3 0.5561224489795918\n",
      "Y_DGS5 0.5459183673469388\n",
      "Y_DGS7 0.5510204081632653\n",
      "Y_DGS10 0.5357142857142857\n",
      "Y_DGS20 0.5357142857142857\n",
      "Y_DGS30 0.5408163265306123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 50/79 [2:45:49<1:35:18, 197.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.65\n",
      "Y_DGS3MO 0.68\n",
      "Y_DGS6MO 0.665\n",
      "Y_DGS1 0.585\n",
      "Y_DGS2 0.555\n",
      "Y_DGS3 0.545\n",
      "Y_DGS5 0.535\n",
      "Y_DGS7 0.54\n",
      "Y_DGS10 0.525\n",
      "Y_DGS20 0.525\n",
      "Y_DGS30 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 51/79 [2:49:02<1:31:29, 196.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6519607843137255\n",
      "Y_DGS3MO 0.6862745098039216\n",
      "Y_DGS6MO 0.6715686274509803\n",
      "Y_DGS1 0.5784313725490197\n",
      "Y_DGS2 0.553921568627451\n",
      "Y_DGS3 0.5441176470588235\n",
      "Y_DGS5 0.5392156862745098\n",
      "Y_DGS7 0.5441176470588235\n",
      "Y_DGS10 0.5294117647058824\n",
      "Y_DGS20 0.5196078431372549\n",
      "Y_DGS30 0.5245098039215687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 52/79 [2:52:15<1:27:44, 194.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6490384615384616\n",
      "Y_DGS3MO 0.6875\n",
      "Y_DGS6MO 0.6682692307692307\n",
      "Y_DGS1 0.5769230769230769\n",
      "Y_DGS2 0.5480769230769231\n",
      "Y_DGS3 0.5384615384615384\n",
      "Y_DGS5 0.5336538461538461\n",
      "Y_DGS7 0.5336538461538461\n",
      "Y_DGS10 0.5192307692307693\n",
      "Y_DGS20 0.5192307692307693\n",
      "Y_DGS30 0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 53/79 [2:55:29<1:24:25, 194.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6462264150943396\n",
      "Y_DGS3MO 0.6839622641509434\n",
      "Y_DGS6MO 0.6650943396226415\n",
      "Y_DGS1 0.5707547169811321\n",
      "Y_DGS2 0.5424528301886793\n",
      "Y_DGS3 0.5330188679245284\n",
      "Y_DGS5 0.5283018867924528\n",
      "Y_DGS7 0.5283018867924528\n",
      "Y_DGS10 0.5141509433962265\n",
      "Y_DGS20 0.5141509433962265\n",
      "Y_DGS30 0.5141509433962265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/79 [2:58:42<1:20:55, 194.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6481481481481481\n",
      "Y_DGS3MO 0.6851851851851852\n",
      "Y_DGS6MO 0.6666666666666666\n",
      "Y_DGS1 0.5787037037037037\n",
      "Y_DGS2 0.5462962962962963\n",
      "Y_DGS3 0.5370370370370371\n",
      "Y_DGS5 0.5231481481481481\n",
      "Y_DGS7 0.5277777777777778\n",
      "Y_DGS10 0.5185185185185185\n",
      "Y_DGS20 0.5231481481481481\n",
      "Y_DGS30 0.5185185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 55/79 [3:01:54<1:17:23, 193.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6454545454545455\n",
      "Y_DGS3MO 0.6863636363636364\n",
      "Y_DGS6MO 0.6727272727272727\n",
      "Y_DGS1 0.5681818181818182\n",
      "Y_DGS2 0.5363636363636364\n",
      "Y_DGS3 0.5272727272727272\n",
      "Y_DGS5 0.5136363636363637\n",
      "Y_DGS7 0.5181818181818182\n",
      "Y_DGS10 0.509090909090909\n",
      "Y_DGS20 0.5181818181818182\n",
      "Y_DGS30 0.5136363636363637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 56/79 [3:05:04<1:13:44, 192.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6473214285714286\n",
      "Y_DGS3MO 0.6875\n",
      "Y_DGS6MO 0.6696428571428571\n",
      "Y_DGS1 0.5625\n",
      "Y_DGS2 0.5357142857142857\n",
      "Y_DGS3 0.5267857142857143\n",
      "Y_DGS5 0.5133928571428571\n",
      "Y_DGS7 0.5178571428571429\n",
      "Y_DGS10 0.5089285714285714\n",
      "Y_DGS20 0.5178571428571429\n",
      "Y_DGS30 0.5178571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 57/79 [3:08:16<1:10:31, 192.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6359649122807017\n",
      "Y_DGS3MO 0.6885964912280702\n",
      "Y_DGS6MO 0.6754385964912281\n",
      "Y_DGS1 0.5570175438596491\n",
      "Y_DGS2 0.5307017543859649\n",
      "Y_DGS3 0.5219298245614035\n",
      "Y_DGS5 0.5087719298245614\n",
      "Y_DGS7 0.5131578947368421\n",
      "Y_DGS10 0.5043859649122807\n",
      "Y_DGS20 0.5131578947368421\n",
      "Y_DGS30 0.5131578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 58/79 [3:11:29<1:07:21, 192.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6293103448275862\n",
      "Y_DGS3MO 0.6853448275862069\n",
      "Y_DGS6MO 0.6767241379310345\n",
      "Y_DGS1 0.5517241379310345\n",
      "Y_DGS2 0.5301724137931034\n",
      "Y_DGS3 0.521551724137931\n",
      "Y_DGS5 0.5043103448275862\n",
      "Y_DGS7 0.5129310344827587\n",
      "Y_DGS10 0.5043103448275862\n",
      "Y_DGS20 0.5086206896551724\n",
      "Y_DGS30 0.5086206896551724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 59/79 [3:14:38<1:03:52, 191.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6228813559322034\n",
      "Y_DGS3MO 0.6822033898305084\n",
      "Y_DGS6MO 0.673728813559322\n",
      "Y_DGS1 0.5550847457627118\n",
      "Y_DGS2 0.5296610169491526\n",
      "Y_DGS3 0.5169491525423728\n",
      "Y_DGS5 0.5042372881355932\n",
      "Y_DGS7 0.5127118644067796\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5127118644067796\n",
      "Y_DGS30 0.5084745762711864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 60/79 [3:17:49<1:00:34, 191.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6166666666666667\n",
      "Y_DGS3MO 0.6875\n",
      "Y_DGS6MO 0.675\n",
      "Y_DGS1 0.5625\n",
      "Y_DGS2 0.5333333333333333\n",
      "Y_DGS3 0.5166666666666667\n",
      "Y_DGS5 0.5041666666666667\n",
      "Y_DGS7 0.5125\n",
      "Y_DGS10 0.5041666666666667\n",
      "Y_DGS20 0.5125\n",
      "Y_DGS30 0.5083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 61/79 [3:21:00<57:25, 191.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6229508196721312\n",
      "Y_DGS3MO 0.6885245901639344\n",
      "Y_DGS6MO 0.6762295081967213\n",
      "Y_DGS1 0.5614754098360656\n",
      "Y_DGS2 0.5368852459016393\n",
      "Y_DGS3 0.5122950819672131\n",
      "Y_DGS5 0.4959016393442623\n",
      "Y_DGS7 0.5122950819672131\n",
      "Y_DGS10 0.4959016393442623\n",
      "Y_DGS20 0.5081967213114754\n",
      "Y_DGS30 0.5040983606557377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/79 [3:24:08<53:55, 190.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6209677419354839\n",
      "Y_DGS3MO 0.6895161290322581\n",
      "Y_DGS6MO 0.6733870967741935\n",
      "Y_DGS1 0.5604838709677419\n",
      "Y_DGS2 0.5403225806451613\n",
      "Y_DGS3 0.5120967741935484\n",
      "Y_DGS5 0.49193548387096775\n",
      "Y_DGS7 0.5040322580645161\n",
      "Y_DGS10 0.4959677419354839\n",
      "Y_DGS20 0.5080645161290323\n",
      "Y_DGS30 0.5040322580645161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 63/79 [3:27:17<50:37, 189.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6150793650793651\n",
      "Y_DGS3MO 0.6865079365079365\n",
      "Y_DGS6MO 0.6746031746031746\n",
      "Y_DGS1 0.5595238095238095\n",
      "Y_DGS2 0.5436507936507936\n",
      "Y_DGS3 0.5119047619047619\n",
      "Y_DGS5 0.48412698412698413\n",
      "Y_DGS7 0.5079365079365079\n",
      "Y_DGS10 0.4880952380952381\n",
      "Y_DGS20 0.5\n",
      "Y_DGS30 0.49603174603174605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 64/79 [3:30:22<47:05, 188.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.609375\n",
      "Y_DGS3MO 0.6796875\n",
      "Y_DGS6MO 0.66796875\n",
      "Y_DGS1 0.55859375\n",
      "Y_DGS2 0.54296875\n",
      "Y_DGS3 0.515625\n",
      "Y_DGS5 0.48828125\n",
      "Y_DGS7 0.5078125\n",
      "Y_DGS10 0.4921875\n",
      "Y_DGS20 0.50390625\n",
      "Y_DGS30 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 65/79 [3:33:30<43:57, 188.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6115384615384616\n",
      "Y_DGS3MO 0.676923076923077\n",
      "Y_DGS6MO 0.6653846153846154\n",
      "Y_DGS1 0.5576923076923077\n",
      "Y_DGS2 0.5423076923076923\n",
      "Y_DGS3 0.5153846153846153\n",
      "Y_DGS5 0.48846153846153845\n",
      "Y_DGS7 0.5076923076923077\n",
      "Y_DGS10 0.49230769230769234\n",
      "Y_DGS20 0.5115384615384615\n",
      "Y_DGS30 0.5038461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 66/79 [3:36:34<40:31, 187.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6136363636363636\n",
      "Y_DGS3MO 0.678030303030303\n",
      "Y_DGS6MO 0.6590909090909091\n",
      "Y_DGS1 0.5606060606060606\n",
      "Y_DGS2 0.5454545454545454\n",
      "Y_DGS3 0.5189393939393939\n",
      "Y_DGS5 0.49242424242424243\n",
      "Y_DGS7 0.5113636363636364\n",
      "Y_DGS10 0.4962121212121212\n",
      "Y_DGS20 0.5151515151515151\n",
      "Y_DGS30 0.5075757575757576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 67/79 [3:39:39<37:15, 186.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6156716417910447\n",
      "Y_DGS3MO 0.6791044776119403\n",
      "Y_DGS6MO 0.664179104477612\n",
      "Y_DGS1 0.5597014925373134\n",
      "Y_DGS2 0.5447761194029851\n",
      "Y_DGS3 0.5186567164179104\n",
      "Y_DGS5 0.4925373134328358\n",
      "Y_DGS7 0.5111940298507462\n",
      "Y_DGS10 0.4962686567164179\n",
      "Y_DGS20 0.5111940298507462\n",
      "Y_DGS30 0.503731343283582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 68/79 [3:42:44<34:06, 186.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6176470588235294\n",
      "Y_DGS3MO 0.6764705882352942\n",
      "Y_DGS6MO 0.6544117647058824\n",
      "Y_DGS1 0.5514705882352942\n",
      "Y_DGS2 0.5367647058823529\n",
      "Y_DGS3 0.5147058823529411\n",
      "Y_DGS5 0.49264705882352944\n",
      "Y_DGS7 0.5110294117647058\n",
      "Y_DGS10 0.4963235294117647\n",
      "Y_DGS20 0.5110294117647058\n",
      "Y_DGS30 0.5036764705882353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 69/79 [3:45:49<30:56, 185.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6159420289855072\n",
      "Y_DGS3MO 0.6702898550724637\n",
      "Y_DGS6MO 0.6557971014492754\n",
      "Y_DGS1 0.5543478260869565\n",
      "Y_DGS2 0.5398550724637681\n",
      "Y_DGS3 0.5181159420289855\n",
      "Y_DGS5 0.4963768115942029\n",
      "Y_DGS7 0.5144927536231884\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5144927536231884\n",
      "Y_DGS30 0.5072463768115942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 70/79 [3:48:53<27:47, 185.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6142857142857143\n",
      "Y_DGS3MO 0.6607142857142857\n",
      "Y_DGS6MO 0.6571428571428571\n",
      "Y_DGS1 0.5464285714285714\n",
      "Y_DGS2 0.5357142857142857\n",
      "Y_DGS3 0.5107142857142857\n",
      "Y_DGS5 0.48928571428571427\n",
      "Y_DGS7 0.5107142857142857\n",
      "Y_DGS10 0.49642857142857144\n",
      "Y_DGS20 0.5107142857142857\n",
      "Y_DGS30 0.5035714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 71/79 [3:51:57<24:38, 184.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6161971830985915\n",
      "Y_DGS3MO 0.6584507042253521\n",
      "Y_DGS6MO 0.6584507042253521\n",
      "Y_DGS1 0.5492957746478874\n",
      "Y_DGS2 0.5387323943661971\n",
      "Y_DGS3 0.5105633802816901\n",
      "Y_DGS5 0.4894366197183099\n",
      "Y_DGS7 0.5105633802816901\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5140845070422535\n",
      "Y_DGS30 0.5070422535211268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 72/79 [3:55:03<21:35, 185.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6180555555555556\n",
      "Y_DGS3MO 0.6597222222222222\n",
      "Y_DGS6MO 0.65625\n",
      "Y_DGS1 0.5520833333333334\n",
      "Y_DGS2 0.5416666666666666\n",
      "Y_DGS3 0.5138888888888888\n",
      "Y_DGS5 0.4930555555555556\n",
      "Y_DGS7 0.5104166666666666\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5173611111111112\n",
      "Y_DGS30 0.5069444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 73/79 [3:58:06<18:27, 184.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6164383561643836\n",
      "Y_DGS3MO 0.6643835616438356\n",
      "Y_DGS6MO 0.6575342465753424\n",
      "Y_DGS1 0.5547945205479452\n",
      "Y_DGS2 0.541095890410959\n",
      "Y_DGS3 0.5136986301369864\n",
      "Y_DGS5 0.4931506849315068\n",
      "Y_DGS7 0.5102739726027398\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5171232876712328\n",
      "Y_DGS30 0.5068493150684932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 74/79 [4:01:08<15:18, 183.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6114864864864865\n",
      "Y_DGS3MO 0.6655405405405406\n",
      "Y_DGS6MO 0.6554054054054054\n",
      "Y_DGS1 0.5574324324324325\n",
      "Y_DGS2 0.5405405405405406\n",
      "Y_DGS3 0.5135135135135135\n",
      "Y_DGS5 0.49324324324324326\n",
      "Y_DGS7 0.5101351351351351\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5168918918918919\n",
      "Y_DGS30 0.5067567567567568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 75/79 [4:04:09<12:12, 183.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6166666666666667\n",
      "Y_DGS3MO 0.67\n",
      "Y_DGS6MO 0.66\n",
      "Y_DGS1 0.56\n",
      "Y_DGS2 0.54\n",
      "Y_DGS3 0.5133333333333333\n",
      "Y_DGS5 0.49666666666666665\n",
      "Y_DGS7 0.5133333333333333\n",
      "Y_DGS10 0.5033333333333333\n",
      "Y_DGS20 0.52\n",
      "Y_DGS30 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 76/79 [4:07:11<09:07, 182.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6151315789473685\n",
      "Y_DGS3MO 0.6710526315789473\n",
      "Y_DGS6MO 0.6611842105263158\n",
      "Y_DGS1 0.5625\n",
      "Y_DGS2 0.5427631578947368\n",
      "Y_DGS3 0.5098684210526315\n",
      "Y_DGS5 0.4934210526315789\n",
      "Y_DGS7 0.5098684210526315\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5164473684210527\n",
      "Y_DGS30 0.506578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 77/79 [4:10:14<06:05, 182.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6201298701298701\n",
      "Y_DGS3MO 0.6753246753246753\n",
      "Y_DGS6MO 0.6590909090909091\n",
      "Y_DGS1 0.5616883116883117\n",
      "Y_DGS2 0.538961038961039\n",
      "Y_DGS3 0.5032467532467533\n",
      "Y_DGS5 0.4902597402597403\n",
      "Y_DGS7 0.5064935064935064\n",
      "Y_DGS10 0.4967532467532468\n",
      "Y_DGS20 0.512987012987013\n",
      "Y_DGS30 0.5032467532467533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 78/79 [4:13:18<03:03, 183.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.6185897435897436\n",
      "Y_DGS3MO 0.6730769230769231\n",
      "Y_DGS6MO 0.657051282051282\n",
      "Y_DGS1 0.5576923076923077\n",
      "Y_DGS2 0.5352564102564102\n",
      "Y_DGS3 0.5032051282051282\n",
      "Y_DGS5 0.4935897435897436\n",
      "Y_DGS7 0.5096153846153846\n",
      "Y_DGS10 0.5\n",
      "Y_DGS20 0.5160256410256411\n",
      "Y_DGS30 0.5064102564102564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [4:16:19<00:00, 194.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO 0.620253164556962\n",
      "Y_DGS3MO 0.6772151898734177\n",
      "Y_DGS6MO 0.6550632911392406\n",
      "Y_DGS1 0.5569620253164557\n",
      "Y_DGS2 0.5316455696202531\n",
      "Y_DGS3 0.5\n",
      "Y_DGS5 0.49050632911392406\n",
      "Y_DGS7 0.5063291139240507\n",
      "Y_DGS10 0.49683544303797467\n",
      "Y_DGS20 0.5126582278481012\n",
      "Y_DGS30 0.5031645569620253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_DGS1MO    0.620253\n",
      "Y_DGS3MO    0.677215\n",
      "Y_DGS6MO    0.655063\n",
      "Y_DGS1      0.556962\n",
      "Y_DGS2      0.531646\n",
      "Y_DGS3      0.500000\n",
      "Y_DGS5      0.490506\n",
      "Y_DGS7      0.506329\n",
      "Y_DGS10     0.496835\n",
      "Y_DGS20     0.512658\n",
      "Y_DGS30     0.503165\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# params_by_target = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw5.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw5.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv=tscv,\n",
    "#                         scoring='accuracy',\n",
    "#                         n_jobs=-1,\n",
    "#                         verbose=0)\n",
    "\n",
    "#     grid.fit(Xw_train, Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         print(col, np.mean(accuracies[col]))\n",
    "\n",
    "#         # feature importance pour la i-ème sortie\n",
    "#         est = best_model.named_steps['xgb'].estimators_[i]   # XGBClassifier\n",
    "#         importance = est.feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "\n",
    "#         # hyperparamètres de l'estimateur i\n",
    "#         params = est.get_params()\n",
    "#         params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "\n",
    "\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "\n",
    "\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies xgboost, MI 0.05, 15y train test.csv')\n",
    "# params.to_csv('params xgboost, MI 0.05, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance xgboost, MI 0.05, 15y train test.csv')\n",
    "# ypred.to_csv('forecast xgboost, MI 0.05, 15y train test.csv')\n",
    "# ytrue.to_csv('true values xgboost, MI 0.05, 15y train test.csv')\n",
    "\n",
    "# print(acc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02f0b8",
   "metadata": {},
   "source": [
    "## D) Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea97c1",
   "metadata": {},
   "source": [
    "We'll proceed as for the logistic regression and XGBoost models when training random forests. The pipelines (with and without PCA) are defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ee62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_train = 52 * 15\n",
    "window_pred = 4\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'rf__estimator__n_estimators': [150],\n",
    "    'rf__estimator__max_depth': [4,7],\n",
    "    'rf__estimator__min_samples_leaf': [5,10]\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', MultiOutputClassifier(\n",
    "        RandomForestClassifier(\n",
    "            n_jobs=-1,\n",
    "            random_state = 42\n",
    "            )))\n",
    "])\n",
    "\n",
    "pipepca = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca',PCA(n_components=0.99)),\n",
    "    ('rf', MultiOutputClassifier(\n",
    "        RandomForestClassifier(\n",
    "            n_jobs=-1,\n",
    "            random_state = 42\n",
    "            )))\n",
    "])\n",
    "\n",
    "\n",
    "#we will cross validate the model the following way: \n",
    "grid = GridSearchCV(pipe,  #or pipepca\n",
    "                        param_grid,\n",
    "                        cv = tscv,\n",
    "                        scoring = 'accuracy',\n",
    "                        n_jobs=-1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_list:\n",
    "\n",
    "    print(f'training model on dataset with features with mutual information above {threshold}')\n",
    "\n",
    "    Xw = datasets[threshold]\n",
    "\n",
    "    # for the dataset containing features with mutual information above 0.03:\n",
    "    # we'll train our random forest model with and without PCA since there are many features in this dataset\n",
    "    if threshold == 0.03:\n",
    "\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['rf'].estimators_[i]  \n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies random forest, 15y train test.csv')\n",
    "        params.to_csv('results of models/params random forest, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance random forest, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast random forest, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values random forest, 15y train test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #### Now we do the same training but this time we add the PCA in the pipeline before training the model\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "\n",
    "        \n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipepca,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['rf'].estimators_[i]   \n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "\n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} and PCA is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv('results of models/accuracies random forest, pca, 15y train test.csv')\n",
    "        params.to_csv('results of models/params random forest, pca, 15y train test.csv')\n",
    "        feature_imp.to_csv('results of models/feature importance random forest, pca, 15y train test.csv')\n",
    "        ypred.to_csv('results of models/forecast random forest, pca, 15y train test.csv')\n",
    "        ytrue.to_csv('results of models/true values random forest, pca, 15y train test.csv')\n",
    "    \n",
    "\n",
    "    # for other datasets with larger mutual information threshold, we don't apply PCA and train the model directly \n",
    "    else:\n",
    "        accuracies = {col: [] for col in Yw.columns}\n",
    "        params_by_target = {col: [] for col in Yw.columns}\n",
    "        feature_importance = {col: [] for col in Yw.columns}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "            end_train = start + window_train\n",
    "            end_pred = end_train + window_pred\n",
    "\n",
    "            Xw_train = Xw.iloc[start:end_train]\n",
    "            Yw_train = Yw.iloc[start:end_train]\n",
    "            Xw_test = Xw.iloc[end_train:end_pred]\n",
    "            Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "            y_true.append(Yw_test)\n",
    "\n",
    "            grid = GridSearchCV(pipe,\n",
    "                                param_grid,\n",
    "                                cv=tscv,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=0)\n",
    "\n",
    "            grid.fit(Xw_train, Yw_train)\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            Yw_pred = best_model.predict(Xw_test)\n",
    "            y_pred.append(Yw_pred)\n",
    "\n",
    "            for i, col in enumerate(Yw_train.columns):\n",
    "                acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "                accuracies[col].append(acc)\n",
    "                print(col, np.mean(accuracies[col]))\n",
    "\n",
    "                # feature importance pour la i-ème sortie\n",
    "                est = best_model.named_steps['rf'].estimators_[i]  \n",
    "                importance = est.feature_importances_\n",
    "                feature_importance[col].append(importance)\n",
    "\n",
    "                # hyperparamètres de l'estimateur i\n",
    "                params = est.get_params()\n",
    "                params_by_target[col].append(params)\n",
    "\n",
    "\n",
    "        \n",
    "        acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "        params = pd.DataFrame(params_by_target, columns = Yw.columns) \n",
    "        feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "        Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "        Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "        ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "        print(f'For each yield, the average out-of-sample accuracy over the 79 rolling windows on the dataset with mutual information > {threshold} is:')\n",
    "        print(acc.mean())\n",
    "        acc.to_csv(f'results of models/accuracies random forest, MI {threshold}, 15y train test.csv')\n",
    "        params.to_csv(f'results of models/params random forest, MI {threshold}, 15y train test.csv')\n",
    "        feature_imp.to_csv(f'results of models/feature importance random forest, MI {threshold}, 15y train test.csv')\n",
    "        ypred.to_csv(f'results of models/forecast random forest, MI {threshold}, 15y train test.csv')\n",
    "        ytrue.to_csv(f'results of models/true values random forest, MI {threshold}, 15y train test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf2355",
   "metadata": {},
   "source": [
    "We now train a random forest model on the dataset with features with a mutual information higher than 0.03: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# param = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv = tscv,\n",
    "#                         scoring = 'accuracy',\n",
    "#                         n_jobs=-1\n",
    "#                         )\n",
    "\n",
    "#     grid.fit(Xw_train,Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         # feature importance\n",
    "#         importance = best_model.named_steps['rf'].estimators_[i].feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "#         # hyperparameters\n",
    "#         params = best_model.named_steps['rf'].estimators_[i].get_params()\n",
    "#         param[col].append(param)\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(param, columns = Yw.columns)\n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "# acc.to_csv('accuracies random forest, no pca, 15y train test.csv')\n",
    "# params.to_csv('params random forest, no pca, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance random forest, no pca, 15y train test.csv')\n",
    "# ypred.to_csv('forecast random forest, no pca, 15y train test.csv')\n",
    "# ytrue.to_csv('true values random forest, no pca, 15y train test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a112ae1",
   "metadata": {},
   "source": [
    "For the dataset with MI >0.03, and applying a PCA before training the random forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eeb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# param = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "\n",
    "#     grid = GridSearchCV(pipepca,\n",
    "#                         param_grid,\n",
    "#                         cv = tscv,\n",
    "#                         scoring = 'accuracy',\n",
    "#                         n_jobs=-1\n",
    "#                         )\n",
    "\n",
    "#     grid.fit(Xw_train,Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         # feature importance\n",
    "#         importance = best_model.named_steps['rf'].estimators_[i].feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "#         # hyperparameters\n",
    "#         params = best_model.named_steps['rf'].estimators_[i].get_params()\n",
    "#         param[col].append(param)\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(param, columns = Yw.columns)\n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "# acc.to_csv('accuracies random forest pca, 15y train test.csv')\n",
    "# params.to_csv('params random forest pca, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance random forest pca, 15y train test.csv')\n",
    "# ypred.to_csv('forecast random forest pca, 15y train test.csv')\n",
    "# ytrue.to_csv('true values random forest pca, 15y train test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8457d",
   "metadata": {},
   "source": [
    "For the dataset with MI>0.035:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e13ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:32<00:00,  2.92s/it]\n",
      "100%|██████████| 79/79 [39:07<00:00, 29.71s/it] \n"
     ]
    }
   ],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# param = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw35.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw35.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv = tscv,\n",
    "#                         scoring = 'accuracy',\n",
    "#                         n_jobs=-1\n",
    "#                         )\n",
    "\n",
    "#     grid.fit(Xw_train,Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         # feature importance\n",
    "#         importance = best_model.named_steps['rf'].estimators_[i].feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "#         # hyperparameters\n",
    "#         params = best_model.named_steps['rf'].estimators_[i].get_params()\n",
    "#         param[col].append(param)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(param, columns = Yw.columns)\n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "\n",
    "\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "\n",
    "\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies random forest, MI 0.035, 15y train test.csv')\n",
    "# params.to_csv('params random forest, MI 0.035, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance random forest, MI 0.035, 15y train test.csv')\n",
    "# ypred.to_csv('forecast random forest, MI 0.035, 15y train test.csv')\n",
    "# ytrue.to_csv('true values random forest, MI 0.035, 15y train test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a01bdb",
   "metadata": {},
   "source": [
    "For the dataset with MI > 0.04:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# param = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw4.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw4.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv = tscv,\n",
    "#                         scoring = 'accuracy',\n",
    "#                         n_jobs=-1\n",
    "#                         )\n",
    "\n",
    "#     grid.fit(Xw_train,Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         # feature importance\n",
    "#         importance = best_model.named_steps['rf'].estimators_[i].feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "#         # hyperparameters\n",
    "#         params = best_model.named_steps['rf'].estimators_[i].get_params()\n",
    "#         param[col].append(param)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(param, columns = Yw.columns)\n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies random forest, MI 0.04, 15y train test.csv')\n",
    "# params.to_csv('params random forest, MI 0.04, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance random forest, MI 0.04, 15y train test.csv')\n",
    "# ypred.to_csv('forecast random forest, MI 0.04, 15y train test.csv')\n",
    "# ytrue.to_csv('true values random forest, MI 0.04, 15y train test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03ff8d",
   "metadata": {},
   "source": [
    "For the dataset with MI > 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933affab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = {col: [] for col in Yw.columns}\n",
    "# param = {col: [] for col in Yw.columns}\n",
    "# feature_importance = {col: [] for col in Yw.columns}\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "\n",
    "# for start in tqdm(range(0, len(Xw) - window_train - window_pred + 1, window_pred)):\n",
    "#     end_train = start + window_train\n",
    "#     end_pred = end_train + window_pred\n",
    "\n",
    "#     Xw_train = Xw5.iloc[start:end_train]\n",
    "#     Yw_train = Yw.iloc[start:end_train]\n",
    "#     Xw_test = Xw5.iloc[end_train:end_pred]\n",
    "#     Yw_test = Yw.iloc[end_train:end_pred]\n",
    "\n",
    "#     y_true.append(Yw_test)\n",
    "\n",
    "\n",
    "#     grid = GridSearchCV(pipe,\n",
    "#                         param_grid,\n",
    "#                         cv = tscv,\n",
    "#                         scoring = 'accuracy',\n",
    "#                         n_jobs=-1\n",
    "#                         )\n",
    "\n",
    "#     grid.fit(Xw_train,Yw_train)\n",
    "#     best_model = grid.best_estimator_\n",
    "\n",
    "#     Yw_pred = best_model.predict(Xw_test)\n",
    "\n",
    "#     y_pred.append(Yw_pred)\n",
    "\n",
    "#     for i, col in enumerate(Yw_train.columns):\n",
    "#         acc = accuracy_score(Yw_test[col], Yw_pred[:, i])\n",
    "#         accuracies[col].append(acc)\n",
    "#         # feature importance\n",
    "#         importance = best_model.named_steps['rf'].estimators_[i].feature_importances_\n",
    "#         feature_importance[col].append(importance)\n",
    "#         # hyperparameters\n",
    "#         params = best_model.named_steps['rf'].estimators_[i].get_params()\n",
    "#         param[col].append(param)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# acc = pd.DataFrame(accuracies,columns = Yw.columns)\n",
    "# params = pd.DataFrame(param, columns = Yw.columns)\n",
    "# feature_imp = pd.DataFrame(feature_importance, columns = Yw.columns)\n",
    "# Y_true_flat = np.array(y_true).reshape(-1, np.array(y_true).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ytrue = pd.DataFrame(Y_true_flat, index = Yw.iloc[780:Yw.shape[0]-1].index,columns=Yw.columns)\n",
    "# Y_pred_flat = np.array(y_pred).reshape(-1, np.array(y_pred).shape[2])  # aplati les 2 premières dimensions en une seule\n",
    "# ypred = pd.DataFrame(Y_pred_flat,index = Yw.iloc[780:Yw.shape[0]-1].index, columns=Yw.columns)\n",
    "\n",
    "\n",
    "\n",
    "# acc.to_csv('accuracies random forest, MI 0.05, 15y train test.csv')\n",
    "# params.to_csv('params random forest, MI 0.05, 15y train test.csv')\n",
    "# feature_imp.to_csv('feature importance random forest, MI 0.05, 15y train test.csv')\n",
    "# ypred.to_csv('forecast random forest, MI 0.05, 15y train test.csv')\n",
    "# ytrue.to_csv('true values random forest, MI 0.05, 15y train test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f6a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6db92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
